{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training data 로부터 20% 비율로 validation data 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration:\n",
    "    \n",
    "    # target_position = 0 (첫번째열이 정답데이터), target_position=-1 (마지막열이 정답데이터)\n",
    "    def __init__(self, name, file_path, seperation_rate, target_position=-1):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        \n",
    "        self.seperation_rate = seperation_rate\n",
    "        \n",
    "        if (target_position == -1  or  target_position == 0):      \n",
    "            self.target_position = target_position\n",
    "        \n",
    "        else:\n",
    "            err_str = 'target_position must be -1 or 0'            \n",
    "            raise Exception(err_str)    \n",
    "            \n",
    "    \n",
    "    # print data target distribution \n",
    "    # str_of_kind : 'original data' or  'training data'  or  'test data'\n",
    "    def __display_target_distribution(self, data, str_of_kind='original data'):\n",
    "        \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        target_data = data[ :, self.target_position ]\n",
    "        \n",
    "        # numpy.unique() 사용하여 loaded data target 분포 확인\n",
    "        unique, counts = np.unique(target_data, return_counts=True)\n",
    "\n",
    "        unique_target = []\n",
    "    \n",
    "        for index in range(len(unique)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique[index], ', count = ', counts[index])\n",
    "        \n",
    "            unique_target.append(unique[index])\n",
    "\n",
    "        for index in range(len(unique_target)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique_target[index], ', ratio = ', np.round(100 * counts[index] / (target_data.shape[0]), 2), ' %')\n",
    "    \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        \n",
    "    # numpy.random.shuffle()  이용하여 training_data / test_data 생성\n",
    "    def generate(self):\n",
    "    \n",
    "        # 데이터 불러오기, 파일이 없는 경우 exception 발생\n",
    "\n",
    "        try:\n",
    "            loaded_data = np.loadtxt(self.file_path, delimiter=',', dtype=np.float32)\n",
    "            \n",
    "        except Exception as err:\n",
    "            print('[DataGeneration::generate()]  ', str(err))\n",
    "            raise Exception(str(err))\n",
    "\n",
    "        print(\"[DataGeneration]  loaded_data.shape = \", loaded_data.shape)\n",
    "            \n",
    "        # print the target distribution of original data \n",
    "        \n",
    "        self.__display_target_distribution(loaded_data, 'original data')\n",
    "        \n",
    "        \n",
    "        # 분리비율에 맞게 테스트데이터로 분리\n",
    "        total_data_num = len(loaded_data)\n",
    "        test_data_num = int(len(loaded_data) * self.seperation_rate)\n",
    "\n",
    "        # numpy.random.shuffle 을 이용하여 랜덤하게 데이터 섞기\n",
    "        np.random.shuffle(loaded_data)\n",
    "        \n",
    "        # test_data 는 0 : test_data_num\n",
    "        \n",
    "        \n",
    "        test_data = loaded_data[ 0:test_data_num ]\n",
    "\n",
    "        # training_data 는 test_data_num 부터 끝까지 \n",
    "        training_data = loaded_data[ test_data_num: ]\n",
    "\n",
    "        # display target distribution of generated data \n",
    "        \n",
    "        self.__display_target_distribution(training_data, 'training data')\n",
    "        \n",
    "        self.__display_target_distribution(test_data, 'test data')\n",
    "        \n",
    "        return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        # 은닉층 가중치  W2 = (784 X 100) Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes)      \n",
    "        \n",
    "        # 출력층 가중치는 W3 = (100X10)  Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes, self.output_nodes) / np.sqrt(self.hidden_nodes/2)\n",
    "        self.b3 = np.random.rand(self.output_nodes)      \n",
    "                        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 정의 (모두 행렬로 표시)\n",
    "        self.Z3 = np.zeros([1,output_nodes])\n",
    "        self.A3 = np.zeros([1,output_nodes])\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 정의 (모두 행렬로 표시)\n",
    "        self.Z2 = np.zeros([1,hidden_nodes])\n",
    "        self.A2 = np.zeros([1,hidden_nodes])\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 정의 (모두 행렬로 표시)\n",
    "        self.Z1 = np.zeros([1,input_nodes])    \n",
    "        self.A1 = np.zeros([1,input_nodes])       \n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def feed_forward(self):  \n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        return  -np.sum( self.target_data*np.log(self.A3 + delta) + (1-self.target_data)*np.log((1 - self.A3)+delta ) )    \n",
    "    \n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        return  -np.sum( self.target_data*np.log(self.A3 + delta) + (1-self.target_data)*np.log((1 - self.A3)+delta ) )\n",
    "   \n",
    "    \n",
    "    # 정확도 측정함수 \n",
    "    def accuracy(self, test_input_data, test_target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        \n",
    "        for index in range(len(test_input_data)):\n",
    "                        \n",
    "            label = int(test_target_data[index])\n",
    "                        \n",
    "            # one-hot encoding을 위한 데이터 정규화 (data normalize)\n",
    "            data = (test_input_data[index] / 255.0 * 0.99) + 0.01\n",
    "                  \n",
    "            # predict 를 위해서 vector 을 matrix 로 변환하여 인수로 넘겨줌\n",
    "            predicted_num = self.predict(np.array(data, ndmin=2)) \n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "                \n",
    "        #print(\"Current Accuracy = \", (len(matched_list)/(len(test_input_data))) )\n",
    "        \n",
    "        accuracy_val = (len(matched_list)/(len(test_input_data)))\n",
    "        \n",
    "        return accuracy_val, not_matched_list\n",
    "    \n",
    "    \n",
    "    def train(self, input_data, target_data):   # input_data : 784 개, target_data : 10개\n",
    "        \n",
    "        self.target_data = target_data    \n",
    "        self.input_data = input_data\n",
    "        \n",
    "        # 먼저 feed forward 를 통해서 최종 출력값과 이를 바탕으로 현재의 에러 값 계산\n",
    "        loss_val = self.feed_forward()\n",
    "        \n",
    "        # 출력층 loss 인 loss_3 구함\n",
    "        loss_3 = (self.A3-self.target_data) * self.A3 * (1-self.A3)\n",
    "        \n",
    "        # 출력층 가중치 W3, 출력층 바이어스 b3 업데이트\n",
    "        self.W3 = self.W3 - self.learning_rate * np.dot(self.A2.T, loss_3)   \n",
    "        \n",
    "        self.b3 = self.b3 - self.learning_rate * loss_3  \n",
    "        \n",
    "        # 은닉층 loss 인 loss_2 구함        \n",
    "        loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)\n",
    "        \n",
    "        # 은닉층 가중치 W2, 은닉층 바이어스 b2 업데이트\n",
    "        self.W2 = self.W2 - self.learning_rate * np.dot(self.A1.T, loss_2)   \n",
    "        \n",
    "        self.b2 = self.b2 - self.learning_rate * loss_2\n",
    "        \n",
    "    def predict(self, input_data):        # input_data 는 행렬로 입력됨 즉, (1, 784) shape 을 가짐        \n",
    "        \n",
    "        Z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = sigmoid(Z3)\n",
    "        \n",
    "        predicted_num = np.argmax(A3)\n",
    "    \n",
    "        return predicted_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation 비율 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataGeneration]  loaded_data.shape =  (60000, 785)\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of original data =  0.0 , count =  5923\n",
      "[DataGeneration] unique number of original data =  1.0 , count =  6742\n",
      "[DataGeneration] unique number of original data =  2.0 , count =  5958\n",
      "[DataGeneration] unique number of original data =  3.0 , count =  6131\n",
      "[DataGeneration] unique number of original data =  4.0 , count =  5842\n",
      "[DataGeneration] unique number of original data =  5.0 , count =  5421\n",
      "[DataGeneration] unique number of original data =  6.0 , count =  5918\n",
      "[DataGeneration] unique number of original data =  7.0 , count =  6265\n",
      "[DataGeneration] unique number of original data =  8.0 , count =  5851\n",
      "[DataGeneration] unique number of original data =  9.0 , count =  5949\n",
      "[DataGeneration] unique number of original data =  0.0 , ratio =  9.87  %\n",
      "[DataGeneration] unique number of original data =  1.0 , ratio =  11.24  %\n",
      "[DataGeneration] unique number of original data =  2.0 , ratio =  9.93  %\n",
      "[DataGeneration] unique number of original data =  3.0 , ratio =  10.22  %\n",
      "[DataGeneration] unique number of original data =  4.0 , ratio =  9.74  %\n",
      "[DataGeneration] unique number of original data =  5.0 , ratio =  9.04  %\n",
      "[DataGeneration] unique number of original data =  6.0 , ratio =  9.86  %\n",
      "[DataGeneration] unique number of original data =  7.0 , ratio =  10.44  %\n",
      "[DataGeneration] unique number of original data =  8.0 , ratio =  9.75  %\n",
      "[DataGeneration] unique number of original data =  9.0 , ratio =  9.91  %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of training data =  0.0 , count =  4746\n",
      "[DataGeneration] unique number of training data =  1.0 , count =  5406\n",
      "[DataGeneration] unique number of training data =  2.0 , count =  4779\n",
      "[DataGeneration] unique number of training data =  3.0 , count =  4930\n",
      "[DataGeneration] unique number of training data =  4.0 , count =  4667\n",
      "[DataGeneration] unique number of training data =  5.0 , count =  4369\n",
      "[DataGeneration] unique number of training data =  6.0 , count =  4663\n",
      "[DataGeneration] unique number of training data =  7.0 , count =  5026\n",
      "[DataGeneration] unique number of training data =  8.0 , count =  4636\n",
      "[DataGeneration] unique number of training data =  9.0 , count =  4778\n",
      "[DataGeneration] unique number of training data =  0.0 , ratio =  9.89  %\n",
      "[DataGeneration] unique number of training data =  1.0 , ratio =  11.26  %\n",
      "[DataGeneration] unique number of training data =  2.0 , ratio =  9.96  %\n",
      "[DataGeneration] unique number of training data =  3.0 , ratio =  10.27  %\n",
      "[DataGeneration] unique number of training data =  4.0 , ratio =  9.72  %\n",
      "[DataGeneration] unique number of training data =  5.0 , ratio =  9.1  %\n",
      "[DataGeneration] unique number of training data =  6.0 , ratio =  9.71  %\n",
      "[DataGeneration] unique number of training data =  7.0 , ratio =  10.47  %\n",
      "[DataGeneration] unique number of training data =  8.0 , ratio =  9.66  %\n",
      "[DataGeneration] unique number of training data =  9.0 , ratio =  9.95  %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of test data =  0.0 , count =  1177\n",
      "[DataGeneration] unique number of test data =  1.0 , count =  1336\n",
      "[DataGeneration] unique number of test data =  2.0 , count =  1179\n",
      "[DataGeneration] unique number of test data =  3.0 , count =  1201\n",
      "[DataGeneration] unique number of test data =  4.0 , count =  1175\n",
      "[DataGeneration] unique number of test data =  5.0 , count =  1052\n",
      "[DataGeneration] unique number of test data =  6.0 , count =  1255\n",
      "[DataGeneration] unique number of test data =  7.0 , count =  1239\n",
      "[DataGeneration] unique number of test data =  8.0 , count =  1215\n",
      "[DataGeneration] unique number of test data =  9.0 , count =  1171\n",
      "[DataGeneration] unique number of test data =  0.0 , ratio =  9.81  %\n",
      "[DataGeneration] unique number of test data =  1.0 , ratio =  11.13  %\n",
      "[DataGeneration] unique number of test data =  2.0 , ratio =  9.82  %\n",
      "[DataGeneration] unique number of test data =  3.0 , ratio =  10.01  %\n",
      "[DataGeneration] unique number of test data =  4.0 , ratio =  9.79  %\n",
      "[DataGeneration] unique number of test data =  5.0 , ratio =  8.77  %\n",
      "[DataGeneration] unique number of test data =  6.0 , ratio =  10.46  %\n",
      "[DataGeneration] unique number of test data =  7.0 , ratio =  10.32  %\n",
      "[DataGeneration] unique number of test data =  8.0 , ratio =  10.12  %\n",
      "[DataGeneration] unique number of test data =  9.0 , ratio =  9.76  %\n",
      "=======================================================================================================\n",
      "training_data.shape =  (48000, 785)\n",
      "validation_data.shape =  (12000, 785)\n"
     ]
    }
   ],
   "source": [
    "# DataGeneration class 이용하여 training data , validation data 생성\n",
    "seperation_rate = 0.2  # training data 10 % 비율로 validation data 생성\n",
    "target_position = 0    # 정답은 첫번째 열\n",
    "\n",
    "try:\n",
    "    data_obj = DataGeneration('MNIST', './mnist_train.csv', seperation_rate, target_position)\n",
    "\n",
    "    (training_data, validation_data) = data_obj.generate()\n",
    "    \n",
    "    print(\"training_data.shape = \", training_data.shape)\n",
    "    print(\"validation_data.shape = \", validation_data.shape)\n",
    "\n",
    "except Exception as err:\n",
    "    print('Exception Occur !!')\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 은닉층 노드 100 개 인 경우의 MNIST 오차역전파 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  1 , step =  0 , current loss_val =  8.7723781167449\n",
      "epochs =  1 , step =  1000 , current loss_val =  1.282195969069911\n",
      "epochs =  1 , step =  2000 , current loss_val =  0.8099511855620258\n",
      "epochs =  1 , step =  3000 , current loss_val =  1.2983634141192513\n",
      "epochs =  1 , step =  4000 , current loss_val =  0.8565900947702215\n",
      "epochs =  1 , step =  5000 , current loss_val =  0.8587066606838726\n",
      "epochs =  1 , step =  6000 , current loss_val =  1.0133768380118953\n",
      "epochs =  1 , step =  7000 , current loss_val =  0.9120218202053497\n",
      "epochs =  1 , step =  8000 , current loss_val =  0.6632417579355425\n",
      "epochs =  1 , step =  9000 , current loss_val =  0.8734468636958455\n",
      "epochs =  1 , step =  10000 , current loss_val =  0.8212222492896591\n",
      "epochs =  1 , step =  11000 , current loss_val =  3.0606437685618624\n",
      "epochs =  1 , step =  12000 , current loss_val =  0.9371317453162993\n",
      "epochs =  1 , step =  13000 , current loss_val =  0.7737534693843096\n",
      "epochs =  1 , step =  14000 , current loss_val =  0.6798885038212699\n",
      "epochs =  1 , step =  15000 , current loss_val =  0.9536731128650847\n",
      "epochs =  1 , step =  16000 , current loss_val =  8.880247397754555\n",
      "epochs =  1 , step =  17000 , current loss_val =  0.822803838857112\n",
      "epochs =  1 , step =  18000 , current loss_val =  0.9227121038038414\n",
      "epochs =  1 , step =  19000 , current loss_val =  2.246008293399855\n",
      "epochs =  1 , step =  20000 , current loss_val =  0.7551892017906812\n",
      "epochs =  1 , step =  21000 , current loss_val =  0.8922386045274755\n",
      "epochs =  1 , step =  22000 , current loss_val =  0.8282276946648551\n",
      "epochs =  1 , step =  23000 , current loss_val =  0.7348762298084712\n",
      "epochs =  1 , step =  24000 , current loss_val =  0.9395491421119123\n",
      "epochs =  1 , step =  25000 , current loss_val =  0.7724331113140813\n",
      "epochs =  1 , step =  26000 , current loss_val =  1.1244658110145282\n",
      "epochs =  1 , step =  27000 , current loss_val =  0.9582125346995489\n",
      "epochs =  1 , step =  28000 , current loss_val =  0.7705043933895783\n",
      "epochs =  1 , step =  29000 , current loss_val =  0.8058192990532672\n",
      "epochs =  1 , step =  30000 , current loss_val =  0.7166029456970722\n",
      "epochs =  1 , step =  31000 , current loss_val =  0.7245470452747048\n",
      "epochs =  1 , step =  32000 , current loss_val =  0.6939449608067128\n",
      "epochs =  1 , step =  33000 , current loss_val =  1.3860850144518058\n",
      "epochs =  1 , step =  34000 , current loss_val =  0.7279035651092205\n",
      "epochs =  1 , step =  35000 , current loss_val =  0.7157581860961554\n",
      "epochs =  1 , step =  36000 , current loss_val =  0.7180480692929282\n",
      "epochs =  1 , step =  37000 , current loss_val =  0.7530862144110779\n",
      "epochs =  1 , step =  38000 , current loss_val =  0.8570425996657447\n",
      "epochs =  1 , step =  39000 , current loss_val =  0.7394343882161446\n",
      "epochs =  1 , step =  40000 , current loss_val =  2.4545526357086893\n",
      "epochs =  1 , step =  41000 , current loss_val =  0.7690410289496581\n",
      "epochs =  1 , step =  42000 , current loss_val =  0.8265462728860753\n",
      "epochs =  1 , step =  43000 , current loss_val =  0.7890526154826836\n",
      "epochs =  1 , step =  44000 , current loss_val =  0.8411438732115355\n",
      "epochs =  1 , step =  45000 , current loss_val =  1.0070734797821272\n",
      "epochs =  1 , step =  46000 , current loss_val =  0.7541118924545855\n",
      "epochs =  1 , step =  47000 , current loss_val =  0.7138112793990683\n",
      "epochs =  2 , step =  0 , current loss_val =  0.8433226363426917\n",
      "epochs =  2 , step =  1000 , current loss_val =  0.7134090650924969\n",
      "epochs =  2 , step =  2000 , current loss_val =  0.7345452254959535\n",
      "epochs =  2 , step =  3000 , current loss_val =  1.1145385406292403\n",
      "epochs =  2 , step =  4000 , current loss_val =  0.8238975800055819\n",
      "epochs =  2 , step =  5000 , current loss_val =  0.800143244553069\n",
      "epochs =  2 , step =  6000 , current loss_val =  0.800209747769162\n",
      "epochs =  2 , step =  7000 , current loss_val =  0.8811887310774227\n",
      "epochs =  2 , step =  8000 , current loss_val =  0.843770996536112\n",
      "epochs =  2 , step =  9000 , current loss_val =  0.7600329536881852\n",
      "epochs =  2 , step =  10000 , current loss_val =  0.873845383037404\n",
      "epochs =  2 , step =  11000 , current loss_val =  4.35100124427679\n",
      "epochs =  2 , step =  12000 , current loss_val =  1.025700677705886\n",
      "epochs =  2 , step =  13000 , current loss_val =  0.8451758613686075\n",
      "epochs =  2 , step =  14000 , current loss_val =  0.7554179934940103\n",
      "epochs =  2 , step =  15000 , current loss_val =  0.7633366786404456\n",
      "epochs =  2 , step =  16000 , current loss_val =  10.54404032657131\n",
      "epochs =  2 , step =  17000 , current loss_val =  0.8286639211659801\n",
      "epochs =  2 , step =  18000 , current loss_val =  0.9355106804840744\n",
      "epochs =  2 , step =  19000 , current loss_val =  0.8387160430482419\n",
      "epochs =  2 , step =  20000 , current loss_val =  0.8028658637902328\n",
      "epochs =  2 , step =  21000 , current loss_val =  0.8081678341663379\n",
      "epochs =  2 , step =  22000 , current loss_val =  0.7989958478256682\n",
      "epochs =  2 , step =  23000 , current loss_val =  0.7818791026667065\n",
      "epochs =  2 , step =  24000 , current loss_val =  1.0080345160739466\n",
      "epochs =  2 , step =  25000 , current loss_val =  0.8083312937247774\n",
      "epochs =  2 , step =  26000 , current loss_val =  1.0152712474209717\n",
      "epochs =  2 , step =  27000 , current loss_val =  0.9474341913675518\n",
      "epochs =  2 , step =  28000 , current loss_val =  0.8657801534352935\n",
      "epochs =  2 , step =  29000 , current loss_val =  0.790454355727501\n",
      "epochs =  2 , step =  30000 , current loss_val =  0.7799959504796892\n",
      "epochs =  2 , step =  31000 , current loss_val =  0.7565610742756608\n",
      "epochs =  2 , step =  32000 , current loss_val =  0.7648675696672737\n",
      "epochs =  2 , step =  33000 , current loss_val =  1.0366340500417257\n",
      "epochs =  2 , step =  34000 , current loss_val =  0.8129662108655945\n",
      "epochs =  2 , step =  35000 , current loss_val =  0.7713470561628489\n",
      "epochs =  2 , step =  36000 , current loss_val =  0.7801511698110095\n",
      "epochs =  2 , step =  37000 , current loss_val =  0.7863880806911054\n",
      "epochs =  2 , step =  38000 , current loss_val =  0.8578597057532542\n",
      "epochs =  2 , step =  39000 , current loss_val =  0.7678602271967956\n",
      "epochs =  2 , step =  40000 , current loss_val =  2.55950021166758\n",
      "epochs =  2 , step =  41000 , current loss_val =  0.812158812034496\n",
      "epochs =  2 , step =  42000 , current loss_val =  0.8924245207563966\n",
      "epochs =  2 , step =  43000 , current loss_val =  0.8427845075624567\n",
      "epochs =  2 , step =  44000 , current loss_val =  0.8014092605855292\n",
      "epochs =  2 , step =  45000 , current loss_val =  1.0199024618026113\n",
      "epochs =  2 , step =  46000 , current loss_val =  0.7886922754203141\n",
      "epochs =  2 , step =  47000 , current loss_val =  0.7268893799796162\n",
      "epochs =  3 , step =  0 , current loss_val =  0.9317612003911369\n",
      "epochs =  3 , step =  1000 , current loss_val =  0.7207385718959485\n",
      "epochs =  3 , step =  2000 , current loss_val =  0.7487733389536079\n",
      "epochs =  3 , step =  3000 , current loss_val =  1.0408737515341082\n",
      "epochs =  3 , step =  4000 , current loss_val =  0.8366828074025083\n",
      "epochs =  3 , step =  5000 , current loss_val =  0.8561828238475493\n",
      "epochs =  3 , step =  6000 , current loss_val =  0.781863556067624\n",
      "epochs =  3 , step =  7000 , current loss_val =  0.906998691096397\n",
      "epochs =  3 , step =  8000 , current loss_val =  0.8685910369282598\n",
      "epochs =  3 , step =  9000 , current loss_val =  0.7725575778161881\n",
      "epochs =  3 , step =  10000 , current loss_val =  0.8813322381744104\n",
      "epochs =  3 , step =  11000 , current loss_val =  4.838177082398889\n",
      "epochs =  3 , step =  12000 , current loss_val =  1.0204652023370153\n",
      "epochs =  3 , step =  13000 , current loss_val =  0.884918311832263\n",
      "epochs =  3 , step =  14000 , current loss_val =  0.7750580977463899\n",
      "epochs =  3 , step =  15000 , current loss_val =  0.7820279182411434\n",
      "epochs =  3 , step =  16000 , current loss_val =  10.179795503930567\n",
      "epochs =  3 , step =  17000 , current loss_val =  0.8639796376169017\n",
      "epochs =  3 , step =  18000 , current loss_val =  0.9525934034755184\n",
      "epochs =  3 , step =  19000 , current loss_val =  0.8471382794837595\n",
      "epochs =  3 , step =  20000 , current loss_val =  0.7989064746971937\n",
      "epochs =  3 , step =  21000 , current loss_val =  0.8235227219177419\n",
      "epochs =  3 , step =  22000 , current loss_val =  0.8021631883426076\n",
      "epochs =  3 , step =  23000 , current loss_val =  0.794579134541248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  3 , step =  24000 , current loss_val =  0.9631493593569095\n",
      "epochs =  3 , step =  25000 , current loss_val =  0.8450195678246284\n",
      "epochs =  3 , step =  26000 , current loss_val =  0.9114358987318151\n",
      "epochs =  3 , step =  27000 , current loss_val =  0.941447584611931\n",
      "epochs =  3 , step =  28000 , current loss_val =  0.8765357703398118\n",
      "epochs =  3 , step =  29000 , current loss_val =  0.7832707213699772\n",
      "epochs =  3 , step =  30000 , current loss_val =  0.8005643504673734\n",
      "epochs =  3 , step =  31000 , current loss_val =  0.7946348473729756\n",
      "epochs =  3 , step =  32000 , current loss_val =  0.800134963728288\n",
      "epochs =  3 , step =  33000 , current loss_val =  0.9509132503395402\n",
      "epochs =  3 , step =  34000 , current loss_val =  0.8501748898367603\n",
      "epochs =  3 , step =  35000 , current loss_val =  0.7962703263660618\n",
      "epochs =  3 , step =  36000 , current loss_val =  0.8064081829079447\n",
      "epochs =  3 , step =  37000 , current loss_val =  0.8052307978098412\n",
      "epochs =  3 , step =  38000 , current loss_val =  0.8432546204109956\n",
      "epochs =  3 , step =  39000 , current loss_val =  0.7849789647429428\n",
      "epochs =  3 , step =  40000 , current loss_val =  2.5881042377709136\n",
      "epochs =  3 , step =  41000 , current loss_val =  0.8367223380948897\n",
      "epochs =  3 , step =  42000 , current loss_val =  0.9158329837475805\n",
      "epochs =  3 , step =  43000 , current loss_val =  0.8700240476648388\n",
      "epochs =  3 , step =  44000 , current loss_val =  0.787331185493759\n",
      "epochs =  3 , step =  45000 , current loss_val =  1.0088231562843288\n",
      "epochs =  3 , step =  46000 , current loss_val =  0.7853916143510916\n",
      "epochs =  3 , step =  47000 , current loss_val =  0.7347958004932046\n",
      "epochs =  4 , step =  0 , current loss_val =  0.9767312822585026\n",
      "epochs =  4 , step =  1000 , current loss_val =  0.716539126226379\n",
      "epochs =  4 , step =  2000 , current loss_val =  0.7494530459871388\n",
      "epochs =  4 , step =  3000 , current loss_val =  1.0111087385014945\n",
      "epochs =  4 , step =  4000 , current loss_val =  0.8468701691691496\n",
      "epochs =  4 , step =  5000 , current loss_val =  0.894166903036129\n",
      "epochs =  4 , step =  6000 , current loss_val =  0.8014316988212136\n",
      "epochs =  4 , step =  7000 , current loss_val =  0.8890744484386766\n",
      "epochs =  4 , step =  8000 , current loss_val =  0.8728588610827408\n",
      "epochs =  4 , step =  9000 , current loss_val =  0.7721583301270062\n",
      "epochs =  4 , step =  10000 , current loss_val =  0.8707284471582262\n",
      "epochs =  4 , step =  11000 , current loss_val =  4.604505329087603\n",
      "epochs =  4 , step =  12000 , current loss_val =  0.9513658484499494\n",
      "epochs =  4 , step =  13000 , current loss_val =  0.9031884459493874\n",
      "epochs =  4 , step =  14000 , current loss_val =  0.7880838538136784\n",
      "epochs =  4 , step =  15000 , current loss_val =  0.8026305259365758\n",
      "epochs =  4 , step =  16000 , current loss_val =  9.27839124404193\n",
      "epochs =  4 , step =  17000 , current loss_val =  0.8775490659303445\n",
      "epochs =  4 , step =  18000 , current loss_val =  0.9821349760155781\n",
      "epochs =  4 , step =  19000 , current loss_val =  0.8531372255208902\n",
      "epochs =  4 , step =  20000 , current loss_val =  0.8019409379846485\n",
      "epochs =  4 , step =  21000 , current loss_val =  0.83341126412156\n",
      "epochs =  4 , step =  22000 , current loss_val =  0.8180456641511523\n",
      "epochs =  4 , step =  23000 , current loss_val =  0.8053253871529159\n",
      "epochs =  4 , step =  24000 , current loss_val =  0.9542023937656279\n",
      "epochs =  4 , step =  25000 , current loss_val =  0.8573765719257106\n",
      "epochs =  4 , step =  26000 , current loss_val =  0.898702598448653\n",
      "epochs =  4 , step =  27000 , current loss_val =  0.9539963172627324\n",
      "epochs =  4 , step =  28000 , current loss_val =  0.8711014578015487\n",
      "epochs =  4 , step =  29000 , current loss_val =  0.7721181144539644\n",
      "epochs =  4 , step =  30000 , current loss_val =  0.8210680854715786\n",
      "epochs =  4 , step =  31000 , current loss_val =  0.8157946790750635\n",
      "epochs =  4 , step =  32000 , current loss_val =  0.8170495014873029\n",
      "epochs =  4 , step =  33000 , current loss_val =  0.9268144598165443\n",
      "epochs =  4 , step =  34000 , current loss_val =  0.8592774107542147\n",
      "epochs =  4 , step =  35000 , current loss_val =  0.8058800202352984\n",
      "epochs =  4 , step =  36000 , current loss_val =  0.8192140908270751\n",
      "epochs =  4 , step =  37000 , current loss_val =  0.8150469945254151\n",
      "epochs =  4 , step =  38000 , current loss_val =  0.8324847377027195\n",
      "epochs =  4 , step =  39000 , current loss_val =  0.7939704224474898\n",
      "epochs =  4 , step =  40000 , current loss_val =  2.6215667375094394\n",
      "epochs =  4 , step =  41000 , current loss_val =  0.8609786314104613\n",
      "epochs =  4 , step =  42000 , current loss_val =  0.9316321575725618\n",
      "epochs =  4 , step =  43000 , current loss_val =  0.8936535063311792\n",
      "epochs =  4 , step =  44000 , current loss_val =  0.7996804362208402\n",
      "epochs =  4 , step =  45000 , current loss_val =  1.0078126065775754\n",
      "epochs =  4 , step =  46000 , current loss_val =  0.7844448178933129\n",
      "epochs =  4 , step =  47000 , current loss_val =  0.7533063793387343\n",
      "epochs =  5 , step =  0 , current loss_val =  0.9971643579890406\n",
      "epochs =  5 , step =  1000 , current loss_val =  0.7147789672663807\n",
      "epochs =  5 , step =  2000 , current loss_val =  0.7486079879065611\n",
      "epochs =  5 , step =  3000 , current loss_val =  1.005290857402674\n",
      "epochs =  5 , step =  4000 , current loss_val =  0.8454539287304008\n",
      "epochs =  5 , step =  5000 , current loss_val =  0.9126593168229146\n",
      "epochs =  5 , step =  6000 , current loss_val =  0.8332133302582737\n",
      "epochs =  5 , step =  7000 , current loss_val =  0.8698098064298543\n",
      "epochs =  5 , step =  8000 , current loss_val =  0.8780108225457572\n",
      "epochs =  5 , step =  9000 , current loss_val =  0.784862034567142\n",
      "epochs =  5 , step =  10000 , current loss_val =  0.880857004310781\n",
      "epochs =  5 , step =  11000 , current loss_val =  4.135253252620281\n",
      "epochs =  5 , step =  12000 , current loss_val =  0.9246232708492259\n",
      "epochs =  5 , step =  13000 , current loss_val =  0.9173568007298483\n",
      "epochs =  5 , step =  14000 , current loss_val =  0.8092624875056721\n",
      "epochs =  5 , step =  15000 , current loss_val =  0.8159547777887324\n",
      "epochs =  5 , step =  16000 , current loss_val =  8.670904458663097\n",
      "epochs =  5 , step =  17000 , current loss_val =  0.8793133166129352\n",
      "epochs =  5 , step =  18000 , current loss_val =  0.993098290221249\n",
      "epochs =  5 , step =  19000 , current loss_val =  0.8676157784867735\n",
      "epochs =  5 , step =  20000 , current loss_val =  0.8103655439089605\n",
      "epochs =  5 , step =  21000 , current loss_val =  0.8269826203471916\n",
      "epochs =  5 , step =  22000 , current loss_val =  0.8322963567641949\n",
      "epochs =  5 , step =  23000 , current loss_val =  0.8094065654970254\n",
      "epochs =  5 , step =  24000 , current loss_val =  0.93179471823103\n",
      "epochs =  5 , step =  25000 , current loss_val =  0.8657049205327403\n",
      "epochs =  5 , step =  26000 , current loss_val =  0.9206398655523789\n",
      "epochs =  5 , step =  27000 , current loss_val =  0.959166256984698\n",
      "epochs =  5 , step =  28000 , current loss_val =  0.8684381955855041\n",
      "epochs =  5 , step =  29000 , current loss_val =  0.7826501795919413\n",
      "epochs =  5 , step =  30000 , current loss_val =  0.8440842944798614\n",
      "epochs =  5 , step =  31000 , current loss_val =  0.8266674684420658\n",
      "epochs =  5 , step =  32000 , current loss_val =  0.8255759318571099\n",
      "epochs =  5 , step =  33000 , current loss_val =  0.908863659173899\n",
      "epochs =  5 , step =  34000 , current loss_val =  0.867459700619958\n",
      "epochs =  5 , step =  35000 , current loss_val =  0.8164327074348439\n",
      "epochs =  5 , step =  36000 , current loss_val =  0.8314501530830543\n",
      "epochs =  5 , step =  37000 , current loss_val =  0.8275769183513497\n",
      "epochs =  5 , step =  38000 , current loss_val =  0.8393002908619318\n",
      "epochs =  5 , step =  39000 , current loss_val =  0.7896456241012261\n",
      "epochs =  5 , step =  40000 , current loss_val =  2.659039411917619\n",
      "epochs =  5 , step =  41000 , current loss_val =  0.884252253300726\n",
      "epochs =  5 , step =  42000 , current loss_val =  0.9470268410826181\n",
      "epochs =  5 , step =  43000 , current loss_val =  0.9161674919467092\n",
      "epochs =  5 , step =  44000 , current loss_val =  0.8136028426209302\n",
      "epochs =  5 , step =  45000 , current loss_val =  0.9923463230406014\n",
      "epochs =  5 , step =  46000 , current loss_val =  0.7907605262290793\n",
      "epochs =  5 , step =  47000 , current loss_val =  0.7687479492562985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  6 , step =  0 , current loss_val =  0.9953509780554791\n",
      "epochs =  6 , step =  1000 , current loss_val =  0.7255176170820067\n",
      "epochs =  6 , step =  2000 , current loss_val =  0.7521277563621075\n",
      "epochs =  6 , step =  3000 , current loss_val =  1.0071778650490695\n",
      "epochs =  6 , step =  4000 , current loss_val =  0.8356938891396724\n",
      "epochs =  6 , step =  5000 , current loss_val =  0.9222809241861726\n",
      "epochs =  6 , step =  6000 , current loss_val =  0.8692058745323015\n",
      "epochs =  6 , step =  7000 , current loss_val =  0.8689735299856678\n",
      "epochs =  6 , step =  8000 , current loss_val =  0.8908211002634496\n",
      "epochs =  6 , step =  9000 , current loss_val =  0.8048277888612997\n",
      "epochs =  6 , step =  10000 , current loss_val =  0.9077067008543553\n",
      "epochs =  6 , step =  11000 , current loss_val =  3.627363058476475\n",
      "epochs =  6 , step =  12000 , current loss_val =  0.9255601377045242\n",
      "epochs =  6 , step =  13000 , current loss_val =  0.9153486028300534\n",
      "epochs =  6 , step =  14000 , current loss_val =  0.8362316608251401\n",
      "epochs =  6 , step =  15000 , current loss_val =  0.8222873997509081\n",
      "epochs =  6 , step =  16000 , current loss_val =  8.193002708264412\n",
      "epochs =  6 , step =  17000 , current loss_val =  0.8871320327394178\n",
      "epochs =  6 , step =  18000 , current loss_val =  1.0058036172718259\n",
      "epochs =  6 , step =  19000 , current loss_val =  0.8806918798464134\n",
      "epochs =  6 , step =  20000 , current loss_val =  0.8245354760119263\n",
      "epochs =  6 , step =  21000 , current loss_val =  0.8329552677832746\n",
      "epochs =  6 , step =  22000 , current loss_val =  0.8485727266569971\n",
      "epochs =  6 , step =  23000 , current loss_val =  0.8043701832994803\n",
      "epochs =  6 , step =  24000 , current loss_val =  0.9338789627715796\n",
      "epochs =  6 , step =  25000 , current loss_val =  0.8770525602933529\n",
      "epochs =  6 , step =  26000 , current loss_val =  0.930555986006514\n",
      "epochs =  6 , step =  27000 , current loss_val =  0.965192804154862\n",
      "epochs =  6 , step =  28000 , current loss_val =  0.8755295884218824\n",
      "epochs =  6 , step =  29000 , current loss_val =  0.8005449922735798\n",
      "epochs =  6 , step =  30000 , current loss_val =  0.866063093034267\n",
      "epochs =  6 , step =  31000 , current loss_val =  0.8349192538864236\n",
      "epochs =  6 , step =  32000 , current loss_val =  0.829542857197737\n",
      "epochs =  6 , step =  33000 , current loss_val =  0.8966403220709159\n",
      "epochs =  6 , step =  34000 , current loss_val =  0.8764367533346767\n",
      "epochs =  6 , step =  35000 , current loss_val =  0.8272483828375086\n",
      "epochs =  6 , step =  36000 , current loss_val =  0.8423740926803431\n",
      "epochs =  6 , step =  37000 , current loss_val =  0.8379824823244517\n",
      "epochs =  6 , step =  38000 , current loss_val =  0.8607081474817776\n",
      "epochs =  6 , step =  39000 , current loss_val =  0.7896206766805187\n",
      "epochs =  6 , step =  40000 , current loss_val =  2.798013103517968\n",
      "epochs =  6 , step =  41000 , current loss_val =  0.9042248242730537\n",
      "epochs =  6 , step =  42000 , current loss_val =  0.9650332699636208\n",
      "epochs =  6 , step =  43000 , current loss_val =  0.9315075131799296\n",
      "epochs =  6 , step =  44000 , current loss_val =  0.8214495800950206\n",
      "epochs =  6 , step =  45000 , current loss_val =  0.9828146915004089\n",
      "epochs =  6 , step =  46000 , current loss_val =  0.8023449062541534\n",
      "epochs =  6 , step =  47000 , current loss_val =  0.7758237050060739\n",
      "epochs =  7 , step =  0 , current loss_val =  0.98580670179547\n",
      "epochs =  7 , step =  1000 , current loss_val =  0.7365434017315693\n",
      "epochs =  7 , step =  2000 , current loss_val =  0.7581397529581175\n",
      "epochs =  7 , step =  3000 , current loss_val =  1.0118512329302989\n",
      "epochs =  7 , step =  4000 , current loss_val =  0.8320117034745719\n",
      "epochs =  7 , step =  5000 , current loss_val =  0.9338710457257055\n",
      "epochs =  7 , step =  6000 , current loss_val =  0.9019773709673805\n",
      "epochs =  7 , step =  7000 , current loss_val =  0.8697383595938382\n",
      "epochs =  7 , step =  8000 , current loss_val =  0.9045738684980474\n",
      "epochs =  7 , step =  9000 , current loss_val =  0.8159925309186904\n",
      "epochs =  7 , step =  10000 , current loss_val =  0.9230608779244339\n",
      "epochs =  7 , step =  11000 , current loss_val =  3.3152882862581037\n",
      "epochs =  7 , step =  12000 , current loss_val =  0.9153247340065405\n",
      "epochs =  7 , step =  13000 , current loss_val =  0.9135865700985113\n",
      "epochs =  7 , step =  14000 , current loss_val =  0.867892421759164\n",
      "epochs =  7 , step =  15000 , current loss_val =  0.8295861548481237\n",
      "epochs =  7 , step =  16000 , current loss_val =  7.465505483711382\n",
      "epochs =  7 , step =  17000 , current loss_val =  0.8975420843415993\n",
      "epochs =  7 , step =  18000 , current loss_val =  1.0210395759172215\n",
      "epochs =  7 , step =  19000 , current loss_val =  0.8786225726862938\n",
      "epochs =  7 , step =  20000 , current loss_val =  0.8410383515461062\n",
      "epochs =  7 , step =  21000 , current loss_val =  0.8449792830091132\n",
      "epochs =  7 , step =  22000 , current loss_val =  0.865167666600246\n",
      "epochs =  7 , step =  23000 , current loss_val =  0.7997933496596624\n",
      "epochs =  7 , step =  24000 , current loss_val =  0.9508137952220549\n",
      "epochs =  7 , step =  25000 , current loss_val =  0.8902066102692694\n",
      "epochs =  7 , step =  26000 , current loss_val =  0.9303720135109096\n",
      "epochs =  7 , step =  27000 , current loss_val =  0.9642270966058171\n",
      "epochs =  7 , step =  28000 , current loss_val =  0.8883587141361612\n",
      "epochs =  7 , step =  29000 , current loss_val =  0.8136104676348674\n",
      "epochs =  7 , step =  30000 , current loss_val =  0.8880650162974031\n",
      "epochs =  7 , step =  31000 , current loss_val =  0.842833849275905\n",
      "epochs =  7 , step =  32000 , current loss_val =  0.838300624109848\n",
      "epochs =  7 , step =  33000 , current loss_val =  0.8847427029719845\n",
      "epochs =  7 , step =  34000 , current loss_val =  0.8845516315856757\n",
      "epochs =  7 , step =  35000 , current loss_val =  0.8332884297971764\n",
      "epochs =  7 , step =  36000 , current loss_val =  0.8512653119240959\n",
      "epochs =  7 , step =  37000 , current loss_val =  0.8488846748503678\n",
      "epochs =  7 , step =  38000 , current loss_val =  0.8787958889648414\n",
      "epochs =  7 , step =  39000 , current loss_val =  0.796453386219126\n",
      "epochs =  7 , step =  40000 , current loss_val =  2.964310687060479\n",
      "epochs =  7 , step =  41000 , current loss_val =  0.9201785977459701\n",
      "epochs =  7 , step =  42000 , current loss_val =  0.9805232419460532\n",
      "epochs =  7 , step =  43000 , current loss_val =  0.9442427852177835\n",
      "epochs =  7 , step =  44000 , current loss_val =  0.8319963066210102\n",
      "epochs =  7 , step =  45000 , current loss_val =  0.9939233781770573\n",
      "epochs =  7 , step =  46000 , current loss_val =  0.8119112568132076\n",
      "epochs =  7 , step =  47000 , current loss_val =  0.7799307054440867\n",
      "epochs =  8 , step =  0 , current loss_val =  0.9742703945521054\n",
      "epochs =  8 , step =  1000 , current loss_val =  0.7460653688825427\n",
      "epochs =  8 , step =  2000 , current loss_val =  0.7659518748370063\n",
      "epochs =  8 , step =  3000 , current loss_val =  1.016176746141463\n",
      "epochs =  8 , step =  4000 , current loss_val =  0.8321555949153393\n",
      "epochs =  8 , step =  5000 , current loss_val =  0.9481008259981394\n",
      "epochs =  8 , step =  6000 , current loss_val =  0.9264854659692565\n",
      "epochs =  8 , step =  7000 , current loss_val =  0.8782253102489819\n",
      "epochs =  8 , step =  8000 , current loss_val =  0.9176254562251507\n",
      "epochs =  8 , step =  9000 , current loss_val =  0.8233423808489331\n",
      "epochs =  8 , step =  10000 , current loss_val =  0.9171420045093049\n",
      "epochs =  8 , step =  11000 , current loss_val =  2.9861690761911386\n",
      "epochs =  8 , step =  12000 , current loss_val =  0.8863518719796613\n",
      "epochs =  8 , step =  13000 , current loss_val =  0.9143925492633282\n",
      "epochs =  8 , step =  14000 , current loss_val =  0.8901355565649139\n",
      "epochs =  8 , step =  15000 , current loss_val =  0.8406542285642951\n",
      "epochs =  8 , step =  16000 , current loss_val =  6.159091914477079\n",
      "epochs =  8 , step =  17000 , current loss_val =  0.9096675024312679\n",
      "epochs =  8 , step =  18000 , current loss_val =  1.0378220525501403\n",
      "epochs =  8 , step =  19000 , current loss_val =  0.8804869638104137\n",
      "epochs =  8 , step =  20000 , current loss_val =  0.8592321902808915\n",
      "epochs =  8 , step =  21000 , current loss_val =  0.8660537860924311\n",
      "epochs =  8 , step =  22000 , current loss_val =  0.8805704548391164\n",
      "epochs =  8 , step =  23000 , current loss_val =  0.8020809842660336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  8 , step =  24000 , current loss_val =  0.9667413107910082\n",
      "epochs =  8 , step =  25000 , current loss_val =  0.904512664077512\n",
      "epochs =  8 , step =  26000 , current loss_val =  0.9300834518151766\n",
      "epochs =  8 , step =  27000 , current loss_val =  0.961503721333678\n",
      "epochs =  8 , step =  28000 , current loss_val =  0.9029229424799249\n",
      "epochs =  8 , step =  29000 , current loss_val =  0.8264880539100566\n",
      "epochs =  8 , step =  30000 , current loss_val =  0.9100496525176933\n",
      "epochs =  8 , step =  31000 , current loss_val =  0.8514357645365421\n",
      "epochs =  8 , step =  32000 , current loss_val =  0.8522357879704803\n",
      "epochs =  8 , step =  33000 , current loss_val =  0.8633968633815472\n",
      "epochs =  8 , step =  34000 , current loss_val =  0.8949568067888061\n",
      "epochs =  8 , step =  35000 , current loss_val =  0.8393690666508203\n",
      "epochs =  8 , step =  36000 , current loss_val =  0.8594924394417033\n",
      "epochs =  8 , step =  37000 , current loss_val =  0.8578942479665022\n",
      "epochs =  8 , step =  38000 , current loss_val =  0.8921025431699481\n",
      "epochs =  8 , step =  39000 , current loss_val =  0.8043220052040951\n",
      "epochs =  8 , step =  40000 , current loss_val =  3.1905399069394416\n",
      "epochs =  8 , step =  41000 , current loss_val =  0.9325957288748622\n",
      "epochs =  8 , step =  42000 , current loss_val =  0.9928722194536526\n",
      "epochs =  8 , step =  43000 , current loss_val =  0.9541262830261266\n",
      "epochs =  8 , step =  44000 , current loss_val =  0.8444237493529795\n",
      "epochs =  8 , step =  45000 , current loss_val =  1.0040887145297706\n",
      "epochs =  8 , step =  46000 , current loss_val =  0.8208330178549237\n",
      "epochs =  8 , step =  47000 , current loss_val =  0.7840252255440409\n",
      "epochs =  9 , step =  0 , current loss_val =  0.9630601538287237\n",
      "epochs =  9 , step =  1000 , current loss_val =  0.7607854479142461\n",
      "epochs =  9 , step =  2000 , current loss_val =  0.7753960054125413\n",
      "epochs =  9 , step =  3000 , current loss_val =  1.0184401797227458\n",
      "epochs =  9 , step =  4000 , current loss_val =  0.8354554264483627\n",
      "epochs =  9 , step =  5000 , current loss_val =  0.9665001851764035\n",
      "epochs =  9 , step =  6000 , current loss_val =  0.946569907560283\n",
      "epochs =  9 , step =  7000 , current loss_val =  0.8920434517944327\n",
      "epochs =  9 , step =  8000 , current loss_val =  0.9335228990064446\n",
      "epochs =  9 , step =  9000 , current loss_val =  0.8332837882992007\n",
      "epochs =  9 , step =  10000 , current loss_val =  0.9031841217545179\n",
      "epochs =  9 , step =  11000 , current loss_val =  2.582588421459486\n",
      "epochs =  9 , step =  12000 , current loss_val =  0.8632236506352476\n",
      "epochs =  9 , step =  13000 , current loss_val =  0.917781684999115\n",
      "epochs =  9 , step =  14000 , current loss_val =  0.9104046423284807\n",
      "epochs =  9 , step =  15000 , current loss_val =  0.855052463783073\n",
      "epochs =  9 , step =  16000 , current loss_val =  4.717172232423288\n",
      "epochs =  9 , step =  17000 , current loss_val =  0.9226589314451812\n",
      "epochs =  9 , step =  18000 , current loss_val =  1.0487492807957808\n",
      "epochs =  9 , step =  19000 , current loss_val =  0.8845540320044305\n",
      "epochs =  9 , step =  20000 , current loss_val =  0.878936252175463\n",
      "epochs =  9 , step =  21000 , current loss_val =  0.8923882630839632\n",
      "epochs =  9 , step =  22000 , current loss_val =  0.8953774796749849\n",
      "epochs =  9 , step =  23000 , current loss_val =  0.8097707043172612\n",
      "epochs =  9 , step =  24000 , current loss_val =  0.9680463348406558\n",
      "epochs =  9 , step =  25000 , current loss_val =  0.9197808689201239\n",
      "epochs =  9 , step =  26000 , current loss_val =  0.9363319535864785\n",
      "epochs =  9 , step =  27000 , current loss_val =  0.960000595043785\n",
      "epochs =  9 , step =  28000 , current loss_val =  0.9160676087001779\n",
      "epochs =  9 , step =  29000 , current loss_val =  0.8402136053206187\n",
      "epochs =  9 , step =  30000 , current loss_val =  0.9313014665773608\n",
      "epochs =  9 , step =  31000 , current loss_val =  0.8610982202793938\n",
      "epochs =  9 , step =  32000 , current loss_val =  0.8631893892048239\n",
      "epochs =  9 , step =  33000 , current loss_val =  0.8506054846731176\n",
      "epochs =  9 , step =  34000 , current loss_val =  0.907790064331919\n",
      "epochs =  9 , step =  35000 , current loss_val =  0.8472140354363482\n",
      "epochs =  9 , step =  36000 , current loss_val =  0.8714594814765669\n",
      "epochs =  9 , step =  37000 , current loss_val =  0.869074633713447\n",
      "epochs =  9 , step =  38000 , current loss_val =  0.9069739887599894\n",
      "epochs =  9 , step =  39000 , current loss_val =  0.8115448092232225\n",
      "epochs =  9 , step =  40000 , current loss_val =  3.4585650909043784\n",
      "epochs =  9 , step =  41000 , current loss_val =  0.9472677238510033\n",
      "epochs =  9 , step =  42000 , current loss_val =  1.0043241006328665\n",
      "epochs =  9 , step =  43000 , current loss_val =  0.9654190063364165\n",
      "epochs =  9 , step =  44000 , current loss_val =  0.8548999038555535\n",
      "epochs =  9 , step =  45000 , current loss_val =  1.0096210061540576\n",
      "epochs =  9 , step =  46000 , current loss_val =  0.8304442067162643\n",
      "epochs =  9 , step =  47000 , current loss_val =  0.7890760670587177\n",
      "epochs =  10 , step =  0 , current loss_val =  0.9577635887177525\n",
      "epochs =  10 , step =  1000 , current loss_val =  0.7731098453631646\n",
      "epochs =  10 , step =  2000 , current loss_val =  0.7871038676557018\n",
      "epochs =  10 , step =  3000 , current loss_val =  1.0168038161237152\n",
      "epochs =  10 , step =  4000 , current loss_val =  0.8395855634295799\n",
      "epochs =  10 , step =  5000 , current loss_val =  0.9833854899690071\n",
      "epochs =  10 , step =  6000 , current loss_val =  0.964946247655847\n",
      "epochs =  10 , step =  7000 , current loss_val =  0.904887678567337\n",
      "epochs =  10 , step =  8000 , current loss_val =  0.9483311314786483\n",
      "epochs =  10 , step =  9000 , current loss_val =  0.8435874137808456\n",
      "epochs =  10 , step =  10000 , current loss_val =  0.8974620285702041\n",
      "epochs =  10 , step =  11000 , current loss_val =  2.1411897920565988\n",
      "epochs =  10 , step =  12000 , current loss_val =  0.8652581247174472\n",
      "epochs =  10 , step =  13000 , current loss_val =  0.9210354916852603\n",
      "epochs =  10 , step =  14000 , current loss_val =  0.9270456496828436\n",
      "epochs =  10 , step =  15000 , current loss_val =  0.8675532194029066\n",
      "epochs =  10 , step =  16000 , current loss_val =  3.66019076865279\n",
      "epochs =  10 , step =  17000 , current loss_val =  0.9324945091415494\n",
      "epochs =  10 , step =  18000 , current loss_val =  1.0539599210179345\n",
      "epochs =  10 , step =  19000 , current loss_val =  0.8887596989620072\n",
      "epochs =  10 , step =  20000 , current loss_val =  0.8964472957840695\n",
      "epochs =  10 , step =  21000 , current loss_val =  0.9241425951367075\n",
      "epochs =  10 , step =  22000 , current loss_val =  0.9073577613322287\n",
      "epochs =  10 , step =  23000 , current loss_val =  0.8221712358258066\n",
      "epochs =  10 , step =  24000 , current loss_val =  0.9567225386555225\n",
      "epochs =  10 , step =  25000 , current loss_val =  0.9348906229904851\n",
      "epochs =  10 , step =  26000 , current loss_val =  0.9434400887637454\n",
      "epochs =  10 , step =  27000 , current loss_val =  0.9585565151586467\n",
      "epochs =  10 , step =  28000 , current loss_val =  0.9255468723585024\n",
      "epochs =  10 , step =  29000 , current loss_val =  0.8539578175808256\n",
      "epochs =  10 , step =  30000 , current loss_val =  0.9512380361380196\n",
      "epochs =  10 , step =  31000 , current loss_val =  0.8710491885571922\n",
      "epochs =  10 , step =  32000 , current loss_val =  0.8729681612790181\n",
      "epochs =  10 , step =  33000 , current loss_val =  0.8513438692180837\n",
      "epochs =  10 , step =  34000 , current loss_val =  0.9204657814538296\n",
      "epochs =  10 , step =  35000 , current loss_val =  0.8523410453811198\n",
      "epochs =  10 , step =  36000 , current loss_val =  0.8849458226645261\n",
      "epochs =  10 , step =  37000 , current loss_val =  0.8853956619147082\n",
      "epochs =  10 , step =  38000 , current loss_val =  0.9239147637262805\n",
      "epochs =  10 , step =  39000 , current loss_val =  0.8212056641877065\n",
      "epochs =  10 , step =  40000 , current loss_val =  3.745512105468087\n",
      "epochs =  10 , step =  41000 , current loss_val =  0.9607731098500112\n",
      "epochs =  10 , step =  42000 , current loss_val =  1.0161499138308392\n",
      "epochs =  10 , step =  43000 , current loss_val =  0.9781190928907133\n",
      "epochs =  10 , step =  44000 , current loss_val =  0.8645797118992474\n",
      "epochs =  10 , step =  45000 , current loss_val =  0.9958001760125664\n",
      "epochs =  10 , step =  46000 , current loss_val =  0.8404504941641374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  10 , step =  47000 , current loss_val =  0.7957366475609279\n",
      "epochs =  11 , step =  0 , current loss_val =  0.9596026754538809\n",
      "epochs =  11 , step =  1000 , current loss_val =  0.7845129783812418\n",
      "epochs =  11 , step =  2000 , current loss_val =  0.8005684439047862\n",
      "epochs =  11 , step =  3000 , current loss_val =  1.00761960595207\n",
      "epochs =  11 , step =  4000 , current loss_val =  0.8442397249201999\n",
      "epochs =  11 , step =  5000 , current loss_val =  0.9966139649481867\n",
      "epochs =  11 , step =  6000 , current loss_val =  0.9828946617090916\n",
      "epochs =  11 , step =  7000 , current loss_val =  0.9165231883768119\n",
      "epochs =  11 , step =  8000 , current loss_val =  0.9651783419743727\n",
      "epochs =  11 , step =  9000 , current loss_val =  0.8544539313654584\n",
      "epochs =  11 , step =  10000 , current loss_val =  0.9006870895482864\n",
      "epochs =  11 , step =  11000 , current loss_val =  1.7204667227781454\n",
      "epochs =  11 , step =  12000 , current loss_val =  0.8631694747413836\n",
      "epochs =  11 , step =  13000 , current loss_val =  0.9276242771300071\n",
      "epochs =  11 , step =  14000 , current loss_val =  0.9401096474565144\n",
      "epochs =  11 , step =  15000 , current loss_val =  0.8776099044620536\n",
      "epochs =  11 , step =  16000 , current loss_val =  2.8292697469547696\n",
      "epochs =  11 , step =  17000 , current loss_val =  0.9391569608770238\n",
      "epochs =  11 , step =  18000 , current loss_val =  1.054201614033468\n",
      "epochs =  11 , step =  19000 , current loss_val =  0.8965386287599557\n",
      "epochs =  11 , step =  20000 , current loss_val =  0.9131665084827548\n",
      "epochs =  11 , step =  21000 , current loss_val =  0.9523564401540063\n",
      "epochs =  11 , step =  22000 , current loss_val =  0.9173846077393037\n",
      "epochs =  11 , step =  23000 , current loss_val =  0.8371853261487447\n",
      "epochs =  11 , step =  24000 , current loss_val =  0.9417974598392257\n",
      "epochs =  11 , step =  25000 , current loss_val =  0.9508946582861915\n",
      "epochs =  11 , step =  26000 , current loss_val =  0.9496077118240523\n",
      "epochs =  11 , step =  27000 , current loss_val =  0.9595804580683224\n",
      "epochs =  11 , step =  28000 , current loss_val =  0.9369316137149173\n",
      "epochs =  11 , step =  29000 , current loss_val =  0.86880350781634\n",
      "epochs =  11 , step =  30000 , current loss_val =  0.9689586821649318\n",
      "epochs =  11 , step =  31000 , current loss_val =  0.8808894135234274\n",
      "epochs =  11 , step =  32000 , current loss_val =  0.8820880534870597\n",
      "epochs =  11 , step =  33000 , current loss_val =  0.8553634983465849\n",
      "epochs =  11 , step =  34000 , current loss_val =  0.9328026621381538\n",
      "epochs =  11 , step =  35000 , current loss_val =  0.8548635183295239\n",
      "epochs =  11 , step =  36000 , current loss_val =  0.8969876466055452\n",
      "epochs =  11 , step =  37000 , current loss_val =  0.9035696682494517\n",
      "epochs =  11 , step =  38000 , current loss_val =  0.9393122671911258\n",
      "epochs =  11 , step =  39000 , current loss_val =  0.8341038724008052\n",
      "epochs =  11 , step =  40000 , current loss_val =  3.9083895144525003\n",
      "epochs =  11 , step =  41000 , current loss_val =  0.9703967760348926\n",
      "epochs =  11 , step =  42000 , current loss_val =  1.0269400475717974\n",
      "epochs =  11 , step =  43000 , current loss_val =  0.9902128168768938\n",
      "epochs =  11 , step =  44000 , current loss_val =  0.8743003015649424\n",
      "epochs =  11 , step =  45000 , current loss_val =  0.9765389453508508\n",
      "epochs =  11 , step =  46000 , current loss_val =  0.8526365609018399\n",
      "epochs =  11 , step =  47000 , current loss_val =  0.804610291646658\n",
      "epochs =  12 , step =  0 , current loss_val =  0.9666478166856642\n",
      "epochs =  12 , step =  1000 , current loss_val =  0.7958129206219138\n",
      "epochs =  12 , step =  2000 , current loss_val =  0.8122506811226714\n",
      "epochs =  12 , step =  3000 , current loss_val =  0.9984693787468651\n",
      "epochs =  12 , step =  4000 , current loss_val =  0.8494662043696559\n",
      "epochs =  12 , step =  5000 , current loss_val =  1.0066743843484014\n",
      "epochs =  12 , step =  6000 , current loss_val =  1.0010053997306856\n",
      "epochs =  12 , step =  7000 , current loss_val =  0.9274582552354944\n",
      "epochs =  12 , step =  8000 , current loss_val =  0.9822336548777919\n",
      "epochs =  12 , step =  9000 , current loss_val =  0.8702686021197074\n",
      "epochs =  12 , step =  10000 , current loss_val =  0.90667938704839\n",
      "epochs =  12 , step =  11000 , current loss_val =  1.3887980664147337\n",
      "epochs =  12 , step =  12000 , current loss_val =  0.861112606912689\n",
      "epochs =  12 , step =  13000 , current loss_val =  0.9359672589232124\n",
      "epochs =  12 , step =  14000 , current loss_val =  0.9511336548459086\n",
      "epochs =  12 , step =  15000 , current loss_val =  0.8870232647857017\n",
      "epochs =  12 , step =  16000 , current loss_val =  2.233750480945352\n",
      "epochs =  12 , step =  17000 , current loss_val =  0.9442575546642612\n",
      "epochs =  12 , step =  18000 , current loss_val =  1.0530318346906364\n",
      "epochs =  12 , step =  19000 , current loss_val =  0.9039726430962263\n",
      "epochs =  12 , step =  20000 , current loss_val =  0.9313754226662124\n",
      "epochs =  12 , step =  21000 , current loss_val =  0.9807042438259238\n",
      "epochs =  12 , step =  22000 , current loss_val =  0.9256454387118164\n",
      "epochs =  12 , step =  23000 , current loss_val =  0.8522571553713394\n",
      "epochs =  12 , step =  24000 , current loss_val =  0.9354846902408506\n",
      "epochs =  12 , step =  25000 , current loss_val =  0.9662446607441738\n",
      "epochs =  12 , step =  26000 , current loss_val =  0.9527583815017179\n",
      "epochs =  12 , step =  27000 , current loss_val =  0.9611550451510265\n",
      "epochs =  12 , step =  28000 , current loss_val =  0.9506355747845099\n",
      "epochs =  12 , step =  29000 , current loss_val =  0.883630251097356\n",
      "epochs =  12 , step =  30000 , current loss_val =  0.9834703877902783\n",
      "epochs =  12 , step =  31000 , current loss_val =  0.8913788172711593\n",
      "epochs =  12 , step =  32000 , current loss_val =  0.8878867699600257\n",
      "epochs =  12 , step =  33000 , current loss_val =  0.8600266289408177\n",
      "epochs =  12 , step =  34000 , current loss_val =  0.945429280540201\n",
      "epochs =  12 , step =  35000 , current loss_val =  0.8590209402713115\n",
      "epochs =  12 , step =  36000 , current loss_val =  0.9079972405036317\n",
      "epochs =  12 , step =  37000 , current loss_val =  0.9213223528590618\n",
      "epochs =  12 , step =  38000 , current loss_val =  0.953934433811544\n",
      "epochs =  12 , step =  39000 , current loss_val =  0.8504869349676287\n",
      "epochs =  12 , step =  40000 , current loss_val =  3.983089742430112\n",
      "epochs =  12 , step =  41000 , current loss_val =  0.9758521125058474\n",
      "epochs =  12 , step =  42000 , current loss_val =  1.0359540532943008\n",
      "epochs =  12 , step =  43000 , current loss_val =  1.0014894998944484\n",
      "epochs =  12 , step =  44000 , current loss_val =  0.8831553001161863\n",
      "epochs =  12 , step =  45000 , current loss_val =  0.9679412642430201\n",
      "epochs =  12 , step =  46000 , current loss_val =  0.8695864631973134\n",
      "epochs =  12 , step =  47000 , current loss_val =  0.8145187077291354\n",
      "epochs =  13 , step =  0 , current loss_val =  0.9756234224166636\n",
      "epochs =  13 , step =  1000 , current loss_val =  0.80536796053651\n",
      "epochs =  13 , step =  2000 , current loss_val =  0.8217961756729086\n",
      "epochs =  13 , step =  3000 , current loss_val =  0.9967198140742187\n",
      "epochs =  13 , step =  4000 , current loss_val =  0.8553747612032376\n",
      "epochs =  13 , step =  5000 , current loss_val =  1.0139052974623661\n",
      "epochs =  13 , step =  6000 , current loss_val =  1.0164674056245169\n",
      "epochs =  13 , step =  7000 , current loss_val =  0.9390516582810359\n",
      "epochs =  13 , step =  8000 , current loss_val =  0.9977970957006334\n",
      "epochs =  13 , step =  9000 , current loss_val =  0.8905996330937332\n",
      "epochs =  13 , step =  10000 , current loss_val =  0.9143101380295247\n",
      "epochs =  13 , step =  11000 , current loss_val =  1.0801171620432144\n",
      "epochs =  13 , step =  12000 , current loss_val =  0.8647363696574898\n",
      "epochs =  13 , step =  13000 , current loss_val =  0.9462859534273534\n",
      "epochs =  13 , step =  14000 , current loss_val =  0.9626063761770053\n",
      "epochs =  13 , step =  15000 , current loss_val =  0.8957260464446928\n",
      "epochs =  13 , step =  16000 , current loss_val =  1.8436850260766726\n",
      "epochs =  13 , step =  17000 , current loss_val =  0.9510563443319769\n",
      "epochs =  13 , step =  18000 , current loss_val =  1.0555844906165113\n",
      "epochs =  13 , step =  19000 , current loss_val =  0.9097072761378073\n",
      "epochs =  13 , step =  20000 , current loss_val =  0.9510359794857414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  13 , step =  21000 , current loss_val =  1.0003285835650935\n",
      "epochs =  13 , step =  22000 , current loss_val =  0.9340733175512242\n",
      "epochs =  13 , step =  23000 , current loss_val =  0.8660387555422485\n",
      "epochs =  13 , step =  24000 , current loss_val =  0.9387243783357003\n",
      "epochs =  13 , step =  25000 , current loss_val =  0.982208740953725\n",
      "epochs =  13 , step =  26000 , current loss_val =  0.9549734146083758\n",
      "epochs =  13 , step =  27000 , current loss_val =  0.961876113702169\n",
      "epochs =  13 , step =  28000 , current loss_val =  0.9634613008564663\n",
      "epochs =  13 , step =  29000 , current loss_val =  0.8992344079608675\n",
      "epochs =  13 , step =  30000 , current loss_val =  0.9954262421850224\n",
      "epochs =  13 , step =  31000 , current loss_val =  0.9030026535427267\n",
      "epochs =  13 , step =  32000 , current loss_val =  0.8917162960554996\n",
      "epochs =  13 , step =  33000 , current loss_val =  0.862759556607229\n",
      "epochs =  13 , step =  34000 , current loss_val =  0.9576815251285968\n",
      "epochs =  13 , step =  35000 , current loss_val =  0.865927020242979\n",
      "epochs =  13 , step =  36000 , current loss_val =  0.9197574378466928\n",
      "epochs =  13 , step =  37000 , current loss_val =  0.9405580229916853\n",
      "epochs =  13 , step =  38000 , current loss_val =  0.9682852836910836\n",
      "epochs =  13 , step =  39000 , current loss_val =  0.8696489785200012\n",
      "epochs =  13 , step =  40000 , current loss_val =  3.9850229375712414\n",
      "epochs =  13 , step =  41000 , current loss_val =  0.9790486029427563\n",
      "epochs =  13 , step =  42000 , current loss_val =  1.0433621775681203\n",
      "epochs =  13 , step =  43000 , current loss_val =  1.0114999471048907\n",
      "epochs =  13 , step =  44000 , current loss_val =  0.8917186136646134\n",
      "epochs =  13 , step =  45000 , current loss_val =  0.968999028109209\n",
      "epochs =  13 , step =  46000 , current loss_val =  0.8890252716978806\n",
      "epochs =  13 , step =  47000 , current loss_val =  0.8248906615708125\n",
      "epochs =  14 , step =  0 , current loss_val =  0.9849932635027774\n",
      "epochs =  14 , step =  1000 , current loss_val =  0.8125719334836587\n",
      "epochs =  14 , step =  2000 , current loss_val =  0.8305748446739293\n",
      "epochs =  14 , step =  3000 , current loss_val =  0.9972580234517916\n",
      "epochs =  14 , step =  4000 , current loss_val =  0.8623403938227101\n",
      "epochs =  14 , step =  5000 , current loss_val =  1.0208757194261275\n",
      "epochs =  14 , step =  6000 , current loss_val =  1.0294467457521523\n",
      "epochs =  14 , step =  7000 , current loss_val =  0.951485536286472\n",
      "epochs =  14 , step =  8000 , current loss_val =  1.0117308535881584\n",
      "epochs =  14 , step =  9000 , current loss_val =  0.9090303752621071\n",
      "epochs =  14 , step =  10000 , current loss_val =  0.921383547268084\n",
      "epochs =  14 , step =  11000 , current loss_val =  0.9217834116947627\n",
      "epochs =  14 , step =  12000 , current loss_val =  0.8693579353081949\n",
      "epochs =  14 , step =  13000 , current loss_val =  0.9557706857719951\n",
      "epochs =  14 , step =  14000 , current loss_val =  0.9736662791844405\n",
      "epochs =  14 , step =  15000 , current loss_val =  0.9043616944094205\n",
      "epochs =  14 , step =  16000 , current loss_val =  1.5940326883793414\n",
      "epochs =  14 , step =  17000 , current loss_val =  0.9604512735929294\n",
      "epochs =  14 , step =  18000 , current loss_val =  1.063877651241838\n",
      "epochs =  14 , step =  19000 , current loss_val =  0.9114460137490225\n",
      "epochs =  14 , step =  20000 , current loss_val =  0.9689721545477856\n",
      "epochs =  14 , step =  21000 , current loss_val =  1.0061626377248447\n",
      "epochs =  14 , step =  22000 , current loss_val =  0.9424229479530909\n",
      "epochs =  14 , step =  23000 , current loss_val =  0.8785707765992046\n",
      "epochs =  14 , step =  24000 , current loss_val =  0.9452421702851317\n",
      "epochs =  14 , step =  25000 , current loss_val =  0.9980330238930146\n",
      "epochs =  14 , step =  26000 , current loss_val =  0.9587324600557439\n",
      "epochs =  14 , step =  27000 , current loss_val =  0.9634150387923844\n",
      "epochs =  14 , step =  28000 , current loss_val =  0.9735806124754732\n",
      "epochs =  14 , step =  29000 , current loss_val =  0.9143991368492853\n",
      "epochs =  14 , step =  30000 , current loss_val =  1.0066296329063371\n",
      "epochs =  14 , step =  31000 , current loss_val =  0.9136268118727457\n",
      "epochs =  14 , step =  32000 , current loss_val =  0.8947936491105375\n",
      "epochs =  14 , step =  33000 , current loss_val =  0.8668766022545134\n",
      "epochs =  14 , step =  34000 , current loss_val =  0.969660866224947\n",
      "epochs =  14 , step =  35000 , current loss_val =  0.8729244971199991\n",
      "epochs =  14 , step =  36000 , current loss_val =  0.9311528062286991\n",
      "epochs =  14 , step =  37000 , current loss_val =  0.9588500516490315\n",
      "epochs =  14 , step =  38000 , current loss_val =  0.9803877738992001\n",
      "epochs =  14 , step =  39000 , current loss_val =  0.8888555407531177\n",
      "epochs =  14 , step =  40000 , current loss_val =  3.912902394688704\n",
      "epochs =  14 , step =  41000 , current loss_val =  0.9847190519488116\n",
      "epochs =  14 , step =  42000 , current loss_val =  1.0512383677252175\n",
      "epochs =  14 , step =  43000 , current loss_val =  1.022239482773701\n",
      "epochs =  14 , step =  44000 , current loss_val =  0.9005795956330744\n",
      "epochs =  14 , step =  45000 , current loss_val =  0.9746986786718996\n",
      "epochs =  14 , step =  46000 , current loss_val =  0.907195577417253\n",
      "epochs =  14 , step =  47000 , current loss_val =  0.8367224714954505\n",
      "epochs =  15 , step =  0 , current loss_val =  0.9943067150424102\n",
      "epochs =  15 , step =  1000 , current loss_val =  0.8182478888909648\n",
      "epochs =  15 , step =  2000 , current loss_val =  0.8395856041695176\n",
      "epochs =  15 , step =  3000 , current loss_val =  0.995816977617914\n",
      "epochs =  15 , step =  4000 , current loss_val =  0.869782900793239\n",
      "epochs =  15 , step =  5000 , current loss_val =  1.0330819013792636\n",
      "epochs =  15 , step =  6000 , current loss_val =  1.0424760944746885\n",
      "epochs =  15 , step =  7000 , current loss_val =  0.9629945055804847\n",
      "epochs =  15 , step =  8000 , current loss_val =  1.0259564321734185\n",
      "epochs =  15 , step =  9000 , current loss_val =  0.9225670355570121\n",
      "epochs =  15 , step =  10000 , current loss_val =  0.9286962120901294\n",
      "epochs =  15 , step =  11000 , current loss_val =  0.9201114344328825\n",
      "epochs =  15 , step =  12000 , current loss_val =  0.8708151816644386\n",
      "epochs =  15 , step =  13000 , current loss_val =  0.9671588651690735\n",
      "epochs =  15 , step =  14000 , current loss_val =  0.9811861251270703\n",
      "epochs =  15 , step =  15000 , current loss_val =  0.91479019130827\n",
      "epochs =  15 , step =  16000 , current loss_val =  1.4237074478474945\n",
      "epochs =  15 , step =  17000 , current loss_val =  0.9712048276705139\n",
      "epochs =  15 , step =  18000 , current loss_val =  1.07565453333715\n",
      "epochs =  15 , step =  19000 , current loss_val =  0.9150188568449166\n",
      "epochs =  15 , step =  20000 , current loss_val =  0.9830868680113425\n",
      "epochs =  15 , step =  21000 , current loss_val =  1.0098439298367592\n",
      "epochs =  15 , step =  22000 , current loss_val =  0.950387746646412\n",
      "epochs =  15 , step =  23000 , current loss_val =  0.8895312469842893\n",
      "epochs =  15 , step =  24000 , current loss_val =  0.9519930245475963\n",
      "epochs =  15 , step =  25000 , current loss_val =  1.0110202190993647\n",
      "epochs =  15 , step =  26000 , current loss_val =  0.9580081743936935\n",
      "epochs =  15 , step =  27000 , current loss_val =  0.9661160206393177\n",
      "epochs =  15 , step =  28000 , current loss_val =  0.9827026607343227\n",
      "epochs =  15 , step =  29000 , current loss_val =  0.9276547588825078\n",
      "epochs =  15 , step =  30000 , current loss_val =  1.0195724850787582\n",
      "epochs =  15 , step =  31000 , current loss_val =  0.9228954338907218\n",
      "epochs =  15 , step =  32000 , current loss_val =  0.8971600391519627\n",
      "epochs =  15 , step =  33000 , current loss_val =  0.8735545027658833\n",
      "epochs =  15 , step =  34000 , current loss_val =  0.982336519476948\n",
      "epochs =  15 , step =  35000 , current loss_val =  0.8792848910134\n",
      "epochs =  15 , step =  36000 , current loss_val =  0.9431864398009691\n",
      "epochs =  15 , step =  37000 , current loss_val =  0.9731040847852738\n",
      "epochs =  15 , step =  38000 , current loss_val =  0.9895982620285014\n",
      "epochs =  15 , step =  39000 , current loss_val =  0.9071683307190501\n",
      "epochs =  15 , step =  40000 , current loss_val =  3.8041655501279537\n",
      "epochs =  15 , step =  41000 , current loss_val =  0.9934298078619513\n",
      "epochs =  15 , step =  42000 , current loss_val =  1.0601447992988833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  15 , step =  43000 , current loss_val =  1.03321560793516\n",
      "epochs =  15 , step =  44000 , current loss_val =  0.9095997195465314\n",
      "epochs =  15 , step =  45000 , current loss_val =  0.9817197556574976\n",
      "epochs =  15 , step =  46000 , current loss_val =  0.9245130022278208\n",
      "epochs =  15 , step =  47000 , current loss_val =  0.8475893286373191\n",
      "epochs =  16 , step =  0 , current loss_val =  1.0027504926075268\n",
      "epochs =  16 , step =  1000 , current loss_val =  0.8247834507593954\n",
      "epochs =  16 , step =  2000 , current loss_val =  0.8485523025327746\n",
      "epochs =  16 , step =  3000 , current loss_val =  0.9892388956170545\n",
      "epochs =  16 , step =  4000 , current loss_val =  0.8779965111234033\n",
      "epochs =  16 , step =  5000 , current loss_val =  1.0432649738094264\n",
      "epochs =  16 , step =  6000 , current loss_val =  1.0542551775792068\n",
      "epochs =  16 , step =  7000 , current loss_val =  0.9732701217634998\n",
      "epochs =  16 , step =  8000 , current loss_val =  1.040493867276477\n",
      "epochs =  16 , step =  9000 , current loss_val =  0.9306375815606185\n",
      "epochs =  16 , step =  10000 , current loss_val =  0.9359351743556621\n",
      "epochs =  16 , step =  11000 , current loss_val =  0.9562630163169881\n",
      "epochs =  16 , step =  12000 , current loss_val =  0.8723571619060421\n",
      "epochs =  16 , step =  13000 , current loss_val =  0.9814460317769227\n",
      "epochs =  16 , step =  14000 , current loss_val =  0.985138323732304\n",
      "epochs =  16 , step =  15000 , current loss_val =  0.9244799450203465\n",
      "epochs =  16 , step =  16000 , current loss_val =  1.2886839867656297\n",
      "epochs =  16 , step =  17000 , current loss_val =  0.9815797828476789\n",
      "epochs =  16 , step =  18000 , current loss_val =  1.0921326567174803\n",
      "epochs =  16 , step =  19000 , current loss_val =  0.923736206536743\n",
      "epochs =  16 , step =  20000 , current loss_val =  0.996741231056355\n",
      "epochs =  16 , step =  21000 , current loss_val =  1.018426643713445\n",
      "epochs =  16 , step =  22000 , current loss_val =  0.9591433813198399\n",
      "epochs =  16 , step =  23000 , current loss_val =  0.8986923896049739\n",
      "epochs =  16 , step =  24000 , current loss_val =  0.958187049600426\n",
      "epochs =  16 , step =  25000 , current loss_val =  1.0209597932362537\n",
      "epochs =  16 , step =  26000 , current loss_val =  0.9558980175549251\n",
      "epochs =  16 , step =  27000 , current loss_val =  0.9678286566933204\n",
      "epochs =  16 , step =  28000 , current loss_val =  0.9905115954910091\n",
      "epochs =  16 , step =  29000 , current loss_val =  0.9407152102105844\n",
      "epochs =  16 , step =  30000 , current loss_val =  1.0361284002158095\n",
      "epochs =  16 , step =  31000 , current loss_val =  0.9304334733892439\n",
      "epochs =  16 , step =  32000 , current loss_val =  0.8999763997149189\n",
      "epochs =  16 , step =  33000 , current loss_val =  0.8806544267709782\n",
      "epochs =  16 , step =  34000 , current loss_val =  0.995958063991244\n",
      "epochs =  16 , step =  35000 , current loss_val =  0.8861524986716784\n",
      "epochs =  16 , step =  36000 , current loss_val =  0.9553343915718728\n",
      "epochs =  16 , step =  37000 , current loss_val =  0.9825143110106254\n",
      "epochs =  16 , step =  38000 , current loss_val =  1.0005678427929718\n",
      "epochs =  16 , step =  39000 , current loss_val =  0.9247107405518666\n",
      "epochs =  16 , step =  40000 , current loss_val =  3.6401039417390924\n",
      "epochs =  16 , step =  41000 , current loss_val =  1.0043179759822811\n",
      "epochs =  16 , step =  42000 , current loss_val =  1.0685406072474115\n",
      "epochs =  16 , step =  43000 , current loss_val =  1.0437077810113056\n",
      "epochs =  16 , step =  44000 , current loss_val =  0.9170483771354421\n",
      "epochs =  16 , step =  45000 , current loss_val =  0.9896892058325714\n",
      "epochs =  16 , step =  46000 , current loss_val =  0.9414491131610558\n",
      "epochs =  16 , step =  47000 , current loss_val =  0.8572834411091302\n",
      "epochs =  17 , step =  0 , current loss_val =  1.0106253441481337\n",
      "epochs =  17 , step =  1000 , current loss_val =  0.8318064730926332\n",
      "epochs =  17 , step =  2000 , current loss_val =  0.8581951693750649\n",
      "epochs =  17 , step =  3000 , current loss_val =  0.9753639093857622\n",
      "epochs =  17 , step =  4000 , current loss_val =  0.8875771204427405\n",
      "epochs =  17 , step =  5000 , current loss_val =  1.0535537455141624\n",
      "epochs =  17 , step =  6000 , current loss_val =  1.064611455412095\n",
      "epochs =  17 , step =  7000 , current loss_val =  0.9818065020308778\n",
      "epochs =  17 , step =  8000 , current loss_val =  1.0549511918108327\n",
      "epochs =  17 , step =  9000 , current loss_val =  0.9362303759268131\n",
      "epochs =  17 , step =  10000 , current loss_val =  0.9435020202190944\n",
      "epochs =  17 , step =  11000 , current loss_val =  0.974773991900641\n",
      "epochs =  17 , step =  12000 , current loss_val =  0.8776283782034987\n",
      "epochs =  17 , step =  13000 , current loss_val =  0.9974616242035683\n",
      "epochs =  17 , step =  14000 , current loss_val =  0.9899245603634618\n",
      "epochs =  17 , step =  15000 , current loss_val =  0.934977114089816\n",
      "epochs =  17 , step =  16000 , current loss_val =  1.2029065227992684\n",
      "epochs =  17 , step =  17000 , current loss_val =  0.9896926774707689\n",
      "epochs =  17 , step =  18000 , current loss_val =  1.1168220782178078\n",
      "epochs =  17 , step =  19000 , current loss_val =  0.9373153678408509\n",
      "epochs =  17 , step =  20000 , current loss_val =  1.010067262972784\n",
      "epochs =  17 , step =  21000 , current loss_val =  1.0298096633567588\n",
      "epochs =  17 , step =  22000 , current loss_val =  0.9690118216686706\n",
      "epochs =  17 , step =  23000 , current loss_val =  0.906138563602519\n",
      "epochs =  17 , step =  24000 , current loss_val =  0.9642767705809141\n",
      "epochs =  17 , step =  25000 , current loss_val =  1.030857964677943\n",
      "epochs =  17 , step =  26000 , current loss_val =  0.9603970204209574\n",
      "epochs =  17 , step =  27000 , current loss_val =  0.9698294756008131\n",
      "epochs =  17 , step =  28000 , current loss_val =  0.9969600520964613\n",
      "epochs =  17 , step =  29000 , current loss_val =  0.9519546018875596\n",
      "epochs =  17 , step =  30000 , current loss_val =  1.0532595301045788\n",
      "epochs =  17 , step =  31000 , current loss_val =  0.9361158584300646\n",
      "epochs =  17 , step =  32000 , current loss_val =  0.9046000324190182\n",
      "epochs =  17 , step =  33000 , current loss_val =  0.8861286252661582\n",
      "epochs =  17 , step =  34000 , current loss_val =  1.0082692988953883\n",
      "epochs =  17 , step =  35000 , current loss_val =  0.8936528119377448\n",
      "epochs =  17 , step =  36000 , current loss_val =  0.9666793211502398\n",
      "epochs =  17 , step =  37000 , current loss_val =  0.9880555644080308\n",
      "epochs =  17 , step =  38000 , current loss_val =  1.0100209563707667\n",
      "epochs =  17 , step =  39000 , current loss_val =  0.940574999471006\n",
      "epochs =  17 , step =  40000 , current loss_val =  3.3971348037405513\n",
      "epochs =  17 , step =  41000 , current loss_val =  1.015812340464324\n",
      "epochs =  17 , step =  42000 , current loss_val =  1.0761730711727318\n",
      "epochs =  17 , step =  43000 , current loss_val =  1.054012755086775\n",
      "epochs =  17 , step =  44000 , current loss_val =  0.9238156658891525\n",
      "epochs =  17 , step =  45000 , current loss_val =  0.9986301962029177\n",
      "epochs =  17 , step =  46000 , current loss_val =  0.9556350073522291\n",
      "epochs =  17 , step =  47000 , current loss_val =  0.8662955501401194\n",
      "epochs =  18 , step =  0 , current loss_val =  1.0180546545120284\n",
      "epochs =  18 , step =  1000 , current loss_val =  0.8385323566170901\n",
      "epochs =  18 , step =  2000 , current loss_val =  0.868975013881801\n",
      "epochs =  18 , step =  3000 , current loss_val =  0.958492594982379\n",
      "epochs =  18 , step =  4000 , current loss_val =  0.8969491578523696\n",
      "epochs =  18 , step =  5000 , current loss_val =  1.063645847189019\n",
      "epochs =  18 , step =  6000 , current loss_val =  1.0739916696451066\n",
      "epochs =  18 , step =  7000 , current loss_val =  0.9908756916161494\n",
      "epochs =  18 , step =  8000 , current loss_val =  1.0693099102837826\n",
      "epochs =  18 , step =  9000 , current loss_val =  0.9426014727374561\n",
      "epochs =  18 , step =  10000 , current loss_val =  0.9517474057246345\n",
      "epochs =  18 , step =  11000 , current loss_val =  0.9842041920947284\n",
      "epochs =  18 , step =  12000 , current loss_val =  0.8845541686028323\n",
      "epochs =  18 , step =  13000 , current loss_val =  1.012948475289464\n",
      "epochs =  18 , step =  14000 , current loss_val =  0.9940108098066345\n",
      "epochs =  18 , step =  15000 , current loss_val =  0.9454956753492999\n",
      "epochs =  18 , step =  16000 , current loss_val =  1.1577274104085065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  18 , step =  17000 , current loss_val =  0.9949787015604887\n",
      "epochs =  18 , step =  18000 , current loss_val =  1.1431054920898012\n",
      "epochs =  18 , step =  19000 , current loss_val =  0.9522116130865783\n",
      "epochs =  18 , step =  20000 , current loss_val =  1.0222958997930212\n",
      "epochs =  18 , step =  21000 , current loss_val =  1.041892214960781\n",
      "epochs =  18 , step =  22000 , current loss_val =  0.9792821105628692\n",
      "epochs =  18 , step =  23000 , current loss_val =  0.9122025459864983\n",
      "epochs =  18 , step =  24000 , current loss_val =  0.9696745580286554\n",
      "epochs =  18 , step =  25000 , current loss_val =  1.0401161683193192\n",
      "epochs =  18 , step =  26000 , current loss_val =  0.9726147250403181\n",
      "epochs =  18 , step =  27000 , current loss_val =  0.9752585310036426\n",
      "epochs =  18 , step =  28000 , current loss_val =  1.0034828362019579\n",
      "epochs =  18 , step =  29000 , current loss_val =  0.9610372771987798\n",
      "epochs =  18 , step =  30000 , current loss_val =  1.0701061990489287\n",
      "epochs =  18 , step =  31000 , current loss_val =  0.941270163656754\n",
      "epochs =  18 , step =  32000 , current loss_val =  0.9120715242907635\n",
      "epochs =  18 , step =  33000 , current loss_val =  0.8896830884635459\n",
      "epochs =  18 , step =  34000 , current loss_val =  1.018628569459076\n",
      "epochs =  18 , step =  35000 , current loss_val =  0.8999374350875704\n",
      "epochs =  18 , step =  36000 , current loss_val =  0.9760967368700798\n",
      "epochs =  18 , step =  37000 , current loss_val =  0.9909464549075939\n",
      "epochs =  18 , step =  38000 , current loss_val =  1.016502620373294\n",
      "epochs =  18 , step =  39000 , current loss_val =  0.9543669267902097\n",
      "epochs =  18 , step =  40000 , current loss_val =  3.0437914946358906\n",
      "epochs =  18 , step =  41000 , current loss_val =  1.0274780191604684\n",
      "epochs =  18 , step =  42000 , current loss_val =  1.0830753461630114\n",
      "epochs =  18 , step =  43000 , current loss_val =  1.0648152675437204\n",
      "epochs =  18 , step =  44000 , current loss_val =  0.9318140175751752\n",
      "epochs =  18 , step =  45000 , current loss_val =  1.0063779176393732\n",
      "epochs =  18 , step =  46000 , current loss_val =  0.9649739568644637\n",
      "epochs =  18 , step =  47000 , current loss_val =  0.8741596226397845\n",
      "epochs =  19 , step =  0 , current loss_val =  1.0261642162327513\n",
      "epochs =  19 , step =  1000 , current loss_val =  0.8449640908182243\n",
      "epochs =  19 , step =  2000 , current loss_val =  0.8785124719554374\n",
      "epochs =  19 , step =  3000 , current loss_val =  0.9465220395758482\n",
      "epochs =  19 , step =  4000 , current loss_val =  0.9050350225669539\n",
      "epochs =  19 , step =  5000 , current loss_val =  1.0730228676224036\n",
      "epochs =  19 , step =  6000 , current loss_val =  1.0826234911478827\n",
      "epochs =  19 , step =  7000 , current loss_val =  1.0011045962594842\n",
      "epochs =  19 , step =  8000 , current loss_val =  1.0841842010924385\n",
      "epochs =  19 , step =  9000 , current loss_val =  0.9489325770673851\n",
      "epochs =  19 , step =  10000 , current loss_val =  0.9607889259826508\n",
      "epochs =  19 , step =  11000 , current loss_val =  0.9928286437181005\n",
      "epochs =  19 , step =  12000 , current loss_val =  0.8921741178516194\n",
      "epochs =  19 , step =  13000 , current loss_val =  1.0252975614738917\n",
      "epochs =  19 , step =  14000 , current loss_val =  0.9965880767197735\n",
      "epochs =  19 , step =  15000 , current loss_val =  0.9541960658245686\n",
      "epochs =  19 , step =  16000 , current loss_val =  1.138326173727976\n",
      "epochs =  19 , step =  17000 , current loss_val =  0.9981518163465114\n",
      "epochs =  19 , step =  18000 , current loss_val =  1.1589090179377528\n",
      "epochs =  19 , step =  19000 , current loss_val =  0.965080297305316\n",
      "epochs =  19 , step =  20000 , current loss_val =  1.0332576374507814\n",
      "epochs =  19 , step =  21000 , current loss_val =  1.0542582484135261\n",
      "epochs =  19 , step =  22000 , current loss_val =  0.9880112777478948\n",
      "epochs =  19 , step =  23000 , current loss_val =  0.9183065066413301\n",
      "epochs =  19 , step =  24000 , current loss_val =  0.9750636459694505\n",
      "epochs =  19 , step =  25000 , current loss_val =  1.0474772565372548\n",
      "epochs =  19 , step =  26000 , current loss_val =  0.9855032350186161\n",
      "epochs =  19 , step =  27000 , current loss_val =  0.9820577428376116\n",
      "epochs =  19 , step =  28000 , current loss_val =  1.0107645569623567\n",
      "epochs =  19 , step =  29000 , current loss_val =  0.968714923029598\n",
      "epochs =  19 , step =  30000 , current loss_val =  1.085735140143163\n",
      "epochs =  19 , step =  31000 , current loss_val =  0.944820841761416\n",
      "epochs =  19 , step =  32000 , current loss_val =  0.9185119996640628\n",
      "epochs =  19 , step =  33000 , current loss_val =  0.8893067164312882\n",
      "epochs =  19 , step =  34000 , current loss_val =  1.0289713570264853\n",
      "epochs =  19 , step =  35000 , current loss_val =  0.9049446637720742\n",
      "epochs =  19 , step =  36000 , current loss_val =  0.9828283415468171\n",
      "epochs =  19 , step =  37000 , current loss_val =  0.9945325939967892\n",
      "epochs =  19 , step =  38000 , current loss_val =  1.0209275323107212\n",
      "epochs =  19 , step =  39000 , current loss_val =  0.9664394282046175\n",
      "epochs =  19 , step =  40000 , current loss_val =  2.7245665054928336\n",
      "epochs =  19 , step =  41000 , current loss_val =  1.0368615378184172\n",
      "epochs =  19 , step =  42000 , current loss_val =  1.0900453810517745\n",
      "epochs =  19 , step =  43000 , current loss_val =  1.0752510064620244\n",
      "epochs =  19 , step =  44000 , current loss_val =  0.9405421465516628\n",
      "epochs =  19 , step =  45000 , current loss_val =  1.0130659470271812\n",
      "epochs =  19 , step =  46000 , current loss_val =  0.9726378544706535\n",
      "epochs =  19 , step =  47000 , current loss_val =  0.8805891245224683\n",
      "epochs =  20 , step =  0 , current loss_val =  1.0359694517445497\n",
      "epochs =  20 , step =  1000 , current loss_val =  0.8517830355762342\n",
      "epochs =  20 , step =  2000 , current loss_val =  0.8845140205802459\n",
      "epochs =  20 , step =  3000 , current loss_val =  0.9416643861445642\n",
      "epochs =  20 , step =  4000 , current loss_val =  0.9122788670061328\n",
      "epochs =  20 , step =  5000 , current loss_val =  1.080929063062375\n",
      "epochs =  20 , step =  6000 , current loss_val =  1.0918617127566845\n",
      "epochs =  20 , step =  7000 , current loss_val =  1.010895246190934\n",
      "epochs =  20 , step =  8000 , current loss_val =  1.0989376233385513\n",
      "epochs =  20 , step =  9000 , current loss_val =  0.9573025500998054\n",
      "epochs =  20 , step =  10000 , current loss_val =  0.9688577100926222\n",
      "epochs =  20 , step =  11000 , current loss_val =  1.0004088680709866\n",
      "epochs =  20 , step =  12000 , current loss_val =  0.9009475639058903\n",
      "epochs =  20 , step =  13000 , current loss_val =  1.0361484134183419\n",
      "epochs =  20 , step =  14000 , current loss_val =  0.999577284846339\n",
      "epochs =  20 , step =  15000 , current loss_val =  0.9635214755541543\n",
      "epochs =  20 , step =  16000 , current loss_val =  1.1326170942688845\n",
      "epochs =  20 , step =  17000 , current loss_val =  1.0011057269578487\n",
      "epochs =  20 , step =  18000 , current loss_val =  1.158000597668424\n",
      "epochs =  20 , step =  19000 , current loss_val =  0.9752724504861554\n",
      "epochs =  20 , step =  20000 , current loss_val =  1.0431245680247285\n",
      "epochs =  20 , step =  21000 , current loss_val =  1.0641073427107124\n",
      "epochs =  20 , step =  22000 , current loss_val =  0.9956126320212317\n",
      "epochs =  20 , step =  23000 , current loss_val =  0.9251301570649569\n",
      "epochs =  20 , step =  24000 , current loss_val =  0.9797559820554164\n",
      "epochs =  20 , step =  25000 , current loss_val =  1.0537046814791968\n",
      "epochs =  20 , step =  26000 , current loss_val =  0.9962951663879656\n",
      "epochs =  20 , step =  27000 , current loss_val =  0.9903474989952552\n",
      "epochs =  20 , step =  28000 , current loss_val =  1.0228059208646383\n",
      "epochs =  20 , step =  29000 , current loss_val =  0.9771655356365253\n",
      "epochs =  20 , step =  30000 , current loss_val =  1.1009392932746853\n",
      "epochs =  20 , step =  31000 , current loss_val =  0.9469594417044171\n",
      "epochs =  20 , step =  32000 , current loss_val =  0.9243003044846895\n",
      "epochs =  20 , step =  33000 , current loss_val =  0.8890908441732688\n",
      "epochs =  20 , step =  34000 , current loss_val =  1.0401076854555953\n",
      "epochs =  20 , step =  35000 , current loss_val =  0.9089015344487178\n",
      "epochs =  20 , step =  36000 , current loss_val =  0.9873042432040938\n",
      "epochs =  20 , step =  37000 , current loss_val =  0.9996225080837511\n",
      "epochs =  20 , step =  38000 , current loss_val =  1.0246219278398812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  20 , step =  39000 , current loss_val =  0.977851183759467\n",
      "epochs =  20 , step =  40000 , current loss_val =  2.5471512509443612\n",
      "epochs =  20 , step =  41000 , current loss_val =  1.0432190309282539\n",
      "epochs =  20 , step =  42000 , current loss_val =  1.0977325645399367\n",
      "epochs =  20 , step =  43000 , current loss_val =  1.0832686033874253\n",
      "epochs =  20 , step =  44000 , current loss_val =  0.9480667943916853\n",
      "epochs =  20 , step =  45000 , current loss_val =  1.021735739714861\n",
      "epochs =  20 , step =  46000 , current loss_val =  0.9833008686392541\n",
      "epochs =  20 , step =  47000 , current loss_val =  0.8863933216002168\n",
      "\n",
      "elapsed time =  0:15:16.054885\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameter\n",
    "i_nodes = training_data.shape[1] - 1    # input nodes 개수\n",
    "h1_nodes = 100     # hidden 1 nodes\n",
    "o_nodes = 10       # output nodes\n",
    "lr = 0.1           # learning rate\n",
    "epochs = 20         # epochs\n",
    "\n",
    "# 손실함수 값을 저장할 list 생성\n",
    "loss_val_list = []\n",
    "\n",
    "# 정확도 저장 리스트\n",
    "training_accuracy_list = []\n",
    "validation_accuracy_list = []\n",
    "\n",
    "# 객체 생성\n",
    "nn = NeuralNetwork(i_nodes, h1_nodes, o_nodes, lr)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):  # train\n",
    "    \n",
    "        # input_data, target_data normalize        \n",
    "        target_data = np.zeros(o_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i+1, \", step = \", step,  \", current loss_val = \", nn.loss_val())\n",
    "            \n",
    "        # 손실함수 값 저장 per step\n",
    "        loss_val_list.append(nn.loss_val())    \n",
    "        \n",
    "    # 정확도 계산 및 저장 per epochs\n",
    "    (training_accuracy, not_matched_list) = nn.accuracy(training_data[:, 1:], training_data[:, 0])\n",
    "    (validation_accuracy, not_matched_list) = nn.accuracy(validation_data[:, 1:], validation_data[:, 0])\n",
    "        \n",
    "    training_accuracy_list.append(training_accuracy)\n",
    "    validation_accuracy_list.append(validation_accuracy)\n",
    "        \n",
    "        \n",
    "end_time = datetime.now() \n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Training / Validation Accuracy Trend')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.plot(training_accuracy_list)\n",
    "plt.plot(validation_accuracy_list)\n",
    "plt.legend(['training acc', 'validation acc'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "test_data[0,0] =  7.0 , len(test_data[0]) =  785\n",
      "Accuracy =  97.4  %\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "test_input_data = test_data[ : , 1: ]\n",
    "test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))\n",
    "\n",
    "# measure accuracy\n",
    "(accuracy_ret, false_list) = nn.accuracy(test_input_data, test_target_data)   \n",
    "\n",
    "print('Accuracy = ', np.round(100*accuracy_ret, 3), ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZgcVbn48e+bfSULIWEJMoRNiReCRAUC3EZcEP2JCy4oiKgXveK96vUuuFxFUOEiIKIiCWtANgEjS0JW0tnIvq+TTDIzmUkmk8y+r31+f1RNpmfSa1VXVy/v53nmme7qqjqnuqrrrXPq1DlijEEppZRyaoDfGVBKKZXdNJAopZRyRQOJUkopVzSQKKWUckUDiVJKKVc0kCillHJFA4lSSRCRZ0Tk137nI9VEZKWIfMPvfKjspIFE+UJESkTko2lO83IRaRaR0RE+2ywi309nfsLS/qmINNl/bSLSHfZ+px95UioZGkhU3jDGrAbKgS+ETxeR9wMXAi/6lK/fGmNGGWNGAd8FVve8N8ZM7T+/iAxKfy6Vik4Dico4IvIvIlIkIjUi8oaInG5PFxH5vYgcFZF6EdlmBwFE5HoR2SUijSJySET+M8rqZwNf7zft68BcY0y1va5XROSIncZyETnhZG7P9w0RWdlvmhGRc+3XQ0XkARE5KCKVIvKYiAx38H0Mstf7PREpAvbY0y8UkcX297RHRL4QtsxfReQREXnb/k5Wi8jZYZ9fJyKF9jb+AZBk86VUDw0kKqOIyEeAe4EvAacBpcBL9scfB64GzgfGAl8Gqu3PngS+Y4wZDbwfeCdKEs8BV4nIe+z0BgBfBZ4Nm+dt4DxgIrAJeN7h5vyfnddpwLnAGcAvHK4L4DPAB4F/sqvnFmHleyLwNWCWiFwQNv9Xgf8FxgMHgXsARGQi8CpwJzABq5T2YRf5UnlOA4nKNF8DnjLGbDLGtAM/AS4XkQKgExgNvBcQY8xuY0yFvVwncKGInGSMqTXGbIq0cmNMGbAMuNmedC0wDJgbNs9TxphGO/27gItFZEwyGyEiAvwL8CNjTI0xphH4LfCVZNbTz2/tbWvFCip7jTHPGmO6jDEbgX8AN4bN/6oxZoMxphMrGE6zp38a2GKMmWN/9iBwzEW+VJ7TQKIyzelYpRAAjDFNWKWOM4wx7wB/Av4MVIrILBE5yZ71C8D1QKmILBORy2OkEV69dQvwgn1CRUQGish9IrJfRBqAEnu+CUluxynACGCjiNSJSB0w357uVFnY67OAGT3rttf/ZaxSXI8jYa9bgFH269PD12WMCWGVSpRyRAOJyjSHsU6SAIjISOBk4BCAMeYRY8ylwFSsaqP/sqevN8bcgFXN8w/gbzHS+DtwhohcA3yevtVaXwVuAD4KjAEKerISYT3NWMGiJ6+nhn1WBbQCU40xY+2/MfYNdafCu+ouA5aErXusfXM+kZZnFcCZYfkeAEx2kS+V5zSQKD8NFpFhYX+DgBeA20RkmogMxaoOWmuMKRGRD4rIh0VkMNZJvA3oFpEhIvI1ERljlywagO5oiRpjmrHuETwNlBpjNoR9PBpoxyoFjbDTj2YrMNXO6zCsarCeNELA48Dv7XsSiMgZIvKJpL6h6N6w0/6qiAy2/z7U7x5JNG8B00TkBvs7/xHuSkoqz2kgUX6ah3XV3vN3lzFmCdYN4tewrpzPofe+wklYJ+darOqvauAB+7NbgBK7Ouq79N4DiWY2Vsnn2X7Tn7XXfQjYBayJtgJjzF7gbmAxsA9Y2W+W/wGKgDV2vhYDiZzo4zLG1AOfwNrOCqxqrHuBoQksW4lVDfY7rO/wPcDaVORL5SfRga2UUkq5oSUSpZRSrmggUUop5YoGEqWUUq5oIFFKKeVKVnT+NmHCBFNQUOBo2ebmZkaOHJnaDGWRfN5+3fb83HbI7+0P3/aNGzdWGWM8b9qdFYGkoKCADRs2xJ8xgmAwSCAQSG2Gskg+b79ue8DvbPgmn7c/fNtFpDT23KmhVVtKKaVc0UCilFLKFQ0kSimlXNFAopRSyhUNJEoppVzRQKKUUsoVDSRKKaVc0UCilFJptK64hn2VjX5nI6Wy4oFEpZTKFV+auRqAkvs+5XNOUkdLJEpF8eO/beXGv7zrdzZUBqpsaKOrO+R3NjKGBhKV05rau+jocvaDf21TORtKax0tW9vcwdLCo46WVZmtoa2TD/92CXe9udPvrGQMDSQqp73/lwv46uNRR8v1zDdnr+e2p9fT2NaZ9rRVfMYYdh1ucLRsY1sXAO/s1guFHhpIVM5zWqpw48CxZgC6QzqUdSZ6dWM51z+ygiW7K/3OSk7QQKIyXm1zB8bkzwm5vLaFK+5dQnlti99ZyWi/W7CHgjvnEnIQrPccsVpNFVc1pzpbeUkDicpo5bUtXHLPImYtP+B3VtLmlQ3lHK5v45UN5X5nxXPrS2pYse+Yo2UfW2YdE6E8usjIVBpIVEYrr20FYMkerY/ORV98bDW3PLnO72xknO6QcdxIxA8aSJTKId0hww1/WsmWo11pS3NrWR1HG9vSll4+uOXJtZz/87f9zkbCNJCotGjr7PY7C3mhsa2TreX1PL693dHyuw43UJLkfYMb/ryK6x5eQVlNC2sOVDtKtztksuZ+RTru172739n36BcNJMpzr24s573/O58Dx5r8zoqK4/pHVhB4IJj0cjXNHVx1/1K+MstZU+vfL9rLNQ8EHR0jda2dXHL3QraU1TlK+509lRysTr5hg4hwqK7V0bIARUcbeWZVsaNlM40GEuW5hTuPALC3UgNJJgqFDA8t2kttc4dveVhXUgPA0cbkS1Lrimuobenkz0uLEl4mvFDxzWc2EHhgqaNlZ9z3Dlf/LvKygd8t5TvPbYi6nv/3x1Xc9eauhNPNZNrXVpoZY1iws5KPXTiJgQPE7+woxfJ9x3hkyT72H83fQO/F4z4l1S2UxCittOZQda+WSNJs7vYKvvvXjTy+Iruasz68eC8fuGeR39lQHuh5aDKXTmzxGBKLHAerW2jvyp/vxSkNJGl2zC66H6l31sql4M653D9/j6Nly2paOFzX6mjZhxfvo8bHqg8V27ztFRTcOff48aUSIxK9VqCpvYurf7eU/3l1WxpzlJ08CyQicqaILBWR3SKyU0R+YE8fLyKLRGSf/X+cV3nIVY8G9zta7qr7l3LFfe+kODcqEzy/thSAwhwb58JPPS0NV+yr8jknmc/LEkkX8GNjzPuAy4A7RORC4E5giTHmPGCJ/V6pvPfu/ioeDfbeMHZSba8PeffVHTK8vuWQo25U4olRmMk7ngUSY0yFMWaT/boR2A2cAdwAzLZnmw181qs8KJVNvvr4Wu6fX6gnqBR6bnUJP3hpCy+tL/M7KzktLa22RKQAuARYC0wyxlSAFWxEZGKUZW4HbgeYNGkSwWDQUdpNTU2Ol/VCUYnVrXh5eTnBoLM+hoCEtynS9rv5PpwsW1Vl3Q/auXMHw6qSu7+zp8aqXqivq0s67aamJsA6K6drmzu6DSLQ1WXt55UrVzFqSHKRoaSkBIDSkhKCwcMJLVNrdyWza5fVnNQYk3C+t9tPwVdX9z4El+5jpL7OegZky5YttB0cmNAyPQ8G7txpjQtSVVV1PO2e437jXuu+3oYdezi9tbeBS3m5dS+pqKi3BNg/3w3t1vo7Ojv6fHasxeq6pK2t9z5nrG2O9324WTYSP855ngcSERkFvAb80BjTEOvmVjhjzCxgFsD06dNNIBBwlH4wGMTpsl4oXlUMe3YxefJkAoGpya9g/lyAhLepz/YnuaybdMO9cHADHK1k6tT3E3j/qUktO+xANaxbw5ixYwkELk9qWevHZD0tna5tLrhzLqeMHsqgQYOhs5Mrr5zB2BFDkkqvoKAAivZxVkEBgcD5CS36eNEaqK7mwgsvhK2bEZGE8929uxI2beDkk0+GY1afZkl9X3a+ezhZdszYsVBbw7Rp07hsysl9ZllaeJSZy/bzwrcvY0BYk3lZOA+MYerUqbBlExMmTCAQmA70Hvcb2gvhQBFnF5xNIHDe8WWDDTuhtITzzj0X9uyKmO+qpnZYupghg4f0+ayspgWWL2XYsGHQ2hp9m6MdP4l8Xy5+b36c8zwNJCIyGCuIPG+M+bs9uVJETrNLI6cB2htf3siPCvxjje2MGT7Y72zkjDue30RLRzetnd2MHOr/o296H+pEXrbaEuBJYLcx5qGwj94AbrVf3wq87lUevBIKGRp05LuEaZ1/+mTqOa62uYOjDd527JjuE7we1728bLU1A7gF+IiIbLH/rgfuAz4mIvuAj9nvs8qDiwq56K6F1LdoMMlFb2497Pg5H78ImX1Wu+SeRXzot0uiz+AiCLjZcifBINGHGfOJZ+VEY8xKou/ja71KNx3e2lYBQG1LB2NGaBVGLmnr7ObfXtzMlAkj/c5KXsrscNhXpgfvdNIn25UK01M9crjeWQ8AfvOyi/OCO+fy0znbPVt/OuXT0M3poIFEqRzk1bXyC2sPerRmb0ULG5lQpsiFoKaBRKk80drRzY1/eZfdFQ1+ZyVt9IZ4emggUTmnrKaFC38xnyPN2TPmdUQRrlSNMVQ3OeuYcX1JDRtKa/ntvN1uc6ZUHxpI0iwHSrEZ742th2np6GblofSNW55KsW7izn63hEt/vZj9Otqkb3p+w1ra6aWBJIvkQl2qslqGOe2SP7jX6lan//CuPSc1PUS81/MVaxzppYFEpY2Tk5xfJ8ZUpRtpPV97Yq3ng4TpSS62ZHavxub4NJCkWT4elKlob5+uE2OqqitirWdjaW1qElGO9VZPRd9RGowTp4HEJ1q/mt2MMRlZ1ZjLT13H37Lktz0TfocZeBglTQOJCzmw/zPW82tLKbhzLp3dVsurTPuu3//LBVz74DK/sxFdBpwgUyXepmRCMMh3Gkgc0OPWew8t3AtAY5vzlldeXuk1d3RzoKrZuwRUSuXCVX8m00DiQiZWbaj8lq2HpFdVcj0Xfalcv/7uT6SBxIFEB+dKNT1+Va5L+W/Lw9+qX+eBTKSBJAvp8Zsaaw9UUxvleY5MiNmZkIdMkiklgczIRWbRQKLyUihk+PKsNdz85Fq/s3ICvVDoy4sr/1RUdelu6uX/uJUqZ72yoazPAFGZeCW3K8c6MMyQi/aMd/w5En+zAWTm7yJZGkiUZ/7r1W0AfPL9p/qck/yTCSfIrOBj8U8kdwK/Vm0pz/nWzYk/ySqVdzSQqLTJtm5OspEGz8hSeTGTK6WIVNJAkmZuWp7o8ZtGWfZla1PUyCd4T78V/cqP00DigptzjZuODPX4tdS3dnLb0+s42tgWf+YE6fk4c0X/velO85sGEgeSPWyb2rt4YEHh8X6jssnrWw6xvbze72xE9MqGMpYWHmPmsgN+Z0V5yIswkWUFzoynrbbS4MGFhTy9qoT3jB/hd1aS9oOXtvidBaU84yxIpTYMWdXd2V2q0hKJC4ne7mjrtEoinaHsK5H4LZe7RfdCup/+bu3odrxsY1vn8dfJZrurO0R3yPm2vrD2YMLz9v9O520/Ajg79a8rrjn+OrtDR18aSJyIcAT8bX0ZU38x39XBHc228jraOp3/YLOR3qtI7uS63B6Ct1fiX+C3Zm9IPKF+rrr/HcfLfu/5TSdMS3S/v7Au8UDQX0tHb4/SsdKL1oDhoUV7Haf9pZmrHS+byTSQpMgv39hJc0c37V2pPeEfqW/jM39axU//vt3R8sYYZi7bT1VTe0rz5SgvaUqno8t5ya/JRbf1hUcaHS+7dM/R46+TjaE7DvXew0p3+a2qydnY8wDbDzm/91bf0hl/pihSda2nLeV66T2SDNdT/N92qN5RtUVJQ4h7V+9hZVFVqrOWsGR/b60d3a5OUA8v3ud42Ut/vRiADgcNIz7x8HLH6b6ysczxsi3h1UtaExiRfi3e0hKJT5I9uRYdbTr+Y0jmSuhXq62msU4GiAqvw07WgWNNCc1X19LBwp1H+kxzc1JVFr1Ytuj3kB4aSBK041A9jwaLXK3jZ3N2uFr+3f3VQPpu0v3z74KOl/12gvXu33luI7c/t5Fjjb1Vb/rksEoXN89zueXB7VTfaNVWgj79x5UAfC9wrm95qGlO732OmihjdSSiO8FocLCmBSDqMzYaVFR8CRwkHhxIRUcTK3XHkwuHuJZIUkxPfBY3Y61HEuu6Mdp3rrsiv0Ta336WOPKJBpIkffe5jWHveg/dZOtiD9W28pfg/tRkKgO5Kc0o57LpuZu6JFteRb9I02DhNw0kSZq/80hKDtv5O4/wf/P3cKiulVDIMHdbBaEIlaapOi1kz+lFuZFJAzaljIcb89M5zprVq740kKRBrNKKMYbn1pRyxwub4rZW0mozldf0+M9YGkjCFB1t6vNwlxciBYPKBquJbqRnJyJ2jZ1Tl5u5zc25L93VVOnuXiVRkQ53/Q1kFm21FeajDy0DoOS+TyU0f6TfXaSfYob+PlOmoa2T9s4Qp4weGnO+XP8ewrk5z+XjSdLrQyNV63fzbFUu0xKJA5EeCEznb7+z2zDt7oUpa37o1ox73+GDv1kc9fO3dxyJ+lk8ITv65FEM8kw2fIdOfkfLTuhnLGx9EVbopgudZBsIJCIXLrA8CyQi8pSIHBWRHWHT7hKRQyKyxf673qv0c11dS2dSPZh6ebQ2trtv6hstd266sc+FH2h/ubhNbr2YZAeOjy5192CxOpGXJZJngOsiTP+9MWaa/TfPw/TTqsvFY6rRliypau7Tf5ObKo+tGTo4lZclubbuHD7r5mH1V7jZq0sdL1vX6qxUsbuiwXHv3vUtnQl36Or1fVoveBZIjDHLgZq4M2axR4P7+fcXNwPQbheXV+7r2zlie1c3R+pbHa3/uTXxfyyhkOF/Xt2WlQdfNMne9I12UzpYltqHIrNBDofOPsK71ElUQ1sns98tcVSq213RwCf/sIKHFyfWhXxDv3spF9+9kJufWJvQsi+vz76+5vy42f59Efk6sAH4sTGmNtJMInI7cDvApEmTCAaDjhJrampKetl487c0NwMwZ/MhAD5/Wu9JfPWm7Qyr2nP8/R83t7GxsvdKpGh/34cQ16xZw8GD1gmv+MABglJ+/LPysr4/lt279/R5X15exusLj/DyhlYWbC/n4Wt6R2DsChl+sLTF0fbFEmvZeOvduWsnI2sK+0xra7e2cc3q1Zw83Lqu2Vd64hVjfV3dCevfX2LNV15eTjAYvZ48Ut567r1g4ufbyTZ3dlp5W7VqFaOHRC4+hC979GjvuPMHiosBKC09SDDY9/5STY013/Zt25AK6+dbWNN7fBUWWt+vMaET8rb9mHWc1dbURsx3dU3vdZ+b/exk2fp66ze0efNmmkoG9vmsq8vK98pVK+k2UN8eORJUV1cfX3/P77642GoJWVJayu0zi1lT0c0pw+PvD4DGDiudjs5OFq1cB8CavRUJLXvP6tYTPltfEvFUx/Llyxg0oDdPhw73/u6d/FadnPPcSncg+QtwD9aF0z3Ag8A3I81ojJkFzAKYPn26CQQCjhIMBoMkvOz8uQCR57c/AxgxciQ0997oDgQCxz8/7/zzCVx21vHPvrmgdzmAc885Bwp3H39/2WWXsV8OQvF+zp4yhUBYX14rmnZBafHx97O29Q0skyefyRVXTIHgEoYMGdIn34frWmleGHnQoWS/j7jLRvreIiw79cKpBC46rc+0YauXQFsbl11+OWeMHQ5Ayapi2L2rz3xjxo4lELi8z7T9K4thzy4mT55MIDA1qXyHQgYWzAOJn28n2zx48GDo7GTGjBmMHzkk7rJ/O7QRKq2gMeXss2HfXs466z0EAu/ts+jTB9ZB1TH+6aKLCFwwEYAh+6tgnXW1e/75F8DO7YgMOCHfsvcYbFzHuPHjCAQ+DNi9NM+3WiuePH48HDuW0DZ3doesk9/8E2un4y27cOcRRg0dBPReoY8cNRrq6rnkkkuYXjC+z6KDggugq4srZ1zJtQ8Fow4xMH78eAKBDwG9v/tt3fugaC8FZ51FXVkdUIUMGgKcWKLpn+/CI43wznIGDx7MRRddBBvXM2LECGhpjrvsN8KOhfDzQyRXX/3PDBnUWzm0pG4HHCyNuN5EJHXOS5G0BhJjTGXPaxF5HHgrnemH++XrO9hcVscb378y6WXzvHpaZZgHFhTGnymK/cdOPCnG09Ud4ryfvc03Z5ztKM3b+3QzZEn0Hp6bcWqS5WZ8mXyT1ua/IhJ+Ofo5wF2/6i7MXl3Ktgy4AS0ix+ts+49/rS108se64sjVHolwchzXt3Ty7dnrHfUo3dOw5Pm1zm94p0uDfWM9k39L2dQ/WjReNv99EVgNXCAi5SLyLeB+EdkuItuAa4AfeZV+pop00Oy3B4H6k4NmiT11/Ucd3HwEuPhXC/naE2scLauiS/bUkO6hkP+6tpTFu4/yxIri+DNnsSdWpnb7sv+U7w3PqraMMTdFmPykV+l5aX+Co/055Wac8Nrm5Jsy7jrcwJnjhzN62GDqWztZVVTN/mNNjBk+mAmjYj+d7kYuXHklKhUPrsW7im5u72JvZeLjxMdrDVfvsFms1xpSPCSBEzo+e2zaRUoCevrCSkS8U+Vv5+2JM0f4urw58V7/yAo+WDCOV757xfFp1z64jOGDB7L7nkiP/ngvU/t58kOsk1b4t/SDlzazePfRfp/H/x6jrb+yIb2lokSEN2t383vIp4sYP2gXKQlwU2LI1MM3UlPE1s7eezSPLz+Qlnzold6JfpfAzXMh8r2RnmM1k77V/s9UJKOsJnITdpVZtESSgEitTFIp2tWSm4t0twHsN/N2x58pA7kp2fRv7JAOOw/XczSFJYF737ZKvE7i86E6Zw/OxvOT11Iz5kdnBvRUkI6SczZeW2kgcSDVO9pdwPDvx7X2QDV7k+g4MtFhTzuijN8eTfj39+rG8ugzxtEZct6Zn1OfemRl2tMMl+ixvL7EeScVyTyFHis/B5K8V7mx1HlLuP6y8NyeVnkXSC66awE//Oj5nq3f7QHX2R1i8MDsqHH88qzIrb2aXXbimOh9pEjfdXmtN1fVsRQeaeSk4bn9U/riY6vTnmYoZNhSVudo2SPNIb7xl3cdp+2mabPTUkvhkUbGDB+c0U2Vo8ntoz+ChrYu7n5rV/wZUyTZg+K8n73Ngh9ezQWnjk5o/vCr/AcXFnLTh97D6fYT4n7pTLJE4adU/Gj9enAtG6tAkvGXZfuZ6fBeXUunux37sznOHnGbv6OC+95OvEEN9B6D2fwAZHZc+maRWcsPMO3uha7Wsd1hB4x/fKeI77+wyVXa8Xz898v48sz0X53G8sy7Jb6lvWhXZfyZokjm2RFjDF0uAnRFfSuPLt0ff8YMUngk8abN0Htf8GB1C6sr+paKE71gKK1u5jqHJ/Symha++9dNlFTnXwOBvCuRJKKupYOqpg7OnTgq4uex6voP2q1Maps7GNe/j6WI63J3Y7z/VanXNyT3VvozmFaiF99Ott4Yw4ML9/KZaacnvWxFEj07d3SF+tzT+te/Jt6I41dv7uKZd0u46rwJSeUPYO62Cu5weIHRHTL824vOL06+9/xG1jm4v7JyX1XMAati+fQfVzh+9uSxZfvZEyOAxTq+Eu0mPhdpiSSCT/5hxfFhdyMpTOAhsB2HkyhVRDk6E6lrjTRLa0c3P3rZ+YBQfpjlsrmxMYY9RxocNdXeVl7Pn5YWccOfVrnKQzxX3LeEC34+//j7ZG5CP7u6BOjd3z9MYv9uPuj8pnNlQxvztjsf4dLpsjc/udbxA5JePMDYc8GWjfcv0iHvA8lV97/DT+f0bZ5YUZ/4A4ipEOmK7Vhje0LjkUTq3uQfWw6xrth5K5tbnkxs3IRovv/C5ojTq5vbjz9gZozpM0jQsy4GKgJ4YkUx1z28gqdWJd8lRkm11XFh+HM0Xki2w8FI56yeYWLdPDm/3OGVfrK06538kfeBpKymNbkha5OQSOul9ijjR9/xwiYSGYyt1uEJJdaN2hX9BudKVLDQesp6ZVHk5X/x+k4+/Uerueuzq0s556fzOBZ2n6CpvYuSquR7owXYWu6sdU+y7p23+/h2+iH8oiPR5tSxOFlHoiWpVUXVJ0xrcxGs/SoM+FkKCbkYeTWd8j6QeGX2u6V8/Pfxb9qFohyltc3p6y47nJsHrl5eX8btz25IaN6/b7Ke9+gIC6RfmbWawANBx+mnw8zlB/jG0+v9zkZa1LV0cPX9S0+YXmQ/z+HkSPnAPYsc5+fuN523tky06jTS4e+2DzI3T/Y/vGSfq7TTRQNJDAt3Jla/W3DniYPWLN5d6dmTwrEk0+KrKUKJadNBd1f2C120YtpxqMHxstlx3ZZ5eqr1Ilm+r+p4l/HhbrMDaUeU0nQsLS56D9hV4fz46AoZipJ4eDYaJw8A3xvnuahHg/ujljzmbHb+gG06aSCJwY9AAOnrwPBzfz7x5rKbJqZeau3s5m/ryzDGEAoZZtz3DvfN7/2Bzt0WeQjU/prbu/inXy7gP1/Z6lVWM8reysaYXalHq1rNRW7ufT6/Jnb1d6zGLS+ui73sI0v2sXBX5IvWshp/zkHJ0ua/GWizw6d5k7UvBVdoTiUbKreV1/Pf5ds4Y9xwGtu6HAf5NQeqaWzv4u+bDzla3i+Rvq9EHkj8r1e3RZz+qIOxb3JFtLF7YrVum2/XTkQ7sc/ZfIg7rjnHcZ6yPaBricRnkc4FXt3891o6nrRu6eh21e9TuqWidFnT3JHyG77NPnRQmRj/Htf/3KPOu1TJdxpIfJZp3ai7ejgyTSeBJ1M86l2m+8iDwYjT091MPdMFC4/xaNBdSUufE3FGA4mt54GvdMusMJI+TsYZz1dOnhnJ1uOq8Eijq1Lc/fPjj+XilXwOQnqPxPaL13f6nYWUcdUtfYLLZupN+XhS/WNPdH2vb8muezJ++emc7XT70J2/ckdLJHnK7RXrQ4v2piQf+eIHL53YqqfGp2eFEuX0GKl3OV69m2a+yh8aSHyWYbdIEm4n/2gwQk+yCW6L08743Lh33m4qG9zdU3jGQfcrscTrEyolpScf6lsuvnthxgdJlVoJVW2JyDlAuTGmXUQCwEXAs8aY9LRT9QruzaUAABH0SURBVNHq/Sd285BKbm5QR3sqPrFlHS8aVaJbcutT6xyn8VKcNvnRzFx+gNc2HUqq6/Zw1U3t3OXiyep8U+3we/abnyOOZrNESySvAd0ici7wJHA28IJnucogNz3ubcdzbrpP8HMcDr8s2eO8n6toQSSRlnPdUYJ2ea13Y088tsz5+CHVbcbVGPSff3RVn041k5Xtz0U4kWm1C+mUaCAJGWO6gM8BDxtjfgSc5l228kdPJ4Yqc7259XDUzx5fEbu6y00wcOs/X3X+9P6mg3WuWjK66TkgWJj+qs8ebppUH21wXgprcNmfl98SDSSdInITcCvwlj1tsDdZUuDuqXM3V0blLrpkyLRnYhJVEecp+X97cbPjWw2Pryh2dVK9+QnnXfrP3VZBo4uxOdx0VR9rcKh4/Hw+ptTF6IY//4ez4XkB/jfLW40mGkhuAy4HfmOMKRaRs4G/epctbyx1US2SL1o6Uj8oUKa7N4Extv/gohfWVzc673gvWpf8iYrU6aJSqZbQzXZjzC7g3wFEZBww2hhzn5cZ88Jtz+RH999+yc7ySGJW7POvusU3ubxDo9Cb7c4kVCIRkaCInCQi44GtwNMi8pC3WVNO5fMTtl7Jll5YUykP44i7h3lTl42sk2jV1hhjTAPweeBpY8ylwEe9y1ZmcNNqJVu56msrH888SqmEA8kgETkN+BK9N9tz3q/n7vY7C470H4NeKSeytfGEX4odDhOdCxINJHcDC4D9xpj1IjIFyI4xIFVS3Jw6Cl201FEqE1Q36RP5TiR6s/0V4JWw9weAL3iVKZWd3DT5VCoTtHZm6jgtmS3Rm+2TRWSOiBwVkUoReU1EJnudOaWUf1IxxrnKD4lWbT0NvAGcDpwBvGlPU0oplecSDSSnGGOeNsZ02X/PAKd4mC+lVAocrPGuLzCleiQaSKpE5GYRGWj/3Qx42y2u8oX2cKuUSlaigeSbWE1/jwAVwI1Y3aYopZTKcwkFEmPMQWPMZ4wxpxhjJhpjPov1cGLW2Fha63cWlFIqJ7kZIfE/Yn0oIk/Zrbx2hE0bLyKLRGSf/X+ci/ST8sd39LEXpZTygptAEu/ZtWeA6/pNuxNYYow5D1hiv1dKKZXF3ASSmN0yGWOWAzX9Jt8AzLZfzwY+6yJ9pZRSGSDmk+0i0kjkgCHAcAfpTTLGVAAYYypEZGKMtG8HbgeYNGkSwWDQQXLQ1NREMBikptq/wXKUUsqpZM99Pee8dIoZSIwxo9OVkQhpzwJmAUyfPt0EAgFH6wkGgwQCAZ4pXgdVeTimhFIqqyV77us556WTm6otJyrtXoSx/6dtyELtx1QppbyR7kDyBta479j/X09z+koppVLMs0AiIi8Cq4ELRKRcRL4F3Ad8TET2AR+z3yullMpiCXUj74Qx5qYoH13rVZqxlNXm31CpSimVDumu2vKNdomtlFLeyJtAopRSyhsaSJRSSrmigUQppZQrOR1IXl5/kCe3t/udDaWUymk5HUh2HGpgy9Euv7OhlFI5LacDCcTpWVIppZRrOR1IRKxA8vjyA35nRSmlHFm2N/P7CMzpQALQ3Am/mbfb72wopZQj5bUtfmchrpwPJEoppbyV04FEe/xVSinv5XQgUUop5T0NJEoplcEkC+pWcjqQiGT+DlBKqWyX04FEKaWU9zSQKKVUBsuGihUNJEoppVzRQKKUUsqVnA4k2VAkVEqpbJfTgUQppbJdNlwP53QgyYb210ople1yOpAopZTyngYSpZRSruR0INGb7UqpbJcN57GcDiRKKaW8l9OBJAsCuVJKZb2cDiRKKZXtsqH1qQYSpZRSruR0IMmGm1RKKZXtcjqQKKWU8p4GEqWUymRZULOS04FER0hUSinv5XQgUUop5b2cDiRaHlFKKe/ldCBRSqlslw0XxBpIlFJKuZLbgSQbQrlSSmW5QX4kKiIlQCPQDXQZY6b7kQ+llMp02dD61JdAYrvGGFPlZQLZ0EeNUkplu9yu2lJKKeU5v0okBlgoIgaYaYyZ1X8GEbkduB1g0qRJBIPBpBM5eLDDZTaVUspfe/bsJthYlPD8TU1Njs6XbvgVSGYYYw6LyERgkYjsMcYsD5/BDi6zAKZPn24CgUDSiaxt2wPF+1ORX6WU8sX73vs+ApdOTnj+YDCIk/OlG75UbRljDtv/jwJzgA/5kQ+llFLupT2QiMhIERnd8xr4OLAj3flQSimVGn5UbU0C5thN2gYBLxhj5nuRkLbZUkop76U9kBhjDgAXpyOtVUWeti5WSinPldW2+J2FuHK6+e/W8nq/s6CUUq50dIX8zkJcOR1IlFJKeU8DiVJKKVc0kCillHJFA4lSSmUw43cGEqCBRCmllCsaSJRSKoNlw/NwGkiUUiqDadWWUkqpnKeBRCmllCsaSJRSSrmigUQppZQrGkiUUkq5ooFEKaWUKxpIlFJKuaKBRCmlMpjJggdJNJAopZRyRQOJUkopVzSQKKVUBusO6QiJSimlXJi9utTvLMSlgUQppTKYjtmulFIq52kgUUop5YoGEqWUUq5oIFFKKeWKBhKllFKuaCBRSinligYSpZRSrmggUUop5UpOB5Khg3J685RSKiPk9Jl28MCc3jyllMoIOX2m/fmn3ud3FpRSKufldCD59MWn+50FpZRy5byJo/zOQlw5HUhGDB7odxaUUsqVl79zud9ZiGuQ3xnw0oAB4ncWVBYYPWwQjW1dET+7fMrJrD5QDcDkccMpr23t8/mDX7yY2atLGDV0EBNGDeWNrYe5YNJoCisbeeLr05m3o4J3i6q59YoCiquaGDdiCOtKaqhv6eSRmy6htqWDivo2zjllFKuKqhgyaABvbj3Mrz4zld1HGmls62TKhJGcPGoonV0hdlU0sLa4hrtvmMrJI4dS2dDGsMEDOdbYTl1rBxtLaplx3gR2bt3M2e+9iKqmdj5z8enUtHRQ2dDGy+vL+PHHLmDk0IG0dnYTMhAKGRrbujhY08LEk4Zy6phhHG1oZ8nuSr591RQA2jq7eW5NKTdeOpkJo4bS2R2ioyvEsMEDaWrror2rGwTGDh9CY1sny/cdI3D+RMaNHIIxhg2ltZx60jDOHD8CYwzt9rLdIcMAga6QQYCQgV0VDZw8cghnjh8BwOG6Vrq6De852Xrf0RViSL+GNMYYukOGY03ttHR0U7ZzA1dceTVdoRCH69o4176q7+oOMUDkhHNDKGTlqaK+lSmnjKKlo4shAwdwoKqZ8yeNPp6GMZHPK53dIaqbOjh1zDDaOrsBONbYzqljhsW9V9sdMrR0dDF88EBEhI6uEM0dXQwdNIDRwwbHXDZTiMmCAYGnT59uNmzY4GjZuYuWcseSlhOmv/gvl3HOKSOZeNIwt9nLaMFgkEAg4Hc2fKHbHvA7G77J5+0P33YR2WiMme51mjldIgEYOVgoue9TfmdDKaVyli/3SETkOhEpFJEiEbnTjzwopZRKjbQHEhEZCPwZ+CRwIXCTiFyY7nwopZRKDT9KJB8CiowxB4wxHcBLwA0+5EMppVQKpP1mu4jcCFxnjPm2/f4W4MPGmO/3m+924HaASZMmXfrSSy85Sq+pqYlRozK/HbZX8nn7ddvzc9shv7c/fNuvueaanL3ZHqlN7gnRzBgzC5gFVqstpy0w8rn1BuT39uu2B/zOhm/yefv92HY/qrbKgTPD3k8GDvuQD6WUUingRyBZD5wnImeLyBDgK8AbPuRDKaVUCqS9assY0yUi3wcWAAOBp4wxO9OdD6WUUqmRFU+2i8gxoNTh4hOAqhRmJ9vk8/brtuevfN7+8G0/yxhzitcJZkUgcUNENqSj1UKmyuft123Pz22H/N5+P7Y9p3v/VUop5T0NJEoppVzJh0Ayy+8M+Cyft1+3PX/l8/anfdtz/h6JUkopb+VDiUQppZSHNJAopZRyJacDSTaPeyIiZ4rIUhHZLSI7ReQH9vTxIrJIRPbZ/8fZ00VEHrG3dZuIfCBsXbfa8+8TkVvDpl8qItvtZR4REYmVRrqJyEAR2Swib9nvzxaRtXa+XrZ7RkBEhtrvi+zPC8LW8RN7eqGIfCJsesRjI1oa6SQiY0XkVRHZY+//y/Nsv//IPuZ3iMiLIjIsV/e9iDwlIkdFZEfYNN/2daw0YrLGIc69P6yn5vcDU4AhwFbgQr/zlUT+TwM+YL8eDezFGr/lfuBOe/qdwP/Zr68H3sbqFPMyYK09fTxwwP4/zn49zv5sHXC5vczbwCft6RHT8OE7+A/gBeAt+/3fgK/Yrx8D/tV+/T3gMfv1V4CX7dcX2vt9KHC2fTwMjHVsREsjzds9G/i2/XoIMDZf9jtwBlAMDA/bH9/I1X0PXA18ANgRNs23fR0tjbjbke4DJY0H5OXAgrD3PwF+4ne+XGzP68DHgELgNHvaaUCh/XomcFPY/IX25zcBM8Omz7SnnQbsCZt+fL5oaaR5eycDS4CPAG/ZB3YVMKj//sXqbudy+/Ugez7pv8975ot2bMRKI43bfRLWiVT6Tc+X/X4GUGafFAfZ+/4TubzvgQL6BhLf9nW0NOJtQy5XbfUckD3K7WlZxy6uXwKsBSYZYyoA7P8T7dmibW+s6eURphMjjXR6GPhvIGS/PxmoM8Z02e/D83t8G+3P6+35k/1OYqWRLlOAY8DTYlXrPSEiI8mT/W6MOQQ8ABwEKrD25UbyY9/38HNfOzpv5nIgSWjck0wnIqOA14AfGmMaYs0aYZpxMN13IvJp4KgxZmP45AizmjifZeN3MgirquMvxphLgGasqodosnEbo7Lr6m/Aqo46HRiJNSx3f7m47+NJxzY5+h5yOZBk/bgnIjIYK4g8b4z5uz25UkROsz8/DThqT4+2vbGmT44wPVYa6TID+IyIlGANxfwRrBLKWBHp6bE6PL/Ht9H+fAxQQ/LfSVWMNNKlHCg3xqy137+KFVjyYb8DfBQoNsYcM8Z0An8HriA/9n0PP/e1o/NmLgeSrB73xG5d8SSw2xjzUNhHbwA9rTJuxbp30jP963ari8uAervIugD4uIiMs6/2Po5V91sBNIrIZXZaX++3rkhppIUx5ifGmMnGmAKs/faOMeZrwFLgxgj5Cs/vjfb8xp7+Fbtlz9nAeVg3HyMeG/Yy0dJIC2PMEaBMRC6wJ10L7CIP9rvtIHCZiIyw89ez/Tm/78P4ua+jpRFbOm4m+fWH1QJhL1YrjZ/5nZ8k834lVpFyG7DF/rseqy53CbDP/j/enl+AP9vbuh2YHraubwJF9t9tYdOnAzvsZf5Eb08HEdPw6XsI0NtqawrWyaAIeAUYak8fZr8vsj+fErb8z+ztK8RusRLr2IiWRpq3eRqwwd73/8BqiZM3+x34FbDHzuNzWC2vcnLfAy9i3QvqxCoNfMvPfR0rjVh/2kWKUkopV3K5aksppVQaaCBRSinligYSpZRSrmggUUop5YoGEqWUUq5oIFHKAyISELvXYqVynQYSpZRSrmggUXlNRG4WkXUiskVEZoo1BkqTiDwoIptEZImInGLPO01E1tjjNMwJG8PhXBFZLCJb7WXOsVc/SnrHFXk+bCyI+0Rkl72eB3zadKVSRgOJylsi8j7gy8AMY8w0oBv4GlZHgZuMMR8AlgG/tBd5FvgfY8xFWE/99kx/HvizMeZirH6herqUuAT4IdbYGFOAGSIyHvgcMNVez6+93UqlvKeBROWza4FLgfUissV+PwWr6/qX7Xn+ClwpImOAscaYZfb02cDVIjIaOMMYMwfAGNNmjGmx51lnjCk3xoSwurgpABqANuAJEfk80DOvUllLA4nKZwLMNsZMs/8uMMbcFWG+WP0IRep2u0d72OturEGTuoAPYfXq/FlgfpJ5VirjaCBR+WwJcKOITITj41ifhfW76OkF9qvASmNMPVArIlfZ028BlhlrjJhyEfmsvY6hIjIiWoL2+DJjjDHzsKq9pnmxYUql06D4syiVm4wxu0Tk58BCERmA1QPrHViDSU0VkY1YI+592V7kVuAxO1AcAG6zp98CzBSRu+11fDFGsqOB10VkGFZp5kcp3iyl0k57/1WqHxFpMsaM8jsfSmULrdpSSinlipZIlFJKuaIlEqWUUq5oIFFKKeWKBhKllFKuaCBRSinligYSpZRSrvx/03YVVleIekEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss Value Trend')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.plot(loss_val_list)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최대손실값 / 최소손실값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_loss =  21.927579584672216 , max_loss_index =  926503 , min_loss =  0.5852124065792236 , min_loss_index =  4296\n",
      "epochs_num =  19\n",
      "real_max_index =  14503 , real_min_index =  4296\n"
     ]
    }
   ],
   "source": [
    "max_loss = np.max(loss_val_list)\n",
    "min_loss = np.min(loss_val_list)\n",
    "max_loss_index = np.argmax(loss_val_list)\n",
    "min_loss_index = np.argmin(loss_val_list)\n",
    "\n",
    "print(\"max_loss = \", max_loss, \", max_loss_index = \", max_loss_index, \", min_loss = \", min_loss, \", min_loss_index = \", min_loss_index)\n",
    "\n",
    "epochs_num = int(max_loss_index/len(training_data))\n",
    "print('epochs_num = ', epochs_num)\n",
    "\n",
    "if max_loss_index > len(training_data):\n",
    "    real_max_loss_index = max_loss_index-epochs_num*len(training_data)\n",
    "else:\n",
    "    real_max_loss_index = max_loss_index\n",
    "    \n",
    "\n",
    "if min_loss_index > len(training_data):\n",
    "    real_min_loss_index = min_loss_index-epochs_num*len(training_data)\n",
    "else:\n",
    "    real_min_loss_index = min_loss_index\n",
    "    \n",
    "\n",
    "\n",
    "print('real_max_index = ', real_max_loss_index, ', real_min_index = ', real_min_loss_index)  # real_min_loss_index 다시 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  4\n",
      "prediction =  7\n"
     ]
    }
   ],
   "source": [
    "# check max loss data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = training_data[real_max_loss_index, 1:].reshape(28,28)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "target = int(training_data[real_max_loss_index, 0])\n",
    "\n",
    "input_data = (training_data[real_max_loss_index, 1:] / 255.0 * 0.99) + 0.01\n",
    "\n",
    "predicted_num = nn.predict(np.array(input_data, ndmin=2))\n",
    "\n",
    "print('label = ', target)\n",
    "print('prediction = ', predicted_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  7\n",
      "prediction =  7\n"
     ]
    }
   ],
   "source": [
    "# check min loss data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = training_data[real_min_loss_index, 1:].reshape(28,28)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "target = int(training_data[real_min_loss_index, 0])\n",
    "\n",
    "input_data = (training_data[real_min_loss_index, 1:] / 255.0 * 0.99) + 0.01\n",
    "\n",
    "predicted_num = nn.predict(np.array(input_data, ndmin=2))\n",
    "\n",
    "print('label = ', target)\n",
    "print('prediction = ', predicted_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
