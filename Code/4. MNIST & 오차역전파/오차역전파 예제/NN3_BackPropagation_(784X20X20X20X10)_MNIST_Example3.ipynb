{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuralNetwork Class\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # 생성자\n",
    "    def __init__(self, input_nodes, hidden_nodes_1, hidden_nodes_2, hidden_nodes_3, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes_1 = hidden_nodes_1\n",
    "        self.hidden_nodes_2 = hidden_nodes_2\n",
    "        self.hidden_nodes_3 = hidden_nodes_3\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        ############################### 가중치 / 바이어스 초기화 #############################################\n",
    "        # 2층 hidden layer unit \n",
    "        # Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes_1) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes_1)\n",
    "        \n",
    "        # 3층 hidden layer unit \n",
    "        # Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes_1, self.hidden_nodes_2) / np.sqrt(self.hidden_nodes_1/2)\n",
    "        self.b3= np.random.rand(self.hidden_nodes_2)\n",
    "        \n",
    "        # 4층 hidden layer unit \n",
    "        # Xavier/He 방법으로 self.W4 가중치 초기화\n",
    "        self.W4 = np.random.randn(self.hidden_nodes_2, self.hidden_nodes_3) / np.sqrt(self.hidden_nodes_2/2)\n",
    "        self.b4 = np.random.rand(self.hidden_nodes_3)\n",
    "        \n",
    "        # 5층 output layer unit \n",
    "        # Xavier/He 방법으로 self.W4 가중치 초기화\n",
    "        self.W5 = np.random.randn(self.hidden_nodes_3, self.output_nodes) / np.sqrt(self.hidden_nodes_3/2)\n",
    "        self.b5 = np.random.rand(self.output_nodes)\n",
    "                          \n",
    "        ############################### 선형회귀 Z / 출력 A 초기화 ##########################################\n",
    "        # 5층 output layer 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z5 = np.zeros([1,output_nodes])\n",
    "        self.A5 = np.zeros([1,output_nodes])\n",
    "        \n",
    "        # 4층 hidden layer 3 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z4 = np.zeros([1,hidden_nodes_3])\n",
    "        self.A4 = np.zeros([1,hidden_nodes_3])\n",
    "        \n",
    "        # 3층 hidden layer 2 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z3 = np.zeros([1,hidden_nodes_2])\n",
    "        self.A3 = np.zeros([1,hidden_nodes_2])\n",
    "        \n",
    "        # 2층 hidden layer 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z2 = np.zeros([1,hidden_nodes_1])\n",
    "        self.A2 = np.zeros([1,hidden_nodes_1])\n",
    "        \n",
    "        # 1층 input layer 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z1 = np.zeros([1,input_nodes])    \n",
    "        self.A1 = np.zeros([1,input_nodes])       \n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    # 손실함수\n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 1층 출력 계산, 가중합과 출력은 입력 값과 동일함\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 2층 가중합, 출력 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 3층 가중합, 출력 계산    \n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # 4층 가중합 , 출력 계산\n",
    "        self.Z4 = np.dot(self.A3, self.W4) + self.b4\n",
    "        self.A4 = sigmoid(self.Z4)\n",
    "        \n",
    "        # 5층 가중합 , 출력 계산\n",
    "        self.Z5 = np.dot(self.A4, self.W5) + self.b5\n",
    "        y = self.A5 = sigmoid(self.Z5)        \n",
    "        \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "\n",
    "    \n",
    "    # 손실 값 계산\n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 1층 출력 계산, 가중합과 출력은 입력 값과 동일함\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 2층 가중합, 출력 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 3층 가중합, 출력 계산    \n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # 4층 가중합 , 출력 계산\n",
    "        self.Z4 = np.dot(self.A3, self.W4) + self.b4\n",
    "        self.A4 = sigmoid(self.Z4)\n",
    "        \n",
    "        # 5층 가중합 , 출력 계산\n",
    "        self.Z5 = np.dot(self.A4, self.W5) + self.b5\n",
    "        y = self.A5 = sigmoid(self.Z5)        \n",
    "        \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, input_data):\n",
    "        \n",
    "        # input_data 는 행렬로 입력됨 즉, (1, 784) shape 을 가짐\n",
    "        Z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = sigmoid(Z3)\n",
    "        \n",
    "        Z4 = np.dot(A3, self.W4) + self.b4\n",
    "        A4 = sigmoid(Z4)\n",
    "        \n",
    "        Z5 = np.dot(A4, self.W5) + self.b5\n",
    "        y = A5 = sigmoid(Z5)\n",
    "        \n",
    "        predicted_num = np.argmax(y)\n",
    "    \n",
    "        return predicted_num\n",
    "    \n",
    "\n",
    "    # 정확도 측정함수\n",
    "    def accuracy(self, test_input_data, test_target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        for index in range(len(test_input_data)):\n",
    "                        \n",
    "            label = int(test_target_data[index])\n",
    "                        \n",
    "            # one-hot encoding을 위한 데이터 정규화 (data normalize)\n",
    "            data = (test_input_data[index] / 255.0 * 0.99) + 0.01\n",
    "                  \n",
    "            # predict 를 위해서 vector 을 matrix 로 변환하여 인수로 넘겨줌\n",
    "            predicted_num = self.predict(np.array(data, ndmin=2)) \n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "        accuracy_val = (len(matched_list)/(len(test_input_data)))\n",
    "        \n",
    "        return accuracy_val, not_matched_list\n",
    "    \n",
    "            \n",
    "    # input_data : 784 개,  target_data : 10개\n",
    "    def train(self, input_data, target_data):  \n",
    "        \n",
    "        self.target_data = target_data    \n",
    "        self.input_data = input_data\n",
    "        \n",
    "        # 먼저 feed forward 를 통해서 최종 출력값과 이를 바탕으로 현재의 에러 값 계산\n",
    "        loss_val = self.feed_forward()      \n",
    "        \n",
    "        # 출력층 loss 인 loss_5, 가중치 W5, 바이어스 b5 계산\n",
    "        loss_5 = (self.A5-self.target_data) * self.A5 * (1-self.A5)    \n",
    "\n",
    "        W5_diff = np.dot(self.A4.T, loss_5)\n",
    "        b5_diff = loss_5\n",
    "        \n",
    "        self.W5 = self.W5 - self.learning_rate * W5_diff        \n",
    "        self.b5 = self.b5 - self.learning_rate * b5_diff\n",
    "        \n",
    "        # 은닉층 3 loss 인 loss_4, 가중치 W4, 바이어스 b4 계산\n",
    "        loss_4 = np.dot(loss_5, self.W5.T) * self.A4 * (1-self.A4)    \n",
    "        \n",
    "        W4_diff = np.dot(self.A3.T, loss_4)\n",
    "        b4_diff = loss_4\n",
    "        \n",
    "        self.W4 = self.W4 - self.learning_rate * W4_diff        \n",
    "        self.b4 = self.b4 - self.learning_rate * b4_diff\n",
    "                \n",
    "        # 은닉층 2 loss 인 loss_3, 가중치 W3, 바이어스 b3 계산\n",
    "        loss_3 = np.dot(loss_4, self.W4.T) * self.A3 * (1-self.A3)\n",
    "        \n",
    "        W3_diff = np.dot(self.A2.T, loss_3)\n",
    "        b3_diff = loss_3\n",
    "        \n",
    "        self.W3 = self.W3 - self.learning_rate * W3_diff        \n",
    "        self.b3 = self.b3 - self.learning_rate * b3_diff              \n",
    "        \n",
    "        # 은닉층 1 loss 인 loss_2,  가중치 W2, 바이어스 b2 계산\n",
    "        loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)   \n",
    "        \n",
    "        W2_diff = np.dot(self.A1.T, loss_2)\n",
    "        b2_diff = loss_2\n",
    "                \n",
    "        self.W2 = self.W2 - self.learning_rate * W2_diff\n",
    "        \n",
    "        self.b2 = self.b2 - self.learning_rate * b2_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape =  (60000, 785)\n",
      "training_data[0,0] =  5.0 , len(training_data[0]) =  785\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 training data 읽어옴\n",
    "training_data = np.loadtxt('./mnist_train.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "print(\"training_data.shape = \", training_data.shape)\n",
    "print(\"training_data[0,0] = \", training_data[0,0], \", len(training_data[0]) = \", len(training_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 784 X 20 X 20 X 20 X 10 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 ,  loss_val =  8.136869957070907\n",
      "epochs =  0 , step =  1000 ,  loss_val =  3.3377423742606784\n",
      "epochs =  0 , step =  2000 ,  loss_val =  3.2610804791777164\n",
      "epochs =  0 , step =  3000 ,  loss_val =  3.6189932986600883\n",
      "epochs =  0 , step =  4000 ,  loss_val =  3.2551826684785263\n",
      "epochs =  0 , step =  5000 ,  loss_val =  2.8721843143534915\n",
      "epochs =  0 , step =  6000 ,  loss_val =  2.4352064778726494\n",
      "epochs =  0 , step =  7000 ,  loss_val =  3.294530756806189\n",
      "epochs =  0 , step =  8000 ,  loss_val =  2.230010639913519\n",
      "epochs =  0 , step =  9000 ,  loss_val =  2.7229007535113694\n",
      "epochs =  0 , step =  10000 ,  loss_val =  2.5425761479203572\n",
      "epochs =  0 , step =  11000 ,  loss_val =  2.1374745598709133\n",
      "epochs =  0 , step =  12000 ,  loss_val =  1.9071605247757848\n",
      "epochs =  0 , step =  13000 ,  loss_val =  1.3899743716024022\n",
      "epochs =  0 , step =  14000 ,  loss_val =  0.9516568433620403\n",
      "epochs =  0 , step =  15000 ,  loss_val =  2.8184653081135314\n",
      "epochs =  0 , step =  16000 ,  loss_val =  1.8432849193369902\n",
      "epochs =  0 , step =  17000 ,  loss_val =  2.3990631204022903\n",
      "epochs =  0 , step =  18000 ,  loss_val =  2.0718477195709335\n",
      "epochs =  0 , step =  19000 ,  loss_val =  1.6153863868423095\n",
      "epochs =  0 , step =  20000 ,  loss_val =  1.6406968274616651\n",
      "epochs =  0 , step =  21000 ,  loss_val =  1.081931719149909\n",
      "epochs =  0 , step =  22000 ,  loss_val =  1.0704640394960416\n",
      "epochs =  0 , step =  23000 ,  loss_val =  0.8581882901840968\n",
      "epochs =  0 , step =  24000 ,  loss_val =  1.2111804362802887\n",
      "epochs =  0 , step =  25000 ,  loss_val =  1.0946124145105094\n",
      "epochs =  0 , step =  26000 ,  loss_val =  1.6557517461884086\n",
      "epochs =  0 , step =  27000 ,  loss_val =  1.4680182337280017\n",
      "epochs =  0 , step =  28000 ,  loss_val =  0.8109439430571284\n",
      "epochs =  0 , step =  29000 ,  loss_val =  0.8174770085033088\n",
      "epochs =  0 , step =  30000 ,  loss_val =  0.7620878966168021\n",
      "epochs =  0 , step =  31000 ,  loss_val =  1.7233407808006465\n",
      "epochs =  0 , step =  32000 ,  loss_val =  1.0150047470468093\n",
      "epochs =  0 , step =  33000 ,  loss_val =  0.9917876836735352\n",
      "epochs =  0 , step =  34000 ,  loss_val =  1.4729296088621358\n",
      "epochs =  0 , step =  35000 ,  loss_val =  0.7844505621719351\n",
      "epochs =  0 , step =  36000 ,  loss_val =  1.1830979589657253\n",
      "epochs =  0 , step =  37000 ,  loss_val =  0.790990514444476\n",
      "epochs =  0 , step =  38000 ,  loss_val =  0.8142732996248306\n",
      "epochs =  0 , step =  39000 ,  loss_val =  1.0736663689266839\n",
      "epochs =  0 , step =  40000 ,  loss_val =  0.7926527234597194\n",
      "epochs =  0 , step =  41000 ,  loss_val =  0.757338119637062\n",
      "epochs =  0 , step =  42000 ,  loss_val =  0.7534985576529927\n",
      "epochs =  0 , step =  43000 ,  loss_val =  0.9832698855538125\n",
      "epochs =  0 , step =  44000 ,  loss_val =  0.7420375640563709\n",
      "epochs =  0 , step =  45000 ,  loss_val =  0.8554641113923291\n",
      "epochs =  0 , step =  46000 ,  loss_val =  0.8626922447548633\n",
      "epochs =  0 , step =  47000 ,  loss_val =  0.7683396928018547\n",
      "epochs =  0 , step =  48000 ,  loss_val =  0.8176945169172499\n",
      "epochs =  0 , step =  49000 ,  loss_val =  0.7318104671051759\n",
      "epochs =  0 , step =  50000 ,  loss_val =  0.8587472513976696\n",
      "epochs =  0 , step =  51000 ,  loss_val =  0.7874157305093163\n",
      "epochs =  0 , step =  52000 ,  loss_val =  0.9352955689997254\n",
      "epochs =  0 , step =  53000 ,  loss_val =  0.7895967009309558\n",
      "epochs =  0 , step =  54000 ,  loss_val =  0.968742376491682\n",
      "epochs =  0 , step =  55000 ,  loss_val =  0.836186157075506\n",
      "epochs =  0 , step =  56000 ,  loss_val =  0.83240682977071\n",
      "epochs =  0 , step =  57000 ,  loss_val =  0.7484059561249188\n",
      "epochs =  0 , step =  58000 ,  loss_val =  0.68891554387837\n",
      "epochs =  0 , step =  59000 ,  loss_val =  0.7692086284066462\n",
      "epochs =  1 , step =  0 ,  loss_val =  0.8877612102399075\n",
      "epochs =  1 , step =  1000 ,  loss_val =  0.744797241766596\n",
      "epochs =  1 , step =  2000 ,  loss_val =  3.6450843178351775\n",
      "epochs =  1 , step =  3000 ,  loss_val =  1.3132530364696071\n",
      "epochs =  1 , step =  4000 ,  loss_val =  0.7934920358121658\n",
      "epochs =  1 , step =  5000 ,  loss_val =  0.9138482784069097\n",
      "epochs =  1 , step =  6000 ,  loss_val =  0.775583540108544\n",
      "epochs =  1 , step =  7000 ,  loss_val =  0.7044133420650901\n",
      "epochs =  1 , step =  8000 ,  loss_val =  0.7396691615396856\n",
      "epochs =  1 , step =  9000 ,  loss_val =  0.8639326437569235\n",
      "epochs =  1 , step =  10000 ,  loss_val =  0.7291803123885682\n",
      "epochs =  1 , step =  11000 ,  loss_val =  0.7838271117491281\n",
      "epochs =  1 , step =  12000 ,  loss_val =  0.8518449928777225\n",
      "epochs =  1 , step =  13000 ,  loss_val =  0.8191107878172947\n",
      "epochs =  1 , step =  14000 ,  loss_val =  0.8052986158402794\n",
      "epochs =  1 , step =  15000 ,  loss_val =  0.7141741759127566\n",
      "epochs =  1 , step =  16000 ,  loss_val =  0.7268383258572843\n",
      "epochs =  1 , step =  17000 ,  loss_val =  0.7216629294050497\n",
      "epochs =  1 , step =  18000 ,  loss_val =  0.8801785890411429\n",
      "epochs =  1 , step =  19000 ,  loss_val =  0.7516502530426451\n",
      "epochs =  1 , step =  20000 ,  loss_val =  0.7179539440652893\n",
      "epochs =  1 , step =  21000 ,  loss_val =  0.8811732929015237\n",
      "epochs =  1 , step =  22000 ,  loss_val =  0.739214343098305\n",
      "epochs =  1 , step =  23000 ,  loss_val =  0.7898649850743871\n",
      "epochs =  1 , step =  24000 ,  loss_val =  0.7369197138672201\n",
      "epochs =  1 , step =  25000 ,  loss_val =  0.9241617021851167\n",
      "epochs =  1 , step =  26000 ,  loss_val =  0.7081695954082189\n",
      "epochs =  1 , step =  27000 ,  loss_val =  0.9435394180655204\n",
      "epochs =  1 , step =  28000 ,  loss_val =  0.8111093358881826\n",
      "epochs =  1 , step =  29000 ,  loss_val =  0.7312938380737166\n",
      "epochs =  1 , step =  30000 ,  loss_val =  0.730642544123263\n",
      "epochs =  1 , step =  31000 ,  loss_val =  1.2683073640572815\n",
      "epochs =  1 , step =  32000 ,  loss_val =  0.7045007808841596\n",
      "epochs =  1 , step =  33000 ,  loss_val =  0.8302280392680639\n",
      "epochs =  1 , step =  34000 ,  loss_val =  0.768754191847974\n",
      "epochs =  1 , step =  35000 ,  loss_val =  0.822348435915755\n",
      "epochs =  1 , step =  36000 ,  loss_val =  0.7100805457150448\n",
      "epochs =  1 , step =  37000 ,  loss_val =  0.7211841528314974\n",
      "epochs =  1 , step =  38000 ,  loss_val =  0.7189340438063837\n",
      "epochs =  1 , step =  39000 ,  loss_val =  0.752601654995646\n",
      "epochs =  1 , step =  40000 ,  loss_val =  0.7905719037516424\n",
      "epochs =  1 , step =  41000 ,  loss_val =  0.6703682246329031\n",
      "epochs =  1 , step =  42000 ,  loss_val =  0.7955383068458212\n",
      "epochs =  1 , step =  43000 ,  loss_val =  0.8248439026675711\n",
      "epochs =  1 , step =  44000 ,  loss_val =  0.7437483533838333\n",
      "epochs =  1 , step =  45000 ,  loss_val =  0.7179841318220179\n",
      "epochs =  1 , step =  46000 ,  loss_val =  0.7414990397740118\n",
      "epochs =  1 , step =  47000 ,  loss_val =  0.7343999573806491\n",
      "epochs =  1 , step =  48000 ,  loss_val =  0.7436075201476247\n",
      "epochs =  1 , step =  49000 ,  loss_val =  0.6992172701179838\n",
      "epochs =  1 , step =  50000 ,  loss_val =  0.794227654884416\n",
      "epochs =  1 , step =  51000 ,  loss_val =  0.7918925335542565\n",
      "epochs =  1 , step =  52000 ,  loss_val =  0.7964627550375813\n",
      "epochs =  1 , step =  53000 ,  loss_val =  0.8070335694060023\n",
      "epochs =  1 , step =  54000 ,  loss_val =  0.7439473012526334\n",
      "epochs =  1 , step =  55000 ,  loss_val =  0.8421266053947913\n",
      "epochs =  1 , step =  56000 ,  loss_val =  0.850356773189484\n",
      "epochs =  1 , step =  57000 ,  loss_val =  0.7557621764051549\n",
      "epochs =  1 , step =  58000 ,  loss_val =  0.7404084878660618\n",
      "epochs =  1 , step =  59000 ,  loss_val =  0.8097416112523859\n",
      "\n",
      "elapsed time =  0:01:26.772665\n"
     ]
    }
   ],
   "source": [
    "input_nodes = 784\n",
    "\n",
    "hidden_nodes_1 = 20\n",
    "hidden_nodes_2 = 20\n",
    "hidden_nodes_3 = 20\n",
    "\n",
    "output_nodes = 10\n",
    "learning_rate = 1e-1\n",
    "epochs = 2\n",
    "\n",
    "nn = NeuralNetwork(input_nodes, hidden_nodes_1, hidden_nodes_2, hidden_nodes_3, output_nodes, learning_rate)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):  # train\n",
    "    \n",
    "        # input_data, target_data normalize\n",
    "        \n",
    "        target_data = np.zeros(output_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "        #target_data = training_data[step, 0]\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "        \n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i, \", step = \", step,  \",  loss_val = \", nn.loss_val())\n",
    "        \n",
    "end_time = datetime.now() \n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "test_data[0,0] =  7.0 , len(test_data[0]) =  785\n",
      "Accuracy =  93.08999999999999\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "test_input_data = test_data[ : , 1: ]\n",
    "test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))\n",
    "\n",
    "# measure accuracy\n",
    "(acc_ret, false_list) = nn.accuracy(test_input_data, test_target_data)   \n",
    "\n",
    "print('Accuracy = ', 100*acc_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 784 X 10 X 20 X 10 X 10 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 ,  loss_val =  10.17700873909984\n",
      "epochs =  0 , step =  1000 ,  loss_val =  3.416359451789721\n",
      "epochs =  0 , step =  2000 ,  loss_val =  3.384162936589458\n",
      "epochs =  0 , step =  3000 ,  loss_val =  3.6060467075359695\n",
      "epochs =  0 , step =  4000 ,  loss_val =  3.3189761416221666\n",
      "epochs =  0 , step =  5000 ,  loss_val =  3.156443374348236\n",
      "epochs =  0 , step =  6000 ,  loss_val =  3.0366965478917876\n",
      "epochs =  0 , step =  7000 ,  loss_val =  3.3275462325028426\n",
      "epochs =  0 , step =  8000 ,  loss_val =  2.8284273105043423\n",
      "epochs =  0 , step =  9000 ,  loss_val =  3.270855531292135\n",
      "epochs =  0 , step =  10000 ,  loss_val =  3.4175932659952575\n",
      "epochs =  0 , step =  11000 ,  loss_val =  3.059374281025432\n",
      "epochs =  0 , step =  12000 ,  loss_val =  3.3978873681504997\n",
      "epochs =  0 , step =  13000 ,  loss_val =  3.224508505586661\n",
      "epochs =  0 , step =  14000 ,  loss_val =  1.8771268114493997\n",
      "epochs =  0 , step =  15000 ,  loss_val =  2.990854524872211\n",
      "epochs =  0 , step =  16000 ,  loss_val =  3.17422304983088\n",
      "epochs =  0 , step =  17000 ,  loss_val =  3.472588350864254\n",
      "epochs =  0 , step =  18000 ,  loss_val =  2.458305074501247\n",
      "epochs =  0 , step =  19000 ,  loss_val =  3.3325938785114055\n",
      "epochs =  0 , step =  20000 ,  loss_val =  2.2326192675692402\n",
      "epochs =  0 , step =  21000 ,  loss_val =  2.583758398556481\n",
      "epochs =  0 , step =  22000 ,  loss_val =  2.7923888524570817\n",
      "epochs =  0 , step =  23000 ,  loss_val =  2.228012662465373\n",
      "epochs =  0 , step =  24000 ,  loss_val =  2.809201679102942\n",
      "epochs =  0 , step =  25000 ,  loss_val =  2.923273251552804\n",
      "epochs =  0 , step =  26000 ,  loss_val =  1.7169938101699433\n",
      "epochs =  0 , step =  27000 ,  loss_val =  2.4831348680301892\n",
      "epochs =  0 , step =  28000 ,  loss_val =  0.9963914809094239\n",
      "epochs =  0 , step =  29000 ,  loss_val =  2.205239968208761\n",
      "epochs =  0 , step =  30000 ,  loss_val =  2.453702364210083\n",
      "epochs =  0 , step =  31000 ,  loss_val =  3.0013054718327905\n",
      "epochs =  0 , step =  32000 ,  loss_val =  1.9724963233672197\n",
      "epochs =  0 , step =  33000 ,  loss_val =  2.0300892762056266\n",
      "epochs =  0 , step =  34000 ,  loss_val =  1.5023123073595523\n",
      "epochs =  0 , step =  35000 ,  loss_val =  0.8346989049325643\n",
      "epochs =  0 , step =  36000 ,  loss_val =  2.0060110086177168\n",
      "epochs =  0 , step =  37000 ,  loss_val =  1.3301936182771772\n",
      "epochs =  0 , step =  38000 ,  loss_val =  1.2642469580197448\n",
      "epochs =  0 , step =  39000 ,  loss_val =  1.7463064875351015\n",
      "epochs =  0 , step =  40000 ,  loss_val =  1.0876016955135825\n",
      "epochs =  0 , step =  41000 ,  loss_val =  2.0667408011782538\n",
      "epochs =  0 , step =  42000 ,  loss_val =  0.7527611984062661\n",
      "epochs =  0 , step =  43000 ,  loss_val =  1.308784208866738\n",
      "epochs =  0 , step =  44000 ,  loss_val =  0.8776774590919083\n",
      "epochs =  0 , step =  45000 ,  loss_val =  2.331758680973583\n",
      "epochs =  0 , step =  46000 ,  loss_val =  1.108361780136213\n",
      "epochs =  0 , step =  47000 ,  loss_val =  0.9527970048137464\n",
      "epochs =  0 , step =  48000 ,  loss_val =  1.0200685458873022\n",
      "epochs =  0 , step =  49000 ,  loss_val =  0.9081813613748089\n",
      "epochs =  0 , step =  50000 ,  loss_val =  1.3865681243286363\n",
      "epochs =  0 , step =  51000 ,  loss_val =  0.9855797704848565\n",
      "epochs =  0 , step =  52000 ,  loss_val =  0.8584184551214\n",
      "epochs =  0 , step =  53000 ,  loss_val =  1.212191338140994\n",
      "epochs =  0 , step =  54000 ,  loss_val =  1.3177067498781905\n",
      "epochs =  0 , step =  55000 ,  loss_val =  0.733204058539796\n",
      "epochs =  0 , step =  56000 ,  loss_val =  0.7332402510295642\n",
      "epochs =  0 , step =  57000 ,  loss_val =  0.8228854671783387\n",
      "epochs =  0 , step =  58000 ,  loss_val =  0.9314936774453114\n",
      "epochs =  0 , step =  59000 ,  loss_val =  0.854519120983954\n",
      "epochs =  1 , step =  0 ,  loss_val =  1.1801709611527045\n",
      "epochs =  1 , step =  1000 ,  loss_val =  0.8400631241658978\n",
      "epochs =  1 , step =  2000 ,  loss_val =  2.734655276671698\n",
      "epochs =  1 , step =  3000 ,  loss_val =  3.1290092637625033\n",
      "epochs =  1 , step =  4000 ,  loss_val =  0.9101115305013037\n",
      "epochs =  1 , step =  5000 ,  loss_val =  0.9544573381079873\n",
      "epochs =  1 , step =  6000 ,  loss_val =  0.8112593603533483\n",
      "epochs =  1 , step =  7000 ,  loss_val =  0.9771933044078467\n",
      "epochs =  1 , step =  8000 ,  loss_val =  0.7980731047847269\n",
      "epochs =  1 , step =  9000 ,  loss_val =  0.8378972499905641\n",
      "epochs =  1 , step =  10000 ,  loss_val =  0.9377098846943975\n",
      "epochs =  1 , step =  11000 ,  loss_val =  0.7779878135647555\n",
      "epochs =  1 , step =  12000 ,  loss_val =  0.9320602494243583\n",
      "epochs =  1 , step =  13000 ,  loss_val =  0.8032182563639122\n",
      "epochs =  1 , step =  14000 ,  loss_val =  0.7550530672356307\n",
      "epochs =  1 , step =  15000 ,  loss_val =  0.9025671021177425\n",
      "epochs =  1 , step =  16000 ,  loss_val =  0.7677407273219641\n",
      "epochs =  1 , step =  17000 ,  loss_val =  0.8882630977130298\n",
      "epochs =  1 , step =  18000 ,  loss_val =  0.8485439548195423\n",
      "epochs =  1 , step =  19000 ,  loss_val =  0.7898307711067908\n",
      "epochs =  1 , step =  20000 ,  loss_val =  0.754965087870707\n",
      "epochs =  1 , step =  21000 ,  loss_val =  0.851898394229022\n",
      "epochs =  1 , step =  22000 ,  loss_val =  0.9055819942785893\n",
      "epochs =  1 , step =  23000 ,  loss_val =  0.7657357197920512\n",
      "epochs =  1 , step =  24000 ,  loss_val =  0.7480237599145685\n",
      "epochs =  1 , step =  25000 ,  loss_val =  1.0219678997831072\n",
      "epochs =  1 , step =  26000 ,  loss_val =  0.7982752102833679\n",
      "epochs =  1 , step =  27000 ,  loss_val =  0.9509184081927912\n",
      "epochs =  1 , step =  28000 ,  loss_val =  0.7653079700980691\n",
      "epochs =  1 , step =  29000 ,  loss_val =  0.7634869436773707\n",
      "epochs =  1 , step =  30000 ,  loss_val =  0.8014441959063947\n",
      "epochs =  1 , step =  31000 ,  loss_val =  0.9090447836160818\n",
      "epochs =  1 , step =  32000 ,  loss_val =  0.7593623830855848\n",
      "epochs =  1 , step =  33000 ,  loss_val =  1.048168869274757\n",
      "epochs =  1 , step =  34000 ,  loss_val =  0.813355066514651\n",
      "epochs =  1 , step =  35000 ,  loss_val =  0.7725629445388753\n",
      "epochs =  1 , step =  36000 ,  loss_val =  1.587715164084994\n",
      "epochs =  1 , step =  37000 ,  loss_val =  0.8111092477382469\n",
      "epochs =  1 , step =  38000 ,  loss_val =  0.764308820591495\n",
      "epochs =  1 , step =  39000 ,  loss_val =  1.9736379870515237\n",
      "epochs =  1 , step =  40000 ,  loss_val =  0.851382182048027\n",
      "epochs =  1 , step =  41000 ,  loss_val =  0.8674895498185481\n",
      "epochs =  1 , step =  42000 ,  loss_val =  0.7756801588067439\n",
      "epochs =  1 , step =  43000 ,  loss_val =  0.9332495895441941\n",
      "epochs =  1 , step =  44000 ,  loss_val =  0.8050766099478321\n",
      "epochs =  1 , step =  45000 ,  loss_val =  1.0400132419760886\n",
      "epochs =  1 , step =  46000 ,  loss_val =  0.882415568304171\n",
      "epochs =  1 , step =  47000 ,  loss_val =  0.8047329878838178\n",
      "epochs =  1 , step =  48000 ,  loss_val =  0.8215556653260566\n",
      "epochs =  1 , step =  49000 ,  loss_val =  0.7861440214585798\n",
      "epochs =  1 , step =  50000 ,  loss_val =  0.7540896060140025\n",
      "epochs =  1 , step =  51000 ,  loss_val =  0.7710454295570375\n",
      "epochs =  1 , step =  52000 ,  loss_val =  0.774244220040939\n",
      "epochs =  1 , step =  53000 ,  loss_val =  0.8318180725999701\n",
      "epochs =  1 , step =  54000 ,  loss_val =  0.7587433609864963\n",
      "epochs =  1 , step =  55000 ,  loss_val =  0.7979384357731608\n",
      "epochs =  1 , step =  56000 ,  loss_val =  0.7869647088546309\n",
      "epochs =  1 , step =  57000 ,  loss_val =  0.7797732178165403\n",
      "epochs =  1 , step =  58000 ,  loss_val =  0.9018186932938889\n",
      "epochs =  1 , step =  59000 ,  loss_val =  0.8107335821465153\n",
      "epochs =  2 , step =  0 ,  loss_val =  1.176989117280057\n",
      "epochs =  2 , step =  1000 ,  loss_val =  0.7813096527922411\n",
      "epochs =  2 , step =  2000 ,  loss_val =  7.285909358185854\n",
      "epochs =  2 , step =  3000 ,  loss_val =  1.292110789558906\n",
      "epochs =  2 , step =  4000 ,  loss_val =  0.871166970949657\n",
      "epochs =  2 , step =  5000 ,  loss_val =  0.8692820776930946\n",
      "epochs =  2 , step =  6000 ,  loss_val =  0.7671219232391561\n",
      "epochs =  2 , step =  7000 ,  loss_val =  0.6925032881113928\n",
      "epochs =  2 , step =  8000 ,  loss_val =  0.7872450593383704\n",
      "epochs =  2 , step =  9000 ,  loss_val =  0.7976354834745021\n",
      "epochs =  2 , step =  10000 ,  loss_val =  0.7657504803149114\n",
      "epochs =  2 , step =  11000 ,  loss_val =  0.7599443148807925\n",
      "epochs =  2 , step =  12000 ,  loss_val =  1.0088095581203285\n",
      "epochs =  2 , step =  13000 ,  loss_val =  0.7677798706527444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  2 , step =  14000 ,  loss_val =  0.7976814784508632\n",
      "epochs =  2 , step =  15000 ,  loss_val =  0.8095119382927718\n",
      "epochs =  2 , step =  16000 ,  loss_val =  0.7438687496823163\n",
      "epochs =  2 , step =  17000 ,  loss_val =  0.7230825848192657\n",
      "epochs =  2 , step =  18000 ,  loss_val =  1.113795477728267\n",
      "epochs =  2 , step =  19000 ,  loss_val =  0.7147205952088992\n",
      "epochs =  2 , step =  20000 ,  loss_val =  0.7119169555074717\n",
      "epochs =  2 , step =  21000 ,  loss_val =  0.9019756031886491\n",
      "epochs =  2 , step =  22000 ,  loss_val =  0.8112391329479204\n",
      "epochs =  2 , step =  23000 ,  loss_val =  0.7829634832402516\n",
      "epochs =  2 , step =  24000 ,  loss_val =  0.7001332561590472\n",
      "epochs =  2 , step =  25000 ,  loss_val =  0.7637465915676622\n",
      "epochs =  2 , step =  26000 ,  loss_val =  0.7615631622188892\n",
      "epochs =  2 , step =  27000 ,  loss_val =  1.3239700507630032\n",
      "epochs =  2 , step =  28000 ,  loss_val =  0.7965598249437363\n",
      "epochs =  2 , step =  29000 ,  loss_val =  0.7700891194045849\n",
      "epochs =  2 , step =  30000 ,  loss_val =  0.7318306598954216\n",
      "epochs =  2 , step =  31000 ,  loss_val =  0.8281898847499449\n",
      "epochs =  2 , step =  32000 ,  loss_val =  0.6961675767649527\n",
      "epochs =  2 , step =  33000 ,  loss_val =  0.9939320104278412\n",
      "epochs =  2 , step =  34000 ,  loss_val =  0.8633093834454454\n",
      "epochs =  2 , step =  35000 ,  loss_val =  0.794647424415663\n",
      "epochs =  2 , step =  36000 ,  loss_val =  1.140658602739089\n",
      "epochs =  2 , step =  37000 ,  loss_val =  0.8231054800132915\n",
      "epochs =  2 , step =  38000 ,  loss_val =  0.7254480453950518\n",
      "epochs =  2 , step =  39000 ,  loss_val =  1.2955248548601368\n",
      "epochs =  2 , step =  40000 ,  loss_val =  0.8440026030816474\n",
      "epochs =  2 , step =  41000 ,  loss_val =  0.7129678982192167\n",
      "epochs =  2 , step =  42000 ,  loss_val =  0.7979610611418808\n",
      "epochs =  2 , step =  43000 ,  loss_val =  0.8515003535449156\n",
      "epochs =  2 , step =  44000 ,  loss_val =  0.8249583134483169\n",
      "epochs =  2 , step =  45000 ,  loss_val =  0.7681086009558877\n",
      "epochs =  2 , step =  46000 ,  loss_val =  0.7677722519233086\n",
      "epochs =  2 , step =  47000 ,  loss_val =  0.8229119535680475\n",
      "epochs =  2 , step =  48000 ,  loss_val =  0.8069104245558444\n",
      "epochs =  2 , step =  49000 ,  loss_val =  0.760248503984601\n",
      "epochs =  2 , step =  50000 ,  loss_val =  0.7368079865485079\n",
      "epochs =  2 , step =  51000 ,  loss_val =  0.7824336933258186\n",
      "epochs =  2 , step =  52000 ,  loss_val =  0.8051916922972279\n",
      "epochs =  2 , step =  53000 ,  loss_val =  0.7918411759858701\n",
      "epochs =  2 , step =  54000 ,  loss_val =  0.7135799035146979\n",
      "epochs =  2 , step =  55000 ,  loss_val =  0.8814164429703798\n",
      "epochs =  2 , step =  56000 ,  loss_val =  0.8070838631906501\n",
      "epochs =  2 , step =  57000 ,  loss_val =  0.7832189819648132\n",
      "epochs =  2 , step =  58000 ,  loss_val =  0.8879770308932023\n",
      "epochs =  2 , step =  59000 ,  loss_val =  0.7656624757199549\n",
      "epochs =  3 , step =  0 ,  loss_val =  1.331960634882263\n",
      "epochs =  3 , step =  1000 ,  loss_val =  0.781049916863856\n",
      "epochs =  3 , step =  2000 ,  loss_val =  7.868460088339529\n",
      "epochs =  3 , step =  3000 ,  loss_val =  0.8475058570562259\n",
      "epochs =  3 , step =  4000 ,  loss_val =  0.8477989814413178\n",
      "epochs =  3 , step =  5000 ,  loss_val =  0.8563186909961841\n",
      "epochs =  3 , step =  6000 ,  loss_val =  0.7498709273236994\n",
      "epochs =  3 , step =  7000 ,  loss_val =  0.6642393913897112\n",
      "epochs =  3 , step =  8000 ,  loss_val =  0.7838487389399591\n",
      "epochs =  3 , step =  9000 ,  loss_val =  0.7814808927905559\n",
      "epochs =  3 , step =  10000 ,  loss_val =  0.7407495027783841\n",
      "epochs =  3 , step =  11000 ,  loss_val =  0.7423070419811384\n",
      "epochs =  3 , step =  12000 ,  loss_val =  0.9044296643698209\n",
      "epochs =  3 , step =  13000 ,  loss_val =  0.7829627920432637\n",
      "epochs =  3 , step =  14000 ,  loss_val =  0.8066594365525458\n",
      "epochs =  3 , step =  15000 ,  loss_val =  0.7155468346281867\n",
      "epochs =  3 , step =  16000 ,  loss_val =  0.824642554344846\n",
      "epochs =  3 , step =  17000 ,  loss_val =  0.7189927166633017\n",
      "epochs =  3 , step =  18000 ,  loss_val =  0.8304164709258527\n",
      "epochs =  3 , step =  19000 ,  loss_val =  0.7384908231309126\n",
      "epochs =  3 , step =  20000 ,  loss_val =  0.7040254563974999\n",
      "epochs =  3 , step =  21000 ,  loss_val =  0.941203005508144\n",
      "epochs =  3 , step =  22000 ,  loss_val =  4.209852988820812\n",
      "epochs =  3 , step =  23000 ,  loss_val =  0.8157170903811567\n",
      "epochs =  3 , step =  24000 ,  loss_val =  0.678309896636464\n",
      "epochs =  3 , step =  25000 ,  loss_val =  0.8648435548617718\n",
      "epochs =  3 , step =  26000 ,  loss_val =  0.7654062225502438\n",
      "epochs =  3 , step =  27000 ,  loss_val =  1.028072700614274\n",
      "epochs =  3 , step =  28000 ,  loss_val =  0.8077009984029321\n",
      "epochs =  3 , step =  29000 ,  loss_val =  0.8336580961395206\n",
      "epochs =  3 , step =  30000 ,  loss_val =  0.8864142333803123\n",
      "epochs =  3 , step =  31000 ,  loss_val =  0.788676340221834\n",
      "epochs =  3 , step =  32000 ,  loss_val =  0.6775922559146808\n",
      "epochs =  3 , step =  33000 ,  loss_val =  1.124961837818046\n",
      "epochs =  3 , step =  34000 ,  loss_val =  0.8702296094049413\n",
      "epochs =  3 , step =  35000 ,  loss_val =  0.8094751437103855\n",
      "epochs =  3 , step =  36000 ,  loss_val =  1.1503378397364032\n",
      "epochs =  3 , step =  37000 ,  loss_val =  0.8911459025906557\n",
      "epochs =  3 , step =  38000 ,  loss_val =  0.6929347097339337\n",
      "epochs =  3 , step =  39000 ,  loss_val =  1.1107007767557315\n",
      "epochs =  3 , step =  40000 ,  loss_val =  0.8500527260619858\n",
      "epochs =  3 , step =  41000 ,  loss_val =  0.7014093716859532\n",
      "epochs =  3 , step =  42000 ,  loss_val =  0.8082523266253281\n",
      "epochs =  3 , step =  43000 ,  loss_val =  0.8257315579128574\n",
      "epochs =  3 , step =  44000 ,  loss_val =  0.7783965894172644\n",
      "epochs =  3 , step =  45000 ,  loss_val =  0.8582612159456642\n",
      "epochs =  3 , step =  46000 ,  loss_val =  0.7692709450262307\n",
      "epochs =  3 , step =  47000 ,  loss_val =  0.7981981747341046\n",
      "epochs =  3 , step =  48000 ,  loss_val =  0.8222991936376518\n",
      "epochs =  3 , step =  49000 ,  loss_val =  0.7618417980228109\n",
      "epochs =  3 , step =  50000 ,  loss_val =  0.7702809484322856\n",
      "epochs =  3 , step =  51000 ,  loss_val =  0.7693015152610085\n",
      "epochs =  3 , step =  52000 ,  loss_val =  0.7392780799894907\n",
      "epochs =  3 , step =  53000 ,  loss_val =  0.8235486872763703\n",
      "epochs =  3 , step =  54000 ,  loss_val =  1.0417464181607707\n",
      "epochs =  3 , step =  55000 ,  loss_val =  0.86925813264977\n",
      "epochs =  3 , step =  56000 ,  loss_val =  0.8245501719725691\n",
      "epochs =  3 , step =  57000 ,  loss_val =  0.7871324135280771\n",
      "epochs =  3 , step =  58000 ,  loss_val =  0.8051542836475608\n",
      "epochs =  3 , step =  59000 ,  loss_val =  0.7809263051901607\n",
      "epochs =  4 , step =  0 ,  loss_val =  1.535795802147329\n",
      "epochs =  4 , step =  1000 ,  loss_val =  0.7919559576771616\n",
      "epochs =  4 , step =  2000 ,  loss_val =  5.6943369816196405\n",
      "epochs =  4 , step =  3000 ,  loss_val =  0.8880464675519806\n",
      "epochs =  4 , step =  4000 ,  loss_val =  0.8410016987031042\n",
      "epochs =  4 , step =  5000 ,  loss_val =  0.8442885151809314\n",
      "epochs =  4 , step =  6000 ,  loss_val =  0.7477082606258737\n",
      "epochs =  4 , step =  7000 ,  loss_val =  0.6705513301805546\n",
      "epochs =  4 , step =  8000 ,  loss_val =  0.7937480101294034\n",
      "epochs =  4 , step =  9000 ,  loss_val =  0.7586057428649877\n",
      "epochs =  4 , step =  10000 ,  loss_val =  0.714059252871963\n",
      "epochs =  4 , step =  11000 ,  loss_val =  0.7476184383359308\n",
      "epochs =  4 , step =  12000 ,  loss_val =  0.931705199231815\n",
      "epochs =  4 , step =  13000 ,  loss_val =  0.7901846849307324\n",
      "epochs =  4 , step =  14000 ,  loss_val =  0.845048808633906\n",
      "epochs =  4 , step =  15000 ,  loss_val =  0.8222789281531622\n",
      "epochs =  4 , step =  16000 ,  loss_val =  0.7989321504837941\n",
      "epochs =  4 , step =  17000 ,  loss_val =  0.6963063741145212\n",
      "epochs =  4 , step =  18000 ,  loss_val =  1.00349918385765\n",
      "epochs =  4 , step =  19000 ,  loss_val =  0.7049135925509735\n",
      "epochs =  4 , step =  20000 ,  loss_val =  0.8808941488171367\n",
      "epochs =  4 , step =  21000 ,  loss_val =  0.9076817263977486\n",
      "epochs =  4 , step =  22000 ,  loss_val =  0.794487625468363\n",
      "epochs =  4 , step =  23000 ,  loss_val =  0.8231032585638739\n",
      "epochs =  4 , step =  24000 ,  loss_val =  0.7285812564186014\n",
      "epochs =  4 , step =  25000 ,  loss_val =  0.8317463029108891\n",
      "epochs =  4 , step =  26000 ,  loss_val =  0.7621127597038737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  4 , step =  27000 ,  loss_val =  0.8684932983930164\n",
      "epochs =  4 , step =  28000 ,  loss_val =  0.8089909470204518\n",
      "epochs =  4 , step =  29000 ,  loss_val =  0.7859272467382314\n",
      "epochs =  4 , step =  30000 ,  loss_val =  0.7349177446675116\n",
      "epochs =  4 , step =  31000 ,  loss_val =  0.7171112431774324\n",
      "epochs =  4 , step =  32000 ,  loss_val =  0.6803370863791559\n",
      "epochs =  4 , step =  33000 ,  loss_val =  0.8174280549438198\n",
      "epochs =  4 , step =  34000 ,  loss_val =  0.8261860477124948\n",
      "epochs =  4 , step =  35000 ,  loss_val =  0.8279870020365594\n",
      "epochs =  4 , step =  36000 ,  loss_val =  1.2617808851021908\n",
      "epochs =  4 , step =  37000 ,  loss_val =  1.2515893390274078\n",
      "epochs =  4 , step =  38000 ,  loss_val =  0.6900629447653145\n",
      "epochs =  4 , step =  39000 ,  loss_val =  2.5221061338939306\n",
      "epochs =  4 , step =  40000 ,  loss_val =  0.8544662532647255\n",
      "epochs =  4 , step =  41000 ,  loss_val =  0.7007659246961389\n",
      "epochs =  4 , step =  42000 ,  loss_val =  0.8111110200413213\n",
      "epochs =  4 , step =  43000 ,  loss_val =  0.8260037870012941\n",
      "epochs =  4 , step =  44000 ,  loss_val =  0.8013066519705313\n",
      "epochs =  4 , step =  45000 ,  loss_val =  0.7999218180462776\n",
      "epochs =  4 , step =  46000 ,  loss_val =  0.7787927449360816\n",
      "epochs =  4 , step =  47000 ,  loss_val =  0.8089134754669777\n",
      "epochs =  4 , step =  48000 ,  loss_val =  0.8065197324315525\n",
      "epochs =  4 , step =  49000 ,  loss_val =  0.7620057514511533\n",
      "epochs =  4 , step =  50000 ,  loss_val =  0.7145390502762127\n",
      "epochs =  4 , step =  51000 ,  loss_val =  0.7962030287690297\n",
      "epochs =  4 , step =  52000 ,  loss_val =  0.7230907454336004\n",
      "epochs =  4 , step =  53000 ,  loss_val =  0.9214535695399588\n",
      "epochs =  4 , step =  54000 ,  loss_val =  0.9393573942938362\n",
      "epochs =  4 , step =  55000 ,  loss_val =  0.8629555817360437\n",
      "epochs =  4 , step =  56000 ,  loss_val =  0.8189374943490955\n",
      "epochs =  4 , step =  57000 ,  loss_val =  0.8008222816437625\n",
      "epochs =  4 , step =  58000 ,  loss_val =  0.881173448735776\n",
      "epochs =  4 , step =  59000 ,  loss_val =  0.736200377673394\n",
      "\n",
      "elapsed time =  0:02:54.193177\n"
     ]
    }
   ],
   "source": [
    "input_nodes = 784\n",
    "\n",
    "hidden_nodes_1 = 10\n",
    "hidden_nodes_2 = 20\n",
    "hidden_nodes_3 = 10\n",
    "\n",
    "output_nodes = 10\n",
    "learning_rate = 0.1\n",
    "epochs = 5\n",
    "\n",
    "nn = NeuralNetwork(input_nodes, hidden_nodes_1, hidden_nodes_2, hidden_nodes_3, output_nodes, learning_rate)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):  # train\n",
    "    \n",
    "        # input_data, target_data normalize\n",
    "        \n",
    "        target_data = np.zeros(output_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "        #target_data = training_data[step, 0]\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "        #input_data = training_data[step, 1:]\n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i, \", step = \", step,  \",  loss_val = \", nn.loss_val())\n",
    "        \n",
    "end_time = datetime.now() \n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "test_data[0,0] =  7.0 , len(test_data[0]) =  785\n",
      "Accuracy =  90.74\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "test_input_data = test_data[ : , 1: ]\n",
    "test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))\n",
    "\n",
    "# measure accuracy\n",
    "(acc_ret, false_list) = nn.accuracy(test_input_data, test_target_data)   \n",
    "\n",
    "print('Accuracy = ', 100*acc_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
