{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 특성과 분포를 유지한채 값을 계산하기 편하게 스케일링 하는것을 정규화라 한다\n",
    "값이 너무 커질경우 컴퓨터가 계산을 하지 못하기 때문에 해준다\n",
    "\n",
    "1. max > 0\n",
    "   max - min > 0\n",
    "2. max = 0\n",
    "   max - min > 0\n",
    "3. max < 0\n",
    "   max - min > 0\n",
    "    \n",
    "데이터의 최댓값과 최솟값을 구해서 나눠주는 방식으로 정규화를 한다\n",
    "\n",
    "0< data-min/ max-min < 1 \n",
    "    \n",
    "TDD방식의 개발법\n",
    "기능검증을 위해 노드 한개만을 제공한 후 돌아가는 방식을 체크한다\n",
    "\n",
    "가중치가 많아지면 최적화가 하기 힘들어진다\n",
    "\n",
    "이번 예제의 목적1. Mnist class 구조 파악\n",
    "2. 정규화와 one-hot encoding best fit\n",
    "3. 문제점 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치미분 함수\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNist:\n",
    "    \n",
    "    # 생성자\n",
    "    # xdata, tdata => numpy.array(...)\n",
    "    def __init__(self, name, input_nodes, hidden1_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        # 2층 hidden layer unit \n",
    "        # 가중치 W, 바이어스 b 초기화\n",
    "        self.W2 = np.random.rand(input_nodes, hidden1_nodes)  \n",
    "        self.b2 = np.random.rand(hidden1_nodes)\n",
    "        \n",
    "        # 3층 hidden layer unit  \n",
    "        self.W3 = np.random.rand(hidden1_nodes, output_nodes)\n",
    "        self.b3 = np.random.rand(output_nodes)\n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        print(self.name, \" is created !!!\")\n",
    "        \n",
    "    # 손실함수\n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z2 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # 손실 값 계산\n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z2 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "            \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, input_data):    \n",
    "        \n",
    "        z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "        \n",
    "        # one-hot encoding 방식으로 하기 위한 코드 수정\n",
    "        predicted_num = np.argmax(y)\n",
    "    \n",
    "        return predicted_num\n",
    "    \n",
    "    def accuracy(self, input_data, target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        for index in range(len(input_data)):\n",
    "            \n",
    "            # one-hot encoding 방식으로 하기 위한 코드 수정\n",
    "            label = int(target_data[index])\n",
    "            \n",
    "            predicted_num = self.predict(input_data[index])\n",
    "            \n",
    "            if predicted_num == label:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "        accuracy_result = len(matched_list) / len(input_data)\n",
    "        \n",
    "        #print(\"Accuracy => \", accuracy_result)\n",
    "        \n",
    "        return not_matched_list, accuracy_result\n",
    "        \n",
    "        \n",
    "    # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
    "    def train(self, input_data, target_data):\n",
    "        \n",
    "        self.input_data = input_data\n",
    "        self.target_data = target_data\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "    \n",
    "        self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "        \n",
    "        self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "    \n",
    "        self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration:\n",
    "    \n",
    "    # target_position = 0 (첫번째열이 정답데이터), target_position=-1 (마지막열이 정답데이터)\n",
    "    def __init__(self, name, file_path, seperation_rate, target_position=-1):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        \n",
    "        self.seperation_rate = seperation_rate\n",
    "        \n",
    "        if (target_position == -1  or  target_position == 0):      \n",
    "            self.target_position = target_position\n",
    "        \n",
    "        else:\n",
    "            err_str = 'target_position must be -1 or 0'            \n",
    "            raise Exception(err_str)    \n",
    "            \n",
    "    \n",
    "    # print data target distribution \n",
    "    # str_of_kind : 'original data' or  'training data'  or  'test data'\n",
    "    def __display_target_distribution(self, data, str_of_kind='original data'):\n",
    "        \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        target_data = data[ :, self.target_position ]\n",
    "        \n",
    "        # numpy.unique() 사용하여 loaded data target 분포 확인\n",
    "        unique, counts = np.unique(target_data, return_counts=True)\n",
    "\n",
    "        unique_target = []\n",
    "    \n",
    "        for index in range(len(unique)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique[index], ', count = ', counts[index])\n",
    "        \n",
    "            unique_target.append(unique[index])\n",
    "\n",
    "        for index in range(len(unique_target)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique_target[index], ', ratio = ', np.round(100 * counts[index] / (target_data.shape[0]), 2), ' %')\n",
    "    \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        \n",
    "    # numpy.random.shuffle()  이용하여 training_data / test_data 생성\n",
    "    def generate(self):\n",
    "    \n",
    "        # 데이터 불러오기, 파일이 없는 경우 exception 발생\n",
    "\n",
    "        try:\n",
    "            loaded_data = np.loadtxt(self.file_path, delimiter=',', dtype=np.float32)\n",
    "            \n",
    "        except Exception as err:\n",
    "            print('[DataGeneration::generate()]  ', str(err))\n",
    "            raise Exception(str(err))\n",
    "\n",
    "        print(\"[DataGeneration]  loaded_data.shape = \", loaded_data.shape)\n",
    "            \n",
    "        # print the target distribution of original data \n",
    "        \n",
    "        self.__display_target_distribution(loaded_data, 'original data')\n",
    "        \n",
    "        \n",
    "        # 분리비율에 맞게 테스트데이터로 분리\n",
    "        total_data_num = len(loaded_data)\n",
    "        test_data_num = int(len(loaded_data) * self.seperation_rate)\n",
    "\n",
    "        # numpy.random.shuffle 을 이용하여 랜덤하게 데이터 섞기\n",
    "        np.random.shuffle(loaded_data)\n",
    "        \n",
    "        # test_data 는 0 : test_data_num\n",
    "        \n",
    "        \n",
    "        test_data = loaded_data[ 0:test_data_num ]\n",
    "\n",
    "        # training_data 는 test_data_num 부터 끝까지 \n",
    "        training_data = loaded_data[ test_data_num: ]\n",
    "\n",
    "        # display target distribution of generated data \n",
    "        \n",
    "        self.__display_target_distribution(training_data, 'training data')\n",
    "        \n",
    "        self.__display_target_distribution(test_data, 'test data')\n",
    "        \n",
    "        return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape =  (60000, 785)\n",
      "training_input_data.shape =  (60000, 784) , training_target_data.shape =  (60000,)\n",
      "test_data.shape =  (10000, 785)\n",
      "test_input_data.shape =  (10000, 784) , test_target_data.shape =  (10000,)\n"
     ]
    }
   ],
   "source": [
    "training_data = np.loadtxt('./mnist_train.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "print(\"training_data.shape = \", training_data.shape)\n",
    "\n",
    "training_input_data = training_data[ : , 1: ]\n",
    "training_target_data = training_data[ : , 0 ]\n",
    "\n",
    "print(\"training_input_data.shape = \", training_input_data.shape, ', training_target_data.shape = ', training_target_data.shape)\n",
    "\n",
    "test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "\n",
    "test_input_data = test_data[ : , 1: ]\n",
    "test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "print(\"test_input_data.shape = \", test_input_data.shape, ', test_target_data.shape = ', test_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_input_val =  255.0 , max_target_val =  9.0\n",
      "min_input_val =  0.0 , min_target_val =  0.0\n"
     ]
    }
   ],
   "source": [
    "# max / min\n",
    "max_input_val = np.max(training_input_data)\n",
    "max_target_val = np.max(training_target_data)\n",
    "\n",
    "min_input_val = np.min(training_input_data)\n",
    "min_target_val = np.min(training_target_data)\n",
    "\n",
    "\n",
    "\n",
    "print('max_input_val = ', max_input_val, ', max_target_val = ', max_target_val)\n",
    "print('min_input_val = ', min_input_val, ', min_target_val = ', min_target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each_max_val =  [255. 255. 255. ... 255. 255. 254.] , len(each_max_val) =  10000\n",
      "each_min_val =  [0. 0. 0. ... 0. 0. 0.] , len(each_min_val) =  10000\n"
     ]
    }
   ],
   "source": [
    "each_max_val = np.max(training_input_data, axis=1)    # 각 행의 최대값\n",
    "each_min_val = np.min(training_input_data, axis=1)    # 각 행의 최소값\n",
    "\n",
    "print('each_max_val = ', each_max_val, ', len(each_max_val) = ', len(each_max_val))\n",
    "print('each_min_val = ', each_min_val, ', len(each_min_val) = ', len(each_min_val))\n",
    "\n",
    "# axis = 0 지정하면 각 열의 최대 값과 최소 값을 구할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist  is created !!!\n",
      "Neural Network Learning using Numerical Derivative...\n",
      "step =  0  , current loss value =  0.11200266932457137\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ba6fe3fd3017>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# 0으로 초기화 후 원핫 인코딩 방식으로 표현\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mobj1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mcur_loss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-d13ad9ddd5c6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_data, target_data)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnumerical_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnumerical_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-c816f05539e5>\u001b[0m in \u001b[0;36mnumerical_derivative\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdelta_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mfx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# f(x-delta_x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfx1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfx2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdelta_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-d13ad9ddd5c6>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnumerical_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-d13ad9ddd5c6>\u001b[0m in \u001b[0;36mfeed_forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-7\u001b[0m    \u001b[1;31m# log 무한대 발산 방지\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mz2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i_nodes = training_data.shape[1] - 1    # input nodes 개수\n",
    "h1_nodes = 1  # hidden 1 nodes 개수. \n",
    "\n",
    "o_nodes = 2    # one-hot encoding 표현하기 위한 output nodes 개수는 2개. 즉 정답은 0 또는 1 두개만 있음\n",
    "\n",
    "lr = 1e-2      # learning rate. hi_node = 2, 1e-1 에서 수렴\n",
    "epochs = 20   # 반복횟수. \n",
    "\n",
    "# 저장 리스트\n",
    "loss_val_list = []    # loss val list\n",
    "\n",
    "# Diabetes 객체 생성\n",
    "obj1 = MNist(\"Mnist\", i_nodes, h1_nodes, o_nodes, lr)\n",
    "\n",
    "print(\"Neural Network Learning using Numerical Derivative...\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in range(epochs):\n",
    "    \n",
    "    for index in range(len(training_data)):\n",
    "        \n",
    "        input_data = training_data[index, 0:-1]\n",
    "        \n",
    "        # one-hot encoding 방식으로 표현                \n",
    "        target_data = np.zeros(o_nodes) + 0.01    \n",
    "        target_data[int(training_data[index, -1])] = 0.99\n",
    "        # 0으로 초기화 후 원핫 인코딩 방식으로 표현\n",
    "        \n",
    "        obj1.train(input_data, target_data)\n",
    "        \n",
    "    cur_loss_val = obj1.loss_val()    \n",
    "    loss_val_list.append(cur_loss_val)\n",
    "    \n",
    "    print(\"step = \", step, \" , current loss value = \", cur_loss_val)\n",
    "\n",
    "end_time = datetime.now()\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
