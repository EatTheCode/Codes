{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add_4:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_1:0\", shape=(2, 2), dtype=float32)\n",
      "[1.0, 2.0]\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "[3.0]\n",
      "[[2. 3.]\n",
      " [4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "# 상수 노드\n",
    "a = tf.constant(1.0, name='a')\n",
    "b = tf.constant(2.0, name='b')\n",
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "print(a)\n",
    "print(a+b)\n",
    "print(c)\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run([a, b]))\n",
    "print(sess.run(c))\n",
    "print(sess.run([a+b]))\n",
    "print(sess.run(c+1.0))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "[4. 6.]\n",
      "400.0\n",
      "[400. 600.]\n"
     ]
    }
   ],
   "source": [
    "# 플레이스 홀더 노드 정의\n",
    "# 외부의 값을 일정한 값을 주고 통과시켜주는 개념\n",
    "a = tf.placeholder(tf.float32) # 정해진 데이터 타입을 받아들인다(초기화값이 업음)\n",
    "b = tf.placeholder(tf.float32)\n",
    "c = a+b\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(c, feed_dict={a:1.0, b:3.0}))\n",
    "print(sess.run(c, feed_dict={a: [1.0, 2.0], b: [3.0, 4.0]}))\n",
    "\n",
    "d = 100*c\n",
    "\n",
    "print(sess.run(d, feed_dict={a: 1.0, b: 3.0}))\n",
    "print(sess.run(d, feed_dict={a: [1.0, 2.0], b: [3.0, 4.0]}))\n",
    "\n",
    "sess.close()\n",
    "# 플레이스 홀더 노드는 머신러닝/딥러닝에서 입려데이터와 정답데이터를 넣어주기 위한 용도로 주로 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , W1 = [-1.0889447] , b1 = [0.7214796]\n",
      "step =  0 , W1 = [[ 0.2840601 -1.0565977]] , b1 = [[-2.9026425  1.2237296]]\n",
      "step =  1 , W1 = [-2.0889447] , b1 = [-1.2785203]\n",
      "step =  1 , W1 = [[-0.7159399 -2.0565977]] , b1 = [[-2.9026425  1.2237296]]\n",
      "step =  2 , W1 = [-4.0889444] , b1 = [-5.2785206]\n",
      "step =  2 , W1 = [[-2.71594   -4.0565977]] , b1 = [[-2.9026425  1.2237296]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseSession.close of <tensorflow.python.client.session.Session object at 0x00000265538ABC88>>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = tf.Variable(tf.random_normal([1]))  # 가우시안 분포(Xavier/He)\n",
    "b1 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1, 2]))\n",
    "b2 = tf.Variable(tf.random_normal([1,2]))\n",
    "\n",
    "sess =  tf.Session()\n",
    "\n",
    "# 변수노드값 초기화\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3):\n",
    "    \n",
    "    W1 = W1 - step        # 변수 노드 업데이트\n",
    "    b1 = b1 - step\n",
    "    \n",
    "    W2 = W2 - step\n",
    "    b1 = b1 - step\n",
    "    \n",
    "    print(\"step = \", step, \", W1 =\", sess.run(W1), \", b1 =\", sess.run(b1))\n",
    "    print(\"step = \", step, \", W1 =\", sess.run(W2), \", b1 =\", sess.run(b2))\n",
    "    \n",
    "sess.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3) (25, 1)\n"
     ]
    }
   ],
   "source": [
    "loaded_data = np.loadtxt(\"./(200221)data-01.csv\", delimiter=',')\n",
    "\n",
    "x_data = loaded_data[ :, 0:-1]\n",
    "t_data = loaded_data[ :, [-1]]\n",
    "\n",
    "print(x_data.shape, t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 3]) # 행은 상관없이 열에 맞춰라\n",
    "T = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.matmul(X, W) + b  # 현재 X, W, b 를 바탕으로 계산된 값(np.dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y-T))   # MSE 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(1e-5)  # 경사하상법 알고리즘 optimizer\n",
    "\n",
    "train = optimizer.minimize(loss)\n",
    "# optimizer를 통한 손실함수 최소화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , loss_val =  1780.1125\n",
      "step =  400 , loss_val =  9.3128605\n",
      "step =  800 , loss_val =  8.664615\n",
      "step =  1200 , loss_val =  8.135008\n",
      "step =  1600 , loss_val =  7.702188\n",
      "step =  2000 , loss_val =  7.3483486\n",
      "step =  2400 , loss_val =  7.059034\n",
      "step =  2800 , loss_val =  6.822423\n",
      "step =  3200 , loss_val =  6.628871\n",
      "step =  3600 , loss_val =  6.4705267\n",
      "step =  4000 , loss_val =  6.3409724\n",
      "step =  4400 , loss_val =  6.2349434\n",
      "step =  4800 , loss_val =  6.1481905\n",
      "step =  5200 , loss_val =  6.0771785\n",
      "step =  5600 , loss_val =  6.0190334\n",
      "step =  6000 , loss_val =  5.971471\n",
      "step =  6400 , loss_val =  5.9325166\n",
      "step =  6800 , loss_val =  5.9006476\n",
      "step =  7200 , loss_val =  5.8745294\n",
      "step =  7600 , loss_val =  5.853156\n",
      "step =  8000 , loss_val =  5.83566\n",
      "step =  8400 , loss_val =  5.8213325\n",
      "step =  8800 , loss_val =  5.809608\n",
      "step =  9200 , loss_val =  5.799994\n",
      "step =  9600 , loss_val =  5.7921276\n",
      "step =  10000 , loss_val =  5.7856975\n",
      "step =  10400 , loss_val =  5.7804236\n",
      "step =  10800 , loss_val =  5.776097\n",
      "step =  11200 , loss_val =  5.7725525\n",
      "step =  11600 , loss_val =  5.7696643\n",
      "step =  12000 , loss_val =  5.767297\n",
      "step =  12400 , loss_val =  5.7653446\n",
      "step =  12800 , loss_val =  5.7637553\n",
      "step =  13200 , loss_val =  5.7624555\n",
      "step =  13600 , loss_val =  5.761387\n",
      "step =  14000 , loss_val =  5.7605004\n",
      "step =  14400 , loss_val =  5.7597933\n",
      "step =  14800 , loss_val =  5.759201\n",
      "step =  15200 , loss_val =  5.758708\n",
      "step =  15600 , loss_val =  5.7583055\n",
      "step =  16000 , loss_val =  5.757972\n",
      "step =  16400 , loss_val =  5.757707\n",
      "step =  16800 , loss_val =  5.757492\n",
      "step =  17200 , loss_val =  5.757306\n",
      "step =  17600 , loss_val =  5.75716\n",
      "step =  18000 , loss_val =  5.757025\n",
      "step =  18400 , loss_val =  5.756914\n",
      "step =  18800 , loss_val =  5.756834\n",
      "step =  19200 , loss_val =  5.7567725\n",
      "step =  19600 , loss_val =  5.756688\n",
      "step =  20000 , loss_val =  5.7566543\n",
      "step =  20400 , loss_val =  5.756596\n",
      "step =  20800 , loss_val =  5.7565675\n",
      "step =  21200 , loss_val =  5.756529\n",
      "step =  21600 , loss_val =  5.756503\n",
      "step =  22000 , loss_val =  5.756483\n",
      "step =  22400 , loss_val =  5.7564783\n",
      "step =  22800 , loss_val =  5.756446\n",
      "step =  23200 , loss_val =  5.7564397\n",
      "step =  23600 , loss_val =  5.7564282\n",
      "step =  24000 , loss_val =  5.7564015\n",
      "step =  24400 , loss_val =  5.756396\n",
      "step =  24800 , loss_val =  5.7563767\n",
      "step =  25200 , loss_val =  5.7563806\n",
      "step =  25600 , loss_val =  5.756361\n",
      "step =  26000 , loss_val =  5.7563624\n",
      "step =  26400 , loss_val =  5.7563415\n",
      "step =  26800 , loss_val =  5.756343\n",
      "step =  27200 , loss_val =  5.756326\n",
      "step =  27600 , loss_val =  5.7563195\n",
      "step =  28000 , loss_val =  5.7563148\n",
      "step =  28400 , loss_val =  5.7563124\n",
      "step =  28800 , loss_val =  5.756289\n",
      "step =  29200 , loss_val =  5.7562904\n",
      "step =  29600 , loss_val =  5.756286\n",
      "step =  30000 , loss_val =  5.7562733\n",
      "step =  30400 , loss_val =  5.756259\n",
      "step =  30800 , loss_val =  5.7562523\n",
      "step =  31200 , loss_val =  5.756258\n",
      "step =  31600 , loss_val =  5.7562404\n",
      "step =  32000 , loss_val =  5.756234\n",
      "step =  32400 , loss_val =  5.756224\n",
      "step =  32800 , loss_val =  5.756219\n",
      "step =  33200 , loss_val =  5.75621\n",
      "step =  33600 , loss_val =  5.756209\n",
      "step =  34000 , loss_val =  5.756202\n",
      "step =  34400 , loss_val =  5.756186\n",
      "step =  34800 , loss_val =  5.7561793\n",
      "step =  35200 , loss_val =  5.7561793\n",
      "step =  35600 , loss_val =  5.7561674\n",
      "step =  36000 , loss_val =  5.7561603\n",
      "step =  36400 , loss_val =  5.756154\n",
      "step =  36800 , loss_val =  5.7561564\n",
      "step =  37200 , loss_val =  5.7561383\n",
      "step =  37600 , loss_val =  5.756125\n",
      "step =  38000 , loss_val =  5.756127\n",
      "step =  38400 , loss_val =  5.756123\n",
      "step =  38800 , loss_val =  5.756116\n",
      "step =  39200 , loss_val =  5.7561064\n",
      "step =  39600 , loss_val =  5.756108\n",
      "step =  40000 , loss_val =  5.7560887\n",
      "step =  40400 , loss_val =  5.756092\n",
      "step =  40800 , loss_val =  5.7560673\n",
      "step =  41200 , loss_val =  5.756073\n",
      "step =  41600 , loss_val =  5.7560563\n",
      "step =  42000 , loss_val =  5.756059\n",
      "step =  42400 , loss_val =  5.7560554\n",
      "step =  42800 , loss_val =  5.756041\n",
      "step =  43200 , loss_val =  5.7560315\n",
      "step =  43600 , loss_val =  5.75602\n",
      "step =  44000 , loss_val =  5.7560234\n",
      "step =  44400 , loss_val =  5.756008\n",
      "step =  44800 , loss_val =  5.7559967\n",
      "step =  45200 , loss_val =  5.7559896\n",
      "step =  45600 , loss_val =  5.7559857\n",
      "step =  46000 , loss_val =  5.755979\n",
      "step =  46400 , loss_val =  5.7559834\n",
      "step =  46800 , loss_val =  5.7559752\n",
      "step =  47200 , loss_val =  5.7559595\n",
      "step =  47600 , loss_val =  5.7559576\n",
      "step =  48000 , loss_val =  5.7559495\n",
      "step =  48400 , loss_val =  5.7559443\n",
      "step =  48800 , loss_val =  5.7559342\n",
      "step =  49200 , loss_val =  5.7559333\n",
      "step =  49600 , loss_val =  5.755922\n",
      "step =  50000 , loss_val =  5.7559175\n",
      "step =  50400 , loss_val =  5.7559075\n",
      "step =  50800 , loss_val =  5.7558937\n",
      "step =  51200 , loss_val =  5.7558994\n",
      "step =  51600 , loss_val =  5.7558804\n",
      "step =  52000 , loss_val =  5.755871\n",
      "step =  52400 , loss_val =  5.7558722\n",
      "step =  52800 , loss_val =  5.7558537\n",
      "step =  53200 , loss_val =  5.75586\n",
      "step =  53600 , loss_val =  5.755851\n",
      "step =  54000 , loss_val =  5.755859\n",
      "step =  54400 , loss_val =  5.7558374\n",
      "step =  54800 , loss_val =  5.755824\n",
      "step =  55200 , loss_val =  5.7558303\n",
      "step =  55600 , loss_val =  5.755808\n",
      "step =  56000 , loss_val =  5.7558117\n",
      "step =  56400 , loss_val =  5.755797\n",
      "step =  56800 , loss_val =  5.755804\n",
      "step =  57200 , loss_val =  5.7557817\n",
      "step =  57600 , loss_val =  5.7557845\n",
      "step =  58000 , loss_val =  5.75578\n",
      "step =  58400 , loss_val =  5.7557597\n",
      "step =  58800 , loss_val =  5.7557616\n",
      "step =  59200 , loss_val =  5.755757\n",
      "step =  59600 , loss_val =  5.755746\n",
      "step =  60000 , loss_val =  5.755729\n",
      "step =  60400 , loss_val =  5.755728\n",
      "step =  60800 , loss_val =  5.7557125\n",
      "step =  61200 , loss_val =  5.7557063\n",
      "step =  61600 , loss_val =  5.7557135\n",
      "step =  62000 , loss_val =  5.7556963\n",
      "step =  62400 , loss_val =  5.7556868\n",
      "step =  62800 , loss_val =  5.755681\n",
      "step =  63200 , loss_val =  5.755675\n",
      "step =  63600 , loss_val =  5.7556553\n",
      "step =  64000 , loss_val =  5.755664\n",
      "step =  64400 , loss_val =  5.755661\n",
      "step =  64800 , loss_val =  5.75564\n",
      "step =  65200 , loss_val =  5.75565\n",
      "step =  65600 , loss_val =  5.7556286\n",
      "step =  66000 , loss_val =  5.755629\n",
      "step =  66400 , loss_val =  5.7556148\n",
      "step =  66800 , loss_val =  5.755624\n",
      "step =  67200 , loss_val =  5.7556114\n",
      "step =  67600 , loss_val =  5.7556005\n",
      "step =  68000 , loss_val =  5.7556014\n",
      "step =  68400 , loss_val =  5.755579\n",
      "step =  68800 , loss_val =  5.755567\n",
      "step =  69200 , loss_val =  5.755582\n",
      "step =  69600 , loss_val =  5.755558\n",
      "step =  70000 , loss_val =  5.755568\n",
      "step =  70400 , loss_val =  5.755542\n",
      "step =  70800 , loss_val =  5.7555475\n",
      "step =  71200 , loss_val =  5.755553\n",
      "step =  71600 , loss_val =  5.755526\n",
      "step =  72000 , loss_val =  5.755526\n",
      "step =  72400 , loss_val =  5.7555084\n",
      "step =  72800 , loss_val =  5.755512\n",
      "step =  73200 , loss_val =  5.7554913\n",
      "step =  73600 , loss_val =  5.7554994\n",
      "step =  74000 , loss_val =  5.7554874\n",
      "step =  74400 , loss_val =  5.755475\n",
      "step =  74800 , loss_val =  5.7554674\n",
      "step =  75200 , loss_val =  5.755472\n",
      "step =  75600 , loss_val =  5.7554674\n",
      "step =  76000 , loss_val =  5.7554674\n",
      "step =  76400 , loss_val =  5.755441\n",
      "step =  76800 , loss_val =  5.755438\n",
      "step =  77200 , loss_val =  5.7554297\n",
      "step =  77600 , loss_val =  5.7554274\n",
      "step =  78000 , loss_val =  5.7554207\n",
      "step =  78400 , loss_val =  5.755397\n",
      "step =  78800 , loss_val =  5.7554073\n",
      "step =  79200 , loss_val =  5.755393\n",
      "step =  79600 , loss_val =  5.7553954\n",
      "step =  80000 , loss_val =  5.7553797\n",
      "step =  80400 , loss_val =  5.755374\n",
      "step =  80800 , loss_val =  5.755374\n",
      "step =  81200 , loss_val =  5.7553644\n",
      "step =  81600 , loss_val =  5.7553535\n",
      "step =  82000 , loss_val =  5.755354\n",
      "step =  82400 , loss_val =  5.7553387\n",
      "step =  82800 , loss_val =  5.7553453\n",
      "step =  83200 , loss_val =  5.755323\n",
      "step =  83600 , loss_val =  5.755324\n",
      "step =  84000 , loss_val =  5.7553124\n",
      "step =  84400 , loss_val =  5.755295\n",
      "step =  84800 , loss_val =  5.7552934\n",
      "step =  85200 , loss_val =  5.7552886\n",
      "step =  85600 , loss_val =  5.7552752\n",
      "step =  86000 , loss_val =  5.755264\n",
      "step =  86400 , loss_val =  5.7552586\n",
      "step =  86800 , loss_val =  5.75528\n",
      "step =  87200 , loss_val =  5.7552643\n",
      "step =  87600 , loss_val =  5.755249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  88000 , loss_val =  5.7552423\n",
      "step =  88400 , loss_val =  5.755246\n",
      "step =  88800 , loss_val =  5.755234\n",
      "step =  89200 , loss_val =  5.755221\n",
      "step =  89600 , loss_val =  5.755214\n",
      "step =  90000 , loss_val =  5.755205\n",
      "step =  90400 , loss_val =  5.7552004\n",
      "step =  90800 , loss_val =  5.7551928\n",
      "step =  91200 , loss_val =  5.755181\n",
      "step =  91600 , loss_val =  5.7551713\n",
      "step =  92000 , loss_val =  5.7551646\n",
      "step =  92400 , loss_val =  5.7551622\n",
      "step =  92800 , loss_val =  5.7551656\n",
      "step =  93200 , loss_val =  5.755146\n",
      "step =  93600 , loss_val =  5.7551446\n",
      "step =  94000 , loss_val =  5.755136\n",
      "step =  94400 , loss_val =  5.7551265\n",
      "step =  94800 , loss_val =  5.755119\n",
      "step =  95200 , loss_val =  5.7551174\n",
      "step =  95600 , loss_val =  5.7551055\n",
      "step =  96000 , loss_val =  5.755107\n",
      "step =  96400 , loss_val =  5.7550993\n",
      "step =  96800 , loss_val =  5.75509\n",
      "step =  97200 , loss_val =  5.7550783\n",
      "step =  97600 , loss_val =  5.7550774\n",
      "step =  98000 , loss_val =  5.7550707\n",
      "step =  98400 , loss_val =  5.7550635\n",
      "step =  98800 , loss_val =  5.755046\n",
      "step =  99200 , loss_val =  5.7550464\n",
      "step =  99600 , loss_val =  5.7550416\n",
      "step =  100000 , loss_val =  5.7550306\n",
      "prediction is  [[178.963]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())   # 변수 노드(tf.Variable)초기화\n",
    "    for step in range(100001):\n",
    "        loss_val, y_val, _ = sess.run([loss, y, train], feed_dict={X: x_data, T: t_data})\n",
    "        \n",
    "        if step % 400 == 0:\n",
    "            print(\"step = \", step, \", loss_val = \", loss_val)\n",
    "            \n",
    "            \n",
    "    print(\"prediction is \", sess.run(y, feed_dict={X: [[100, 98, 81]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded_data = (759, 9)\n",
      "x_data =  (759, 8) , t_data =  (759, 1)\n"
     ]
    }
   ],
   "source": [
    "loaded_data = np.loadtxt('./(200309)diabetes.csv',delimiter=',' )\n",
    "\n",
    "x_data = loaded_data[ :, 0:-1]\n",
    "t_data = loaded_data[ :, [-1]]\n",
    "\n",
    "print(\"loaded_data =\", loaded_data.shape)\n",
    "print(\"x_data = \", x_data.shape, \", t_data = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 8])\n",
    "T = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.matmul(X, W) + b  # 선형회귀 값\n",
    "\n",
    "y = tf.sigmoid(z)    # 시그모이드 계산값\n",
    "\n",
    "loss = -tf.reduce_mean( T*tf.log(y) + (1-T)*tf.log(1-y))   # 시그모이드 함수(+_delta가 빠짐 내부에서 구조적으로 잡아줌)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)   # W와 b값을 업데이트\n",
    "\n",
    "# loss - optimizer, z에 w, b가 업데이트 된다\n",
    "# 결국 loss는 y 와 z 에 따라서 변화하고 따라 올라가면 z와 y 는 w와 b로 연결된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(y > 0.5, dtype = tf.float32)\n",
    "# tf.cast = true는 1로 false는 0으로 바꿔주는 메소드\n",
    "# (759, 1)로 바꿔줌 y의 모든값을 행렬로 갖고있음\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, T), dtype = tf.float32))\n",
    "# predicted 된 값과 T값을 비교해서 또 true of false값으로 반환 즉 1의총합/759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , loss_val =  0.82745427\n",
      "step =  1000 , loss_val =  0.61675453\n",
      "step =  2000 , loss_val =  0.5715868\n",
      "step =  3000 , loss_val =  0.5428321\n",
      "step =  4000 , loss_val =  0.5238288\n",
      "step =  5000 , loss_val =  0.5108163\n",
      "step =  6000 , loss_val =  0.5016296\n",
      "step =  7000 , loss_val =  0.49497622\n",
      "step =  8000 , loss_val =  0.49005377\n",
      "step =  9000 , loss_val =  0.48634577\n",
      "step =  10000 , loss_val =  0.48350954\n",
      "step =  11000 , loss_val =  0.48131073\n",
      "step =  12000 , loss_val =  0.47958606\n",
      "step =  13000 , loss_val =  0.4782192\n",
      "step =  14000 , loss_val =  0.47712573\n",
      "step =  15000 , loss_val =  0.47624376\n",
      "step =  16000 , loss_val =  0.47552666\n",
      "step =  17000 , loss_val =  0.47493964\n",
      "step =  18000 , loss_val =  0.47445595\n",
      "step =  19000 , loss_val =  0.47405502\n",
      "step =  20000 , loss_val =  0.4737208\n",
      "y_val.shape =  (759, 1) , predicted_val =  (759, 1)\n",
      "Accuracy =  0.770751\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())   # 변수 노드(tf.Variable)초기화\n",
    "    for step in range(20001):\n",
    "        loss_val, _ = sess.run([loss, train], feed_dict={X: x_data, T: t_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\"step = \", step, \", loss_val = \", loss_val)\n",
    "            \n",
    "    y_val, predicted_val, accuracy_val = sess.run([y, predicted, accuracy], feed_dict = {X: x_data, T: t_data})\n",
    "    #                                               y, predicted, accuracy값을 feed_dict에있는 인자로 받아서 y_val, predicted_val, accuracy_val로 반환\n",
    "            \n",
    "    print(\"y_val.shape = \", y_val.shape, \", predicted_val = \", predicted_val.shape)\n",
    "    print(\"Accuracy = \", accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "가상화란 물리적인걸 논리적으로 바꿔주는것을 뜻한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
