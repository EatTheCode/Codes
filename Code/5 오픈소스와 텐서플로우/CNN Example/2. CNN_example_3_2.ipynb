{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wcEVJdRCeXO1",
    "outputId": "5c105c63-ccd8-4677-f65a-ada7301d8e6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "eprj1ComWHp7",
    "outputId": "58b65a34-883b-483b-a998-806c7f042791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      " 55000 10000 5000\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
    "\n",
    "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
    "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
    "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
    "\n",
    "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
    "\n",
    "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
    "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
    "\n",
    "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
    "print(\"test image shape = \", np.shape(mnist.test.images))\n",
    "print(\"test label shape = \", np.shape(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMI0w-KUeXO7"
   },
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 0.001  # 학습율\n",
    "epochs = 30            # 반복횟수\n",
    "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJX7CkOFeXPA"
   },
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # image 28X28X1 (black/white)\n",
    "\n",
    "\n",
    "T = tf.placeholder(tf.float32, [None, 10])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aThyxBVeXPE"
   },
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))  \n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[32]))   \n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 X 28 X1  => 28 X 28 X 32 \n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 X 28 X 32  => 14 X 14 X 32 \n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUEChtlgeXPI"
   },
   "outputs": [],
   "source": [
    "# 2번째 컨볼루션 층, 3X3X32 개 필터\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))  \n",
    "b3 = tf.Variable(tf.constant(0.1, shape=[64]))   \n",
    "\n",
    "# 2번째 컨볼루션 연산을 통해 14 X 14 X 32 => 14 X 14 X 64 \n",
    "C3 = tf.nn.conv2d(A2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z3 = tf.nn.relu(C3+b3)\n",
    "\n",
    "# 2번째 max pooling을 통해 14 X 14 X 64 => 7 X 7 X 64\n",
    "# 이 이상 컨볼루션 층을 추가한다면 패딩이 적용되어 2X2에 맞는 형태로 늘어난다\n",
    "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WB9boOK0eXPM"
   },
   "outputs": [],
   "source": [
    "# 7X7 크기를 가진 64개의 activation map을 flatten 시킴\n",
    "A3_flat = P3_flat = tf.reshape(A3, [-1, 7*7*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvpTuu89eXPR"
   },
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W4 = tf.Variable(tf.random_normal([7*7*64, 10], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀  값 Z4, 즉 softmax 에 들어가는 입력 값\n",
    "Z4 = logits = tf.matmul(A3_flat, W4) + b4    # 선형회귀 값 Z4\n",
    "\n",
    "y = A4 = tf.nn.softmax(Z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WuEvwMjVeXPV"
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z4, labels=T) )\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DwYNZP2qeXPY"
   },
   "outputs": [],
   "source": [
    "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal( tf.argmax(A4, 1), tf.argmax(T, 1) )\n",
    "\n",
    "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "# 예측값 처리\n",
    "predicted_list = tf.argmax(A4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "woyijCk2eXPc",
    "outputId": "b1c42983-d3af-4217-f099-668e978a7b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.4780285\n",
      "epochs =  0 , step =  100 , loss_val =  0.5929743\n",
      "epochs =  0 , step =  200 , loss_val =  0.36183265\n",
      "epochs =  0 , step =  300 , loss_val =  0.23092446\n",
      "epochs =  0 , step =  400 , loss_val =  0.18114568\n",
      "epochs =  0 , step =  500 , loss_val =  0.28777894\n",
      "epochs =  1 , step =  0 , loss_val =  0.30198997\n",
      "epochs =  1 , step =  100 , loss_val =  0.1141362\n",
      "epochs =  1 , step =  200 , loss_val =  0.10724768\n",
      "epochs =  1 , step =  300 , loss_val =  0.10307771\n",
      "epochs =  1 , step =  400 , loss_val =  0.109488726\n",
      "epochs =  1 , step =  500 , loss_val =  0.021022923\n",
      "epochs =  2 , step =  0 , loss_val =  0.12754025\n",
      "epochs =  2 , step =  100 , loss_val =  0.049061295\n",
      "epochs =  2 , step =  200 , loss_val =  0.03714746\n",
      "epochs =  2 , step =  300 , loss_val =  0.033555944\n",
      "epochs =  2 , step =  400 , loss_val =  0.04672038\n",
      "epochs =  2 , step =  500 , loss_val =  0.04824041\n",
      "epochs =  3 , step =  0 , loss_val =  0.037672922\n",
      "epochs =  3 , step =  100 , loss_val =  0.051184207\n",
      "epochs =  3 , step =  200 , loss_val =  0.033377875\n",
      "epochs =  3 , step =  300 , loss_val =  0.15112266\n",
      "epochs =  3 , step =  400 , loss_val =  0.073942155\n",
      "epochs =  3 , step =  500 , loss_val =  0.024764769\n",
      "epochs =  4 , step =  0 , loss_val =  0.034635615\n",
      "epochs =  4 , step =  100 , loss_val =  0.0853824\n",
      "epochs =  4 , step =  200 , loss_val =  0.032511946\n",
      "epochs =  4 , step =  300 , loss_val =  0.16440135\n",
      "epochs =  4 , step =  400 , loss_val =  0.0639936\n",
      "epochs =  4 , step =  500 , loss_val =  0.093861826\n",
      "epochs =  5 , step =  0 , loss_val =  0.030470647\n",
      "epochs =  5 , step =  100 , loss_val =  0.0744078\n",
      "epochs =  5 , step =  200 , loss_val =  0.06695494\n",
      "epochs =  5 , step =  300 , loss_val =  0.023550214\n",
      "epochs =  5 , step =  400 , loss_val =  0.03500651\n",
      "epochs =  5 , step =  500 , loss_val =  0.04880275\n",
      "epochs =  6 , step =  0 , loss_val =  0.022453608\n",
      "epochs =  6 , step =  100 , loss_val =  0.053766698\n",
      "epochs =  6 , step =  200 , loss_val =  0.032496873\n",
      "epochs =  6 , step =  300 , loss_val =  0.033763003\n",
      "epochs =  6 , step =  400 , loss_val =  0.006806735\n",
      "epochs =  6 , step =  500 , loss_val =  0.07815156\n",
      "epochs =  7 , step =  0 , loss_val =  0.005305454\n",
      "epochs =  7 , step =  100 , loss_val =  0.03525832\n",
      "epochs =  7 , step =  200 , loss_val =  0.06121848\n",
      "epochs =  7 , step =  300 , loss_val =  0.091368735\n",
      "epochs =  7 , step =  400 , loss_val =  0.020455634\n",
      "epochs =  7 , step =  500 , loss_val =  0.04627381\n",
      "epochs =  8 , step =  0 , loss_val =  0.015714835\n",
      "epochs =  8 , step =  100 , loss_val =  0.015542228\n",
      "epochs =  8 , step =  200 , loss_val =  0.0039510857\n",
      "epochs =  8 , step =  300 , loss_val =  0.0119028725\n",
      "epochs =  8 , step =  400 , loss_val =  0.00635981\n",
      "epochs =  8 , step =  500 , loss_val =  0.015216892\n",
      "epochs =  9 , step =  0 , loss_val =  0.03577234\n",
      "epochs =  9 , step =  100 , loss_val =  0.020784559\n",
      "epochs =  9 , step =  200 , loss_val =  0.11377272\n",
      "epochs =  9 , step =  300 , loss_val =  0.01942626\n",
      "epochs =  9 , step =  400 , loss_val =  0.008685409\n",
      "epochs =  9 , step =  500 , loss_val =  0.04201881\n",
      "epochs =  10 , step =  0 , loss_val =  0.11013464\n",
      "epochs =  10 , step =  100 , loss_val =  0.00062009884\n",
      "epochs =  10 , step =  200 , loss_val =  0.004133044\n",
      "epochs =  10 , step =  300 , loss_val =  0.0022406883\n",
      "epochs =  10 , step =  400 , loss_val =  0.08314859\n",
      "epochs =  10 , step =  500 , loss_val =  0.020276345\n",
      "epochs =  11 , step =  0 , loss_val =  0.004327705\n",
      "epochs =  11 , step =  100 , loss_val =  0.042593177\n",
      "epochs =  11 , step =  200 , loss_val =  0.008319338\n",
      "epochs =  11 , step =  300 , loss_val =  0.0193044\n",
      "epochs =  11 , step =  400 , loss_val =  0.0063428106\n",
      "epochs =  11 , step =  500 , loss_val =  0.01799076\n",
      "epochs =  12 , step =  0 , loss_val =  0.01606783\n",
      "epochs =  12 , step =  100 , loss_val =  0.049596716\n",
      "epochs =  12 , step =  200 , loss_val =  0.018552057\n",
      "epochs =  12 , step =  300 , loss_val =  0.043399792\n",
      "epochs =  12 , step =  400 , loss_val =  0.0028822422\n",
      "epochs =  12 , step =  500 , loss_val =  0.017445976\n",
      "epochs =  13 , step =  0 , loss_val =  0.0069316174\n",
      "epochs =  13 , step =  100 , loss_val =  0.007706934\n",
      "epochs =  13 , step =  200 , loss_val =  0.03681889\n",
      "epochs =  13 , step =  300 , loss_val =  0.0011458052\n",
      "epochs =  13 , step =  400 , loss_val =  0.0027551516\n",
      "epochs =  13 , step =  500 , loss_val =  0.014353629\n",
      "epochs =  14 , step =  0 , loss_val =  0.0025971485\n",
      "epochs =  14 , step =  100 , loss_val =  0.0021609876\n",
      "epochs =  14 , step =  200 , loss_val =  0.0037548272\n",
      "epochs =  14 , step =  300 , loss_val =  0.054539897\n",
      "epochs =  14 , step =  400 , loss_val =  0.05292477\n",
      "epochs =  14 , step =  500 , loss_val =  0.010495473\n",
      "epochs =  15 , step =  0 , loss_val =  0.013778519\n",
      "epochs =  15 , step =  100 , loss_val =  0.047443897\n",
      "epochs =  15 , step =  200 , loss_val =  0.014343879\n",
      "epochs =  15 , step =  300 , loss_val =  0.026055014\n",
      "epochs =  15 , step =  400 , loss_val =  0.010603998\n",
      "epochs =  15 , step =  500 , loss_val =  0.0055094836\n",
      "epochs =  16 , step =  0 , loss_val =  0.0064116134\n",
      "epochs =  16 , step =  100 , loss_val =  0.009317834\n",
      "epochs =  16 , step =  200 , loss_val =  0.009326467\n",
      "epochs =  16 , step =  300 , loss_val =  0.0007766647\n",
      "epochs =  16 , step =  400 , loss_val =  0.0008239259\n",
      "epochs =  16 , step =  500 , loss_val =  0.0067529664\n",
      "epochs =  17 , step =  0 , loss_val =  0.004701995\n",
      "epochs =  17 , step =  100 , loss_val =  0.0042779273\n",
      "epochs =  17 , step =  200 , loss_val =  0.0013392724\n",
      "epochs =  17 , step =  300 , loss_val =  0.024709063\n",
      "epochs =  17 , step =  400 , loss_val =  0.010144483\n",
      "epochs =  17 , step =  500 , loss_val =  0.0032972647\n",
      "epochs =  18 , step =  0 , loss_val =  0.017808776\n",
      "epochs =  18 , step =  100 , loss_val =  0.0055470215\n",
      "epochs =  18 , step =  200 , loss_val =  0.051544048\n",
      "epochs =  18 , step =  300 , loss_val =  0.0005674085\n",
      "epochs =  18 , step =  400 , loss_val =  0.0011744441\n",
      "epochs =  18 , step =  500 , loss_val =  0.01403622\n",
      "epochs =  19 , step =  0 , loss_val =  0.012279852\n",
      "epochs =  19 , step =  100 , loss_val =  0.014263276\n",
      "epochs =  19 , step =  200 , loss_val =  0.00038218565\n",
      "epochs =  19 , step =  300 , loss_val =  0.0030511534\n",
      "epochs =  19 , step =  400 , loss_val =  0.0030641514\n",
      "epochs =  19 , step =  500 , loss_val =  0.031119602\n",
      "epochs =  20 , step =  0 , loss_val =  0.03265704\n",
      "epochs =  20 , step =  100 , loss_val =  0.024149988\n",
      "epochs =  20 , step =  200 , loss_val =  0.018431278\n",
      "epochs =  20 , step =  300 , loss_val =  0.0037679481\n",
      "epochs =  20 , step =  400 , loss_val =  0.0054893857\n",
      "epochs =  20 , step =  500 , loss_val =  0.014012667\n",
      "epochs =  21 , step =  0 , loss_val =  0.0014494853\n",
      "epochs =  21 , step =  100 , loss_val =  0.00029648282\n",
      "epochs =  21 , step =  200 , loss_val =  0.007147354\n",
      "epochs =  21 , step =  300 , loss_val =  0.0037720802\n",
      "epochs =  21 , step =  400 , loss_val =  0.0002881664\n",
      "epochs =  21 , step =  500 , loss_val =  0.013503953\n",
      "epochs =  22 , step =  0 , loss_val =  0.012809944\n",
      "epochs =  22 , step =  100 , loss_val =  0.009905681\n",
      "epochs =  22 , step =  200 , loss_val =  0.0037439791\n",
      "epochs =  22 , step =  300 , loss_val =  0.000833077\n",
      "epochs =  22 , step =  400 , loss_val =  4.8819646e-05\n",
      "epochs =  22 , step =  500 , loss_val =  0.0016090268\n",
      "epochs =  23 , step =  0 , loss_val =  0.0014321384\n",
      "epochs =  23 , step =  100 , loss_val =  0.02657696\n",
      "epochs =  23 , step =  200 , loss_val =  0.014360263\n",
      "epochs =  23 , step =  300 , loss_val =  0.00042331644\n",
      "epochs =  23 , step =  400 , loss_val =  0.002046098\n",
      "epochs =  23 , step =  500 , loss_val =  0.015823247\n",
      "epochs =  24 , step =  0 , loss_val =  0.0022481638\n",
      "epochs =  24 , step =  100 , loss_val =  0.00038103707\n",
      "epochs =  24 , step =  200 , loss_val =  0.01116813\n",
      "epochs =  24 , step =  300 , loss_val =  0.011165235\n",
      "epochs =  24 , step =  400 , loss_val =  0.00080113934\n",
      "epochs =  24 , step =  500 , loss_val =  0.0019698183\n",
      "epochs =  25 , step =  0 , loss_val =  0.0028375483\n",
      "epochs =  25 , step =  100 , loss_val =  0.00058187894\n",
      "epochs =  25 , step =  200 , loss_val =  0.00053489\n",
      "epochs =  25 , step =  300 , loss_val =  0.00041832225\n",
      "epochs =  25 , step =  400 , loss_val =  0.016936155\n",
      "epochs =  25 , step =  500 , loss_val =  0.018759808\n",
      "epochs =  26 , step =  0 , loss_val =  0.0065731998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  26 , step =  100 , loss_val =  0.0020632949\n",
      "epochs =  26 , step =  200 , loss_val =  0.0058228266\n",
      "epochs =  26 , step =  300 , loss_val =  0.0003319908\n",
      "epochs =  26 , step =  400 , loss_val =  0.0003005222\n",
      "epochs =  26 , step =  500 , loss_val =  0.0044633984\n",
      "epochs =  27 , step =  0 , loss_val =  0.0045844633\n",
      "epochs =  27 , step =  100 , loss_val =  0.0029362442\n",
      "epochs =  27 , step =  200 , loss_val =  0.0012276515\n",
      "epochs =  27 , step =  300 , loss_val =  0.0039517405\n",
      "epochs =  27 , step =  400 , loss_val =  0.00048285554\n",
      "epochs =  27 , step =  500 , loss_val =  0.0382331\n",
      "epochs =  28 , step =  0 , loss_val =  0.00035303654\n",
      "epochs =  28 , step =  100 , loss_val =  1.26889e-05\n",
      "epochs =  28 , step =  200 , loss_val =  0.0044083693\n",
      "epochs =  28 , step =  300 , loss_val =  0.012366254\n",
      "epochs =  28 , step =  400 , loss_val =  0.0085731195\n",
      "epochs =  28 , step =  500 , loss_val =  0.0007581655\n",
      "epochs =  29 , step =  0 , loss_val =  0.0004704722\n",
      "epochs =  29 , step =  100 , loss_val =  0.0029281017\n",
      "epochs =  29 , step =  200 , loss_val =  0.000471616\n",
      "epochs =  29 , step =  300 , loss_val =  0.00027454947\n",
      "epochs =  29 , step =  400 , loss_val =  0.000314756\n",
      "epochs =  29 , step =  500 , loss_val =  0.00032986104\n",
      "\n",
      "elapsed time =  0:47:31.967725\n",
      "\n",
      "Accuracy =  0.9888\n",
      "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
      "index_label.shape =  (10000,)\n",
      "length of index_label_list =  10000\n",
      "false label count =  112\n",
      "\n",
      "length of index_label_false_list 112\n"
     ]
    }
   ],
   "source": [
    "index_label_prediction_list = []\n",
    "\n",
    "with  tf.Session()  as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):    # 100 번 반복수행\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
    "\n",
    "        for step in range(total_batch):\n",
    "            \n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "      \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now() \n",
    "    \n",
    "    print(\"\\nelapsed time = \", end_time - start_time) \n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images    # 10000 X 784\n",
    "    test_t_data = mnist.test.labels    # 10000 X 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy = \", accuracy_val)\n",
    "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
    "    print(\"index_label.shape = \", index_label.shape)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "        \n",
    "    \n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label)):\n",
    "        \n",
    "        if index_label[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_prediction_list.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ysJo9tWEeXPg",
    "outputId": "5464e18f-a82b-443f-a8c1-d385fba3b6ae"
   },
   "outputs": [],
   "source": [
    "# index_label_prediction_list\n",
    "print(index_label_prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6QAtG28eXPo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "(200407)CNN_example_3_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
