{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example_5_1 에서 Exception Handling 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PU2mbKAlparO",
    "outputId": "3870df28-202a-4e0f-cd61-435055260332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "# Colab에서 tensorflow 1.x 실행\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "colab_type": "code",
    "id": "73l1mwPq7Yva",
    "outputId": "e3ec04ae-86ed-4c17-90bf-99e2deb28c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-37edfc5623ff>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      " 55000 10000 5000\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
    "\n",
    "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
    "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
    "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
    "\n",
    "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
    "\n",
    "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
    "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
    "\n",
    "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
    "print(\"test image shape = \", np.shape(mnist.test.images))\n",
    "print(\"test label shape = \", np.shape(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUhWgzsPpare"
   },
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 0.001  # 학습율\n",
    "epochs = 30            # 반복횟수\n",
    "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBURWGq-parm"
   },
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "\n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # image 28 X 28 X 1 (black/white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlNm5ebiparq"
   },
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층\n",
    "# 5X5 크기를 가지는 32개의 필터를 적용\n",
    "\n",
    "F2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev=0.01))  \n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[32]))   \n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 X 28 X1  => 28 X 28 X 32 \n",
    "C2 = tf.nn.conv2d(A1, F2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 X 28 X 32  => 14 X 14 X 32 \n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhxXLQd9parv"
   },
   "outputs": [],
   "source": [
    "# 2번째 컨볼루션 층\n",
    "F3 = tf.Variable(tf.random_normal([5, 5, 32, 64], stddev=0.01))  \n",
    "b3 = tf.Variable(tf.constant(0.1, shape=[64]))   \n",
    "\n",
    "# 2번째 컨볼루션 연산을 통해 14 X 14 X 32 => 14 X 14 X 64 \n",
    "C3 = tf.nn.conv2d(A2, F3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z3 = tf.nn.relu(C3+b3)\n",
    "\n",
    "# 2번째 max pooling을 통해 14 X 14 X 64 => 7 X 7 X 64\n",
    "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhgsJObypar4"
   },
   "outputs": [],
   "source": [
    "# 3번째 컨볼루션 층\n",
    "F4 = tf.Variable(tf.random_normal([5, 5, 64, 128], stddev=0.01))  \n",
    "b4 = tf.Variable(tf.constant(0.1, shape=[128]))   \n",
    "\n",
    "# 3번째 컨볼루션 연산을 통해 7 X 7 X 64 => 7 X 7 X 128\n",
    "C4 = tf.nn.conv2d(A3, F4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z4 = tf.nn.relu(C4+b4)\n",
    "\n",
    "# 3번째 max pooling을 통해 7 X 7 X 128 => 4 X 4 X 128\n",
    "A4 = P4 = tf.nn.max_pool(Z4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZdbm2qOpar9"
   },
   "outputs": [],
   "source": [
    "# 4X4 크기를 가진 128개의 activation map을 flatten 시킴\n",
    "A4_flat = P4_flat = tf.reshape(A4, [-1, 128*4*4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91YPQ1D0pasC"
   },
   "outputs": [],
   "source": [
    "# 512 개의 노드 완전연결\n",
    "W5 = tf.Variable(tf.random_normal([128*4*4, 512], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([512]))\n",
    "\n",
    "Z5 = tf.matmul(A4_flat, W5) + b5\n",
    "\n",
    "A5 = tf.nn.relu(Z5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xx3DkYB-pasL"
   },
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W6 = tf.Variable(tf.random_normal([512, 10], stddev=0.01))\n",
    "b6 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀  값 Z6, 즉 softmax 에 들어가는 입력 값\n",
    "Z6 = logits = tf.matmul(A5, W6) + b6    # 선형회귀 값 Z6\n",
    "\n",
    "y = A6 = tf.nn.softmax(Z6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldRNNVqVpasP"
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z6, labels=T) )\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QBhUJwHpasW"
   },
   "outputs": [],
   "source": [
    "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal( tf.argmax(A6, 1), tf.argmax(T, 1) )\n",
    "\n",
    "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "# 예측값 처리\n",
    "predicted_list = tf.argmax(A6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iGkjyvs-pasb",
    "outputId": "db1ddc02-abce-4d78-b140-2e9fcadd3979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.6972167\n",
      "epochs =  0 , step =  100 , loss_val =  1.024276\n",
      "epochs =  0 , step =  200 , loss_val =  0.18056965\n",
      "epochs =  0 , step =  300 , loss_val =  0.120784245\n",
      "epochs =  0 , step =  400 , loss_val =  0.063465424\n",
      "epochs =  0 , step =  500 , loss_val =  0.04080782\n",
      "epochs =  1 , step =  0 , loss_val =  0.04611829\n",
      "epochs =  1 , step =  100 , loss_val =  0.0580576\n",
      "epochs =  1 , step =  200 , loss_val =  0.02844864\n",
      "epochs =  1 , step =  300 , loss_val =  0.022968793\n",
      "epochs =  1 , step =  400 , loss_val =  0.058598332\n",
      "epochs =  1 , step =  500 , loss_val =  0.04513318\n",
      "epochs =  2 , step =  0 , loss_val =  0.012506868\n",
      "epochs =  2 , step =  100 , loss_val =  0.016633896\n",
      "epochs =  2 , step =  200 , loss_val =  0.027091537\n",
      "epochs =  2 , step =  300 , loss_val =  0.11209611\n",
      "epochs =  2 , step =  400 , loss_val =  0.037512563\n",
      "epochs =  2 , step =  500 , loss_val =  0.11920361\n",
      "epochs =  3 , step =  0 , loss_val =  0.022659905\n",
      "epochs =  3 , step =  100 , loss_val =  0.009747782\n",
      "epochs =  3 , step =  200 , loss_val =  0.0014962774\n",
      "epochs =  3 , step =  300 , loss_val =  0.020517547\n",
      "epochs =  3 , step =  400 , loss_val =  0.01687708\n",
      "epochs =  3 , step =  500 , loss_val =  0.042745262\n",
      "epochs =  4 , step =  0 , loss_val =  0.014466131\n",
      "epochs =  4 , step =  100 , loss_val =  0.04087983\n",
      "epochs =  4 , step =  200 , loss_val =  0.0067770686\n",
      "epochs =  4 , step =  300 , loss_val =  0.0029147046\n",
      "epochs =  4 , step =  400 , loss_val =  0.019150991\n",
      "epochs =  4 , step =  500 , loss_val =  0.04521734\n",
      "epochs =  5 , step =  0 , loss_val =  0.009712205\n",
      "epochs =  5 , step =  100 , loss_val =  0.0030388993\n",
      "epochs =  5 , step =  200 , loss_val =  0.022391368\n",
      "epochs =  5 , step =  300 , loss_val =  0.00031246923\n",
      "epochs =  5 , step =  400 , loss_val =  0.002496215\n",
      "epochs =  5 , step =  500 , loss_val =  0.1652127\n",
      "epochs =  6 , step =  0 , loss_val =  0.0018823184\n",
      "epochs =  6 , step =  100 , loss_val =  0.0011139709\n",
      "epochs =  6 , step =  200 , loss_val =  0.0043741893\n",
      "epochs =  6 , step =  300 , loss_val =  0.025487805\n",
      "epochs =  6 , step =  400 , loss_val =  0.020226052\n",
      "epochs =  6 , step =  500 , loss_val =  0.000106262436\n",
      "epochs =  7 , step =  0 , loss_val =  0.00256438\n",
      "epochs =  7 , step =  100 , loss_val =  0.013513821\n",
      "epochs =  7 , step =  200 , loss_val =  0.040891603\n",
      "epochs =  7 , step =  300 , loss_val =  0.0032293294\n",
      "epochs =  7 , step =  400 , loss_val =  0.02393399\n",
      "epochs =  7 , step =  500 , loss_val =  0.010809465\n",
      "epochs =  8 , step =  0 , loss_val =  0.01596447\n",
      "epochs =  8 , step =  100 , loss_val =  0.038692724\n",
      "epochs =  8 , step =  200 , loss_val =  8.918183e-05\n",
      "epochs =  8 , step =  300 , loss_val =  0.00039748318\n",
      "epochs =  8 , step =  400 , loss_val =  0.0049821045\n",
      "epochs =  8 , step =  500 , loss_val =  0.00038927287\n",
      "epochs =  9 , step =  0 , loss_val =  0.019142466\n",
      "epochs =  9 , step =  100 , loss_val =  0.0032628437\n",
      "epochs =  9 , step =  200 , loss_val =  0.00018406913\n",
      "epochs =  9 , step =  300 , loss_val =  0.024322256\n",
      "epochs =  9 , step =  400 , loss_val =  9.911804e-05\n",
      "epochs =  9 , step =  500 , loss_val =  0.0014006501\n",
      "epochs =  10 , step =  0 , loss_val =  0.00018449833\n",
      "epochs =  10 , step =  100 , loss_val =  0.00016744547\n",
      "epochs =  10 , step =  200 , loss_val =  0.00011761768\n",
      "epochs =  10 , step =  300 , loss_val =  2.2738981e-05\n",
      "epochs =  10 , step =  400 , loss_val =  0.0018415792\n",
      "epochs =  10 , step =  500 , loss_val =  0.002221809\n",
      "epochs =  11 , step =  0 , loss_val =  0.07324648\n",
      "epochs =  11 , step =  100 , loss_val =  0.00054086134\n",
      "epochs =  11 , step =  200 , loss_val =  0.019292288\n",
      "epochs =  11 , step =  300 , loss_val =  0.00012780643\n",
      "epochs =  11 , step =  400 , loss_val =  0.00058440614\n",
      "epochs =  11 , step =  500 , loss_val =  0.0003263296\n",
      "epochs =  12 , step =  0 , loss_val =  0.0018571639\n",
      "epochs =  12 , step =  100 , loss_val =  0.00073126546\n",
      "epochs =  12 , step =  200 , loss_val =  0.013685603\n",
      "epochs =  12 , step =  300 , loss_val =  0.00046162837\n",
      "epochs =  12 , step =  400 , loss_val =  0.006919935\n",
      "epochs =  12 , step =  500 , loss_val =  0.009744398\n",
      "epochs =  13 , step =  0 , loss_val =  0.0007953192\n",
      "epochs =  13 , step =  100 , loss_val =  0.00017109636\n",
      "epochs =  13 , step =  200 , loss_val =  0.029610358\n",
      "epochs =  13 , step =  300 , loss_val =  0.0014605474\n",
      "epochs =  13 , step =  400 , loss_val =  5.9086633e-06\n",
      "epochs =  13 , step =  500 , loss_val =  0.00014729513\n",
      "epochs =  14 , step =  0 , loss_val =  0.006987357\n",
      "epochs =  14 , step =  100 , loss_val =  0.0006395487\n",
      "epochs =  14 , step =  200 , loss_val =  7.8299876e-05\n",
      "epochs =  14 , step =  300 , loss_val =  0.0003039486\n",
      "epochs =  14 , step =  400 , loss_val =  0.001705397\n",
      "epochs =  14 , step =  500 , loss_val =  0.0020584106\n",
      "epochs =  15 , step =  0 , loss_val =  0.0078475885\n",
      "epochs =  15 , step =  100 , loss_val =  0.00020122746\n",
      "epochs =  15 , step =  200 , loss_val =  0.00028748089\n",
      "epochs =  15 , step =  300 , loss_val =  0.0058665834\n",
      "epochs =  15 , step =  400 , loss_val =  0.0001681508\n",
      "epochs =  15 , step =  500 , loss_val =  0.011704215\n",
      "epochs =  16 , step =  0 , loss_val =  0.0027371186\n",
      "epochs =  16 , step =  100 , loss_val =  6.671967e-05\n",
      "epochs =  16 , step =  200 , loss_val =  7.081878e-05\n",
      "epochs =  16 , step =  300 , loss_val =  0.13095044\n",
      "epochs =  16 , step =  400 , loss_val =  7.1885624e-05\n",
      "epochs =  16 , step =  500 , loss_val =  1.8881631e-06\n",
      "epochs =  17 , step =  0 , loss_val =  0.0076573137\n",
      "epochs =  17 , step =  100 , loss_val =  2.3720868e-05\n",
      "epochs =  17 , step =  200 , loss_val =  0.03329919\n",
      "epochs =  17 , step =  300 , loss_val =  0.00019679956\n",
      "epochs =  17 , step =  400 , loss_val =  8.13499e-05\n",
      "epochs =  17 , step =  500 , loss_val =  0.0016772565\n",
      "epochs =  18 , step =  0 , loss_val =  0.00049351226\n",
      "epochs =  18 , step =  100 , loss_val =  0.00079475396\n",
      "epochs =  18 , step =  200 , loss_val =  1.931056e-06\n",
      "epochs =  18 , step =  300 , loss_val =  0.00038512738\n",
      "epochs =  18 , step =  400 , loss_val =  0.03340264\n",
      "epochs =  18 , step =  500 , loss_val =  0.0013450135\n",
      "epochs =  19 , step =  0 , loss_val =  0.013502196\n",
      "epochs =  19 , step =  100 , loss_val =  3.3612436e-05\n",
      "epochs =  19 , step =  200 , loss_val =  0.0039182315\n",
      "epochs =  19 , step =  300 , loss_val =  0.00040456196\n",
      "epochs =  19 , step =  400 , loss_val =  4.5163837e-05\n",
      "epochs =  19 , step =  500 , loss_val =  0.00050547067\n",
      "epochs =  20 , step =  0 , loss_val =  0.00012028855\n",
      "epochs =  20 , step =  100 , loss_val =  0.00079344824\n",
      "epochs =  20 , step =  200 , loss_val =  0.000109555396\n",
      "epochs =  20 , step =  300 , loss_val =  0.0008380938\n",
      "epochs =  20 , step =  400 , loss_val =  5.3492536e-06\n",
      "epochs =  20 , step =  500 , loss_val =  0.00019303535\n",
      "epochs =  21 , step =  0 , loss_val =  3.0140553e-05\n",
      "epochs =  21 , step =  100 , loss_val =  0.000105277744\n",
      "epochs =  21 , step =  200 , loss_val =  1.320849e-05\n",
      "epochs =  21 , step =  300 , loss_val =  1.3720396e-06\n",
      "epochs =  21 , step =  400 , loss_val =  0.00010785543\n",
      "epochs =  21 , step =  500 , loss_val =  7.53392e-07\n",
      "epochs =  22 , step =  0 , loss_val =  9.5023504e-05\n",
      "epochs =  22 , step =  100 , loss_val =  6.846969e-05\n",
      "epochs =  22 , step =  200 , loss_val =  2.7631222e-06\n",
      "epochs =  22 , step =  300 , loss_val =  9.977489e-05\n",
      "epochs =  22 , step =  400 , loss_val =  3.6311994e-05\n",
      "epochs =  22 , step =  500 , loss_val =  0.00025316345\n",
      "epochs =  23 , step =  0 , loss_val =  0.00021153943\n",
      "epochs =  23 , step =  100 , loss_val =  3.852536e-06\n",
      "epochs =  23 , step =  200 , loss_val =  6.512123e-05\n",
      "epochs =  23 , step =  300 , loss_val =  8.5382e-05\n",
      "epochs =  23 , step =  400 , loss_val =  0.0009891288\n",
      "epochs =  23 , step =  500 , loss_val =  0.00067587895\n",
      "epochs =  24 , step =  0 , loss_val =  0.0024826832\n",
      "epochs =  24 , step =  100 , loss_val =  2.7224387e-06\n",
      "epochs =  24 , step =  200 , loss_val =  0.014443576\n",
      "epochs =  24 , step =  300 , loss_val =  7.0313704e-06\n",
      "epochs =  24 , step =  400 , loss_val =  0.0124744605\n",
      "epochs =  24 , step =  500 , loss_val =  0.0026025972\n",
      "epochs =  25 , step =  0 , loss_val =  2.8115317e-05\n",
      "epochs =  25 , step =  100 , loss_val =  0.0015603495\n",
      "epochs =  25 , step =  200 , loss_val =  1.0328859e-05\n",
      "epochs =  25 , step =  300 , loss_val =  0.0011237239\n",
      "epochs =  25 , step =  400 , loss_val =  2.4726376e-05\n",
      "epochs =  25 , step =  500 , loss_val =  0.00274693\n",
      "epochs =  26 , step =  0 , loss_val =  3.4150355e-06\n",
      "epochs =  26 , step =  100 , loss_val =  0.015833242\n",
      "epochs =  26 , step =  200 , loss_val =  0.000171549\n",
      "epochs =  26 , step =  300 , loss_val =  1.9190273e-05\n",
      "epochs =  26 , step =  400 , loss_val =  9.727231e-07\n",
      "epochs =  26 , step =  500 , loss_val =  5.5945202e-05\n",
      "epochs =  27 , step =  0 , loss_val =  0.00015883894\n",
      "epochs =  27 , step =  100 , loss_val =  0.19088262\n",
      "epochs =  27 , step =  200 , loss_val =  6.1749364e-07\n",
      "epochs =  27 , step =  300 , loss_val =  3.2699278e-05\n",
      "epochs =  27 , step =  400 , loss_val =  0.03495737\n",
      "epochs =  27 , step =  500 , loss_val =  0.00012799827\n",
      "epochs =  28 , step =  0 , loss_val =  0.011061605\n",
      "epochs =  28 , step =  100 , loss_val =  3.2981864e-06\n",
      "epochs =  28 , step =  200 , loss_val =  0.00068140647\n",
      "epochs =  28 , step =  300 , loss_val =  5.676991e-05\n",
      "epochs =  28 , step =  400 , loss_val =  2.0807332e-05\n",
      "epochs =  28 , step =  500 , loss_val =  0.021789677\n",
      "epochs =  29 , step =  0 , loss_val =  3.802517e-05\n",
      "epochs =  29 , step =  100 , loss_val =  0.0008925024\n",
      "epochs =  29 , step =  200 , loss_val =  1.1718062e-05\n",
      "epochs =  29 , step =  300 , loss_val =  0.00021972194\n",
      "epochs =  29 , step =  400 , loss_val =  8.025459e-05\n",
      "epochs =  29 , step =  500 , loss_val =  0.00087363017\n",
      "\n",
      "elapsed time =  0:04:09.866403\n",
      "\n",
      "Accuracy =  0.9929\n",
      "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
      "index_label.shape =  (10000,)\n",
      "length of index_label_list =  10000\n",
      "false label count =  71\n",
      "\n",
      "length of index_label_false_list 71\n"
     ]
    }
   ],
   "source": [
    "index_label_prediction_list = []\n",
    "\n",
    "with  tf.Session()  as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):    # 30 번 반복수행\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
    "\n",
    "        for step in range(total_batch):\n",
    "            \n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "      \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now() \n",
    "    \n",
    "    print(\"\\nelapsed time = \", end_time - start_time) \n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images    # 10000 X 784\n",
    "    test_t_data = mnist.test.labels    # 10000 X 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy = \", accuracy_val)\n",
    "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
    "    print(\"index_label.shape = \", index_label.shape)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "        \n",
    "    \n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label)):\n",
    "        \n",
    "        if index_label[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_prediction_list.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "ua5zLZvTpasf",
    "outputId": "21b9af40-9a68-4eff-a843-00048f48678b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115, 4, 9], [321, 2, 7], [340, 5, 3], [445, 6, 0], [582, 8, 2], [583, 2, 7], [646, 2, 4], [659, 2, 7], [740, 4, 9], [938, 3, 5], [947, 8, 9], [1014, 6, 9], [1112, 4, 6], [1232, 9, 4], [1242, 4, 9], [1247, 9, 5], [1260, 7, 1], [1393, 5, 3], [1527, 1, 3], [1621, 0, 6], [1790, 2, 7], [1878, 8, 3], [2035, 5, 3], [2070, 7, 9], [2098, 2, 0], [2118, 6, 0], [2130, 4, 9], [2135, 6, 1], [2266, 1, 3], [2447, 4, 9], [2462, 2, 0], [2597, 5, 3], [2654, 6, 1], [2953, 3, 5], [2959, 2, 3], [3023, 8, 5], [3225, 7, 9], [3422, 6, 0], [3475, 3, 7], [3520, 6, 4], [3681, 2, 8], [4176, 2, 7], [4289, 2, 7], [4443, 3, 2], [4497, 8, 7], [4504, 2, 7], [4740, 3, 5], [4743, 8, 6], [4783, 4, 9], [4860, 4, 9], [5634, 2, 8], [5937, 5, 3], [5997, 5, 9], [6560, 9, 5], [6576, 7, 1], [6597, 0, 7], [6744, 2, 8], [8059, 2, 1], [8094, 2, 8], [8246, 3, 5], [8316, 7, 2], [8325, 0, 6], [8376, 1, 4], [9015, 7, 2], [9700, 2, 8], [9729, 5, 6], [9779, 2, 8], [9792, 4, 9], [9839, 2, 7], [9847, 2, 7], [9850, 0, 6]]\n"
     ]
    }
   ],
   "source": [
    "# index_label_prediction_list\n",
    "print(index_label_prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "GOhDBVyopozU",
    "outputId": "2bdcda10-5281-48e5-c0c7-5548646b4465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive   # colab 사용시 mount 하기 위한 용도. local 에서는 불필요\n",
    "drive.mount('/content/gdrive/')  # colab 사용시 mount 하기 위한 용도. local 에서는 불필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "colab_type": "code",
    "id": "KKHE6vNYpasj",
    "outputId": "854f522b-a7f7-4b1a-ba00-1e6ef0bc6b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "Elapsed save time =>  0:00:25.788418\n",
      "Total  71  data is saved\n",
      "Bye....\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAEICAYAAABWCOFPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIumJ9bfuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "example_name = 'CNN_Example_5_2_'\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "\n",
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "\n",
    "save_dir_name = example_name + str(now.year) + '-' + str(now.month) + '-' + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "colab_default_dir = '/content/gdrive/My Drive/Colab Notebooks/'\n",
    "\n",
    "# Exception handling => 파일과 디렉토리 프로그래밍 이므로 반드시 exception handling 필요\n",
    "\n",
    "try:\n",
    "\n",
    "  os.chdir(colab_default_dir)\n",
    "  os.mkdir(save_dir_name)\n",
    "\n",
    "  # change dir\n",
    "  os.chdir(save_dir_name)\n",
    "\n",
    "  start_time = datetime.now()\n",
    "\n",
    "  for list_data in index_label_prediction_list:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "    \n",
    "    # 인덱스 문자열\n",
    "    index_str = str(index_int)\n",
    "\n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 인덱스 정답 오답을 나타내는 문자열\n",
    "    index_label_prediction_str = 'index = ' + index_str + ', label = ' + label_str + ', prediction = ' + prediction_str\n",
    "    \n",
    "\n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    plt.title(index_label_prediction_str)\n",
    "\n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "    plt.savefig(save_image_name)  # 파일저장\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "      print(save_count, 'image is saved now')\n",
    "        \n",
    "  end_time = datetime.now()\n",
    "\n",
    "  print('Elapsed save time => ', end_time - start_time)\n",
    "  print('Total ', save_count, \" data is saved\")        \n",
    "\n",
    "  # 원래의 dir 로 복귀\n",
    "  os.chdir(curr_dir)\n",
    "\n",
    "except Exception as err:\n",
    "\n",
    "  # 원래의 dir 로 복귀\n",
    "  os.chdir(curr_dir)\n",
    "  print(str(err))\n",
    "\n",
    "print('Bye....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQvRG8Bkpasq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_Example_5_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
